<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><?properties no_embargo?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title>Bioinformatics</journal-title><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1460-2059</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmc">2519164</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btn346</article-id><article-id pub-id-type="publisher-id">btn346</article-id><article-id pub-id-type="pmid">18603566</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review Paper</subject><subj-group><subject>Data and Text Mining</subject></subj-group></subj-group></article-categories><title-group><article-title>Bioimage informatics: a new area of engineering biology</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peng</surname><given-names>Hanchuan</given-names></name></contrib></contrib-group><aff>Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, Virginia, USA</aff><author-notes><fn><p>Associate Editor: Jonathan Wren</p></fn></author-notes><pub-date pub-type="ppub"><day>1</day><month>9</month><year>2008</year></pub-date><pub-date pub-type="epub"><day>4</day><month>7</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>4</day><month>7</month><year>2008</year></pub-date><volume>24</volume><issue>17</issue><fpage>1827</fpage><lpage>1836</lpage><history><date date-type="received"><day>6</day><month>6</month><year>2008</year></date><date date-type="rev-recd"><day>1</day><month>7</month><year>2008</year></date><date date-type="accepted"><day>2</day><month>7</month><year>2008</year></date></history><permissions><copyright-statement>&#x000a9; 2008 The Author(s)</copyright-statement><copyright-year>2008</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p>In recent years, the deluge of complicated molecular and cellular microscopic images creates compelling challenges for the image computing community. There has been an increasing focus on developing novel image processing, data mining, database and visualization techniques to extract, compare, search and manage the biological knowledge in these data-intensive problems. This emerging new area of bioinformatics can be called &#x02018;bioimage informatics&#x02019;. This article reviews the advances of this field from several aspects, including applications, key techniques, available tools and resources. Application examples such as high-throughput/high-content phenotyping and atlas building for model organisms demonstrate the importance of bioimage informatics. The essential techniques to the success of these applications, such as bioimage feature identification, segmentation and tracking, registration, annotation, mining, image data management and visualization, are further summarized, along with a brief overview of the available bioimage databases, analysis tools and other resources.</p><p><bold>Contact:</bold> <email>pengh@janelia.hhmi.org</email></p><p><bold>Supplementary information:</bold> <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btn346/DC1">Supplementary data</ext-link> are available at <italic>Bioinformatics</italic> online.</p></abstract></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>1 INTRODUCTION</title><p>In the last several decades, numerous biomedical imaging techniques were developed, ranging from the whole organism level (millimeter resolution) down to the single molecule level (nanometer resolution) (Murphy, <xref ref-type="bibr" rid="B87">2001</xref>; Tsien, <xref ref-type="bibr" rid="B119">2003</xref>). Some of the most widely used biological imaging methods include confocal or two-photon laser scanning microscopy (LSM) (Pawley, <xref ref-type="bibr" rid="B94">2006</xref>), scanning or transmission electron microscopy (EM) (Bozzola and Russell, <xref ref-type="bibr" rid="B18">1999</xref>), etc. Novel imaging techniques such as PALM (Betzig <italic>et al.</italic>, <xref ref-type="bibr" rid="B16">2006</xref>), STORM (Rust <italic>et al.</italic>, <xref ref-type="bibr" rid="B107">2006</xref>), STED (Hell, <xref ref-type="bibr" rid="B50">2003</xref>) that far surpass the resolution of conventional optical microscopes currently can pinpoint the location of individual proteins that are only several nanometers apart. Along with the dramatic advances of many related techniques such as image signal digitization and storage, biological tissue labeling [e.g. green fluorescent proteins (GFP) and enhanced GFP (EGFP) (Heim <italic>et al.</italic>, <xref ref-type="bibr" rid="B48">1995</xref>; Shimomura <italic>et al.</italic>, <xref ref-type="bibr" rid="B111">1962</xref>), Dronpa (Ando <italic>et al.</italic>, <xref ref-type="bibr" rid="B9">2004</xref>), Brainbow combinatorial labeling (Livet <italic>et al.</italic>, <xref ref-type="bibr" rid="B68">2007</xref>)], the number of biological images (e.g. cellular and molecular images, as well as medical images) acquired in digital forms is growing rapidly. Large bioimage databases such as Allen Brain Atlas (Lein <italic>et al.</italic>, <xref ref-type="bibr" rid="B60">2007</xref>) and the Cell Centered Database CCDB; (Martone <italic>et al.</italic>, <xref ref-type="bibr" rid="B79">2002</xref>) are becoming available. These image data could involve (1) two-dimensional (2D) or 3D spatial information, (2) multiple colors which may correspond to various molecular reporters, (3) 4D spatio-temporal information for developing tissues or moving cells, (4) various co-localized biological signals such as mRNA expression levels of different genes (Lein <italic>et al.</italic>, <xref ref-type="bibr" rid="B60">2007</xref>; Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B72">2007b</xref>; Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B100">2007</xref>) or (5) other screening experiments related to RNA interference (RNAi), chemical compounds, etc. (Echeverri and Perrimon, <xref ref-type="bibr" rid="B33">2006</xref>; Moffat <italic>et al.</italic>, <xref ref-type="bibr" rid="B86">2006</xref>; Sepp <italic>et al.</italic>, <xref ref-type="bibr" rid="B108">2008</xref>). Analyzing these images is critical for biologists to seek answers to many biological problems, such as differentiating cancer cell phenotypes (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B71">2007a</xref>), categorization of neurons (Jefferis <italic>et al.</italic>, <xref ref-type="bibr" rid="B55">2007</xref>), etc.</p><p>The deluge of complicated biological and biomedical images poses significant challenges for the image computing community. As a natural extension of the existing biomedical image analysis field, an emerging new engineering area is to develop and use various image data analysis and informatics techniques to extract, compare, search and manage the biological knowledge of the respective images. This new field can be called bioimage informatics. However, due to the great complexity and information content in bioimages, such as the very high density of cells (e.g. astrocytes, microglia, neurons) intertwined together (<xref ref-type="fig" rid="F1">Fig. 1</xref>A), or very rapid microtubule growing process in a 4D movie of live cells, it is very challenging to directly apply existing medical image analysis methods to these bioimage informatics problems. Special techniques such as those developed in the FARSIGHT project (Roysam, <xref ref-type="bibr" rid="B106">2008</xref>) will be necessary to analyze these complicated image objects (<xref ref-type="fig" rid="F1">Fig. 1</xref>B). In addition, usually a single biological image stack has a large size (several hundreds of megabytes or even several gigabytes) and several color channels. The objects of interest in such an image, for instance the 3D structures of neurons, could have dramatic variations of morphology and intensity variations from image to image. It is yet not uncommon that thousands of images need to be automatically analyzed in a high-throughput way, in terms of the number of hours or days, but not months or years of manual work. All these difficulties make it necessary to develop novel bioimage informatics algorithms and systems, especially from three aspects: image processing and mining, image database and visualization.
<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>(<bold>A</bold>) Maximum projection of a 5-channel confocal 3D image of a 100 &#x003bc;m thick section of rat hippocampus. Red: GFAP-labeled astrocytes; green: EBA-labeled blood vessels; yellow: Iba1-labeled microglia; cyan: CyQuant-labeled cell nuclei; purple: NeuroTrace-labeled Nissl substance; scale bar=50 &#x003bc;m. (<bold>B</bold>) 3D rendering (with a similar color scheme) of the segmented and classified cells produced using the FARSIGHT techniques for (A). Image courtesy of Badrinath Roysam (Bjornsson <italic>et al.</italic>, <xref ref-type="bibr" rid="B17">2008</xref>)</p></caption><graphic xlink:href="btn346f1"/></fig></p><p>Many studies of bioimage informatics are either underway or have been done over the last few years. Several very successful workshops (e.g. bioimageinformatics.org) were organized to discuss the latest developments of this field. The goal of this essay is to briefly review the advance of bioimage informatics from the angles of applications, key techniques, available tools and resources. First, in <xref ref-type="sec" rid="SEC2">Section 2</xref> several application studies on the high-through biology, model organisms, etc., are introduced. Further, in <xref ref-type="sec" rid="SEC3">Section 3</xref> the desired computational techniques, including bioimage feature identification, segmentation, registration, annotation, mining, indexing, retrieval and visualization, are discussed. In <xref ref-type="sec" rid="SEC4">Sections 4</xref> and <xref ref-type="sec" rid="SEC5">5</xref> the available tools and resources are summarized. While in this short article, it is difficult to include all the important work, and to explain the details of the discussed applications and computing methods (such as their biological objectives, challenges and findings), I hope that the presented facts and links can be helpful for both researchers in this field and general audiences who may have interests in learning the basic ideas of bioimage informatics.</p></sec><sec id="SEC2"><title>2 APPLICATIONS</title><p>Just like many other engineering fields, bioimage informatics is application-driven, as one can see from the following non-exclusive instances.</p><sec id="SEC2.1"><title>2.1 High-throughput and high-content analysis of cellular phenotypes</title><p>Large-scale screening of cellular phenotypes, at whole-cell or sub-cellular levels, is of importance for determination of gene functions, delineating cellular pathways, drug discovery and even cancer diagnosis. The CellProfiler system (Carpenter <italic>et al.</italic>, <xref ref-type="bibr" rid="B23">2006</xref>; Lamprecht <italic>et al.</italic>, <xref ref-type="bibr" rid="B58">2007</xref>) was developed to screen cellular images rapidly and gather information such as number of cells, size and other morphological features of cells, per-cell protein levels, cell cycle distribution, etc. This system has been used to detect various cell phenotypes, such as <italic>Drosophila</italic> Kc167 cells, whose images are often textured and clumpy, and human HT29 cells, which are smooth and elliptical. Intelligent human&#x02013;computer interface and content-based image retrieval relevance feedback were also used to enable high-content screening of <italic>Drosophila</italic> (fruit fly) neurons (Hong, <xref ref-type="bibr" rid="B52">2006</xref>; Lin <italic>et al.</italic>, <xref ref-type="bibr" rid="B63">2007</xref>). Analysis of the morphological signatures of cells was used to study signaling pathways related to cell protrusion, adhesion and tension (Bakal <italic>et al.</italic>, <xref ref-type="bibr" rid="B14">2007</xref>).</p><p>For high-resolution intracellular analysis, 3D protein location patterns associated with a number of subcellular organelles and components such as nucleus, nucleolus, mitochondria, cytoskeleton, etc., can be described and classified using fluorescence image features, such as Haralick textures features and Zernike moments (Murphy <italic>et al.</italic>, <xref ref-type="bibr" rid="B88">2003</xref>). Spatial patterns may also be considered in clustering analysis and used for prediction of breast cancers (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B71">2007a</xref>). More systematic descriptions, such as generative models for subcellular locations of proteins, can provide information for systems biology study (Zhao and Murphy, <xref ref-type="bibr" rid="B127">2007</xref>).</p></sec><sec id="SEC2.2"><title>2.2 Atlas building for model organisms</title><p>Bioimage informatics methods were used to study widely used model organisms, such as mouse (Dorr <italic>et al.</italic>, <xref ref-type="bibr" rid="B32">2008</xref>; Lein <italic>et al.</italic>, <xref ref-type="bibr" rid="B60">2007</xref>; Ng <italic>et al.</italic>, <xref ref-type="bibr" rid="B90">2007</xref>), fruit fly (Luengo Hendriks <italic>et al.</italic>, <xref ref-type="bibr" rid="B76">2006</xref>, Luengo Hendriks <italic>et al.</italic>, <xref ref-type="bibr" rid="B76">2006</xref>, Peng and Myers, <xref ref-type="bibr" rid="B96">2004</xref>, Peng and Myers, <xref ref-type="bibr" rid="B96">2004</xref>; H. Peng <italic>et al.</italic>, unpublished data), <italic>Caenorhabditiselegans</italic> (Liu <italic>et al.</italic>, <xref ref-type="bibr" rid="B66">2008</xref>; Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B72">2007b</xref>), zebrafish (Megason <italic>et al.</italic>, 2007), etc. One very important aspect is to build various digital atlases of these organisms, and further integrate the respective anatomical and ontological knowledge into databases.</p><p>Allen Brain Atlas (Lein <italic>et al.</italic>, <xref ref-type="bibr" rid="B60">2007</xref>) integrates the genome-wide RNA <italic>in situ</italic> hybridization (ISH) gene expression information of 20 000 mouse genes. Besides a manually generated reference atlas, the Anatomic Gene Expression Atlas (AGEA) is an interactive 3D atlas of the adult mouse brain based on ISH gene expression images. AGEA is based on approximately 4000 coronal gene sets, which allows anatomic specification and browsing based on 3D spatial coordinates and expression threshold control. With the pixel resolution at &#x0223c;25 &#x003bc;m, Allen Brain Atlas provides very useful information for studies close to the cellular level.</p><p>Single-cell analysis for an entire animal is useful for understanding the cell functions, such as the neuronal circuit mapping based on 3D cellular images of a brain. This task is possible if the cells have unique identities, indicated by the stereotypy of their 3D locations, 3D morphology, birth orders (lineages), gene expression patterns or other functional properties. Several systems do have these distinct properties. In <italic>C.elegans</italic>, each cell has a unique lineage and identity. A recent development is the building of the single-cell atlas for the L1 stage of <italic>C.elegans</italic> (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B72">2007b</xref>). It is based on a series of bioimage-processing and mining techniques including <italic>C.elegans</italic> worm body straightening (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B101">2008a</xref>), nuclei segmentation (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B73">2007c</xref>), annotation and cell identification (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B74">2008</xref>; Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B102">2008b</xref>) and atlas modeling. With this atlas, systematic and high-throughput analysis of gene expression at the truly single-cell level, instead of clusters of cells, becomes feasible (Liu <italic>et al.</italic>, <xref ref-type="bibr" rid="B66">2008</xref>). Several other pieces of similar work are underway for different systems, e.g. a fruit fly adult brain (H. Peng <italic>et al.</italic> unpublished data).</p></sec><sec id="SEC2.3"><title>2.3 Understanding the dynamic processes in cells and living organisms</title><p>For intracellular processes, the microtubule, one class of the cytoskeleton polymers that is constantly assembled and disassembled, receives much attention in studies of various cell functions, e.g. cell division. By imaging GFP fused to the distal ends of microtubules, it is possible to analyze the different dynamic patterns of microtubules, such as the velocity and acceleration, for mutants or under other conditions. Computationally, the microtubule growing, shortening and other dynamic patterns can be tracked in time-lapse microscopy images, via mixture analysis of hidden Markov models (Altinok <italic>et al.</italic>, <xref ref-type="bibr" rid="B6">2006</xref>; Altinok <italic>et al.</italic>, <xref ref-type="bibr" rid="B7">2007</xref>), minimum shared decomposition of directed graphs derived from the microtubule spots (Swidan <italic>et al.</italic>, <xref ref-type="bibr" rid="B114">2007</xref>), particle filtering (Smal <italic>et al.</italic>, <xref ref-type="bibr" rid="B112">2008</xref>), multiscale tip and body model (Jiang <italic>et al.</italic>, <xref ref-type="bibr" rid="B56">2005</xref>), detecting individual segments and linking (Danuser <italic>et al.</italic>, <xref ref-type="bibr" rid="B29">2000</xref>; Hadjidemetriou <italic>et al.</italic>, <xref ref-type="bibr" rid="B46">2004</xref>; Meijering <italic>et al.</italic>, <xref ref-type="bibr" rid="B83">2006</xref>). Hierarchical, agglomerative clustering analysis of various yeast mutants based on kinetochore microtubule dynamics was also reported (Jaqaman <italic>et al.</italic>, <xref ref-type="bibr" rid="B54">2007</xref>).</p><p>For developmental biology, visualizing how genes are expressed in living organisms allows us to gain insight in the interactions of gene products. For developing zebrafish embryos, <italic>in toto</italic> imaging based on time-lapse, LSM were used to track cells in the four dimensions of space and time (Megason <italic>et al.</italic>, <xref ref-type="bibr" rid="B81">2008</xref>). Image analysis methods were developed to read out quantitative, cell-based protein expression patterns and transcriptional expression patterns <italic>in vivo</italic>. The <italic>in toto</italic> imaging analysis approach is suitable for studying animal development from a systems biology perspective. For cases where it is difficult to directly observe how 3D spatial patterns of gene expression change over time, manifold learning can be used to computationally reconstruct the 4D spatio-temporal developmental dynamics of these patterns. For developing fruit fly embryos, spatial registration and comparison of 3D gene expression patterns were developed and conjugated with an approximation algorithm of the Traveling Salesman problem, to reconstruct the developing dynamics of genes such as <italic>ftz and snail</italic> (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B97">2005a</xref>).</p></sec><sec id="SEC2.4"><title>2.4 Reconstruction of 3D neuronal structures and the wiring diagram of a brain</title><p>For neuroscience, there have been a lot of efforts on tracing and reconstruction of 3D structures of neurons, based on optical and electron microcopy images. Neurolucida (Glaser and Glaser, <xref ref-type="bibr" rid="B41">1990</xref>), a pioneering software package in this sort, permits users to digitally trace neuronal structures in images. Many automated approaches were developed recently. Directional kernels were used to exploratorily search neuronal topology in confocal images (Al-Kofahi <italic>et al.</italic>, <xref ref-type="bibr" rid="B4">2002</xref>, <xref ref-type="bibr" rid="B5">2003</xref>). A repulsive force-based snake model was proposed to segment axons in 2D images and then track them in 3D confocal images of transgenic mice that express fluorescent protein (Cai <italic>et al.</italic>, <xref ref-type="bibr" rid="B22">2006</xref>). A graph cut method was used to segment neuronal structures in electron micrographs (Vu and Manjunath, <xref ref-type="bibr" rid="B122">2008</xref>). The convolutional neural network was used to reconstruct the nanometer scale image objects from scanning electron microscopy (SEM) images (Jain <italic>et al.</italic>, <xref ref-type="bibr" rid="B53">2007</xref>). Several automated 3D reconstruction software packages for optical and EM images were also built (e.g. Maack <italic>et al.</italic>, <xref ref-type="bibr" rid="B77">2007</xref>); Y. Mishchenko, personal communication). The FARSIGHT project (<xref ref-type="fig" rid="F1">Fig. 1</xref>), which targets integrating the automated 3D segmentation and tracing algorithms for astrocytes, microglia, neurons, etc., uses a systematic divide and conquer strategy for associative bioimage analysis (Bjornsson <italic>et al.</italic>, <xref ref-type="bibr" rid="B17">2008</xref>; Roysam <italic>et al.</italic>, <xref ref-type="bibr" rid="B106">2008</xref>). Thousands of reconstructed neurons have also been organized into publicly available databases, such as NeuroMorpho.org (Ascoli, <xref ref-type="bibr" rid="B12">2006</xref>). Along with a number of on-going projects on categorizing the types of neuronal structures, or mapping the neuronal circuits, these resources will provide very valuable information to understand and manipulate neuronal circuits.</p><p>One of the most exciting challenges in science is to understand how a brain works. The reverse-engineering approach to tackle this problem needs to reconstruct either the anatomical wiring diagram of the brain of an animal (e.g. a fruit fly's brain with 100 000 or so neurons), or the functional wiring diagram of this brain, or both. The aforementioned 3D neuron tracing techniques, as well as image segmentation and neuron classification methods are needed to identify neurons and study their wirings based on electron, optical or functional imaging (e.g. Ca<sup>2+</sup>) data.</p></sec><sec id="SEC2.5"><title>2.5 Joint analysis using both bioimage informatics and other bioinformatics methods</title><p>Bioimage informatics techniques can also be paired with conven-tional bioinformatics methods. For example, clustering embryonic gene expression patterns of fruit fly can be conjugated with com-parative genomics approach to predict sequence motifs that may have regulatory functions (<xref ref-type="fig" rid="F2">Fig. 2</xref>) (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B100">2007</xref>).
<fig id="F2" position="float"><label>Fig. 2.</label><caption><p>Clustering analysis of embryonic <italic>in situ</italic> mRNA gene expression patterns of fruit fly genes and its utility in assisting prediction of the regulatory sequence motifs. Based on clustering the eigen-embryo profiles (purple&#x02013;cyan plot) of representative gene expression patterns, four genes in <italic>S</italic><sub>Q</sub> are detected to be co-expressed genes. This prediction is consistent with their known gene regulation relationship for fly mesoderm patterning. Further, <italic>S</italic><sub>Q</sub> can be used to predict sequence motifs. The motif example shown is detected using the entire upstream regions of the homologous genes in eight fly species <italic>D.melanogaster</italic>, <italic>D.simulans</italic>, <italic>D.yakuba</italic>, <italic>D.erecta</italic>, and <italic>D.ananassae</italic>, <italic>D.pseudoobscura</italic>, <italic>D.virilis</italic>, and <italic>D.mojavensis</italic>, along with three randomly selected example genes in the subsequent genome-wide motif scanning results. BDGP (fruitfly.org) ISH images (in blue) and annotations are also shown, without image cropping or orientation correction. Short terms of annotations: AAISN, amnioserosa anlage in statu nascendi; AISN, anlage in statu nascendi; AEA, anterior endoderm anlage; AEAISN, anterior endoderm anlage in statu nascendi; CB, cellular blastoderm; DEA, dorsal ectoderm anlage; DEAISN, dorsal ectoderm anlage in statu nascendi; EAISN, endoderm anlage in statu nascendi; FA, foregut anlage; FAISN, foregut anlage in statu nascendi; HMA, head mesoderm anlage; HA, hindgut anlage; MAISN, mesoderm anlage in statu nascendi; PTEA, posterior endoderm anlage; S, subset; TMA, trunk mesoderm anlage; TMAISN, trunk mesoderm anlage in statu nascendi; VEA, ventral ectoderm anlage; VNA, ventral neuroderm anlage. Original image source: (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B100">2007</xref>)</p></caption><graphic xlink:href="btn346f2"/></fig></p><p>Besides the above examples, several bioimage informatics applications (e.g. functional genomics) have also been discussed in recent articles such as Megason and Fraser (<xref ref-type="bibr" rid="B80">2007</xref>) and Meijering <italic>et al.</italic>, (<xref ref-type="bibr" rid="B83">2006</xref>).</p></sec></sec><sec id="SEC3"><title>3 CRITICAL TECHNIQUES</title><p>In order to cope with the complexity in bioimage data, a number of image analyses, machine learning and data mining techniques are needed. Data management and visualization techniques are also required in most bioimage informatics applications. Notably, some particular problems, such as tracking of fibrous microtubule or neuronal structures, may be tackled using different methods, e.g. segmentation versus classification. Therefore, I only review the basic categories of key techniques, but explain very briefly or ignore those more complicated combinations of these basic categories, such as various techniques for modeling. Due to the length limitation, I will also have to skip the signal-processing techniques for biomedical images, such as attenuation correction, deconvolution (Heintzmann, <xref ref-type="bibr" rid="B49">2007</xref>), mixture model estimation, etc., as well as techniques that may be used for general scientific computing but not limited to bioimage informatics, such as supercomputing with particular computer architecture (Rao <italic>et al.</italic>, 2007).</p><sec id="SEC3.1"><title>3.1 Feature extraction and selection</title><p>Image features are the fundamental description of pixels/voxels and all higher level objects. Useful image features can correspond to statistical, geometrical, morphological properties and frequency of image pixels and regions, as well as the topological relationship of multiple image objects. Almost all bioimage-related studies rely on recognizing certain image features. For instance, points, edges, curves, corners, ridges, textures have been considered in analyzing (e.g. tracking) dynamic fluorescence images (Dorn <italic>et al.</italic>, <xref ref-type="bibr" rid="B31">2008</xref>).</p><p>One way to extract features is based on domain knowledge, as seen in the analyses of fruit fly embryogenesis <italic>in situ</italic> mRNA gene expression patterns. Local features based on Gaussian mixture model decomposition can be utilized to describe and compare gene expression patterns (Peng and Myers, <xref ref-type="bibr" rid="B96">2004</xref>). Global decomposition based on eigen-embryo analysis can be used for clustering these patterns (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B99">2006</xref>). Wavelet features that capture both global and local frequency properties of these patterns can be used to recognize these gene expression patterns and thus enable automatic annotation (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B100">2007</xref>; Zhou and Peng, <xref ref-type="bibr" rid="B128">2007</xref>). Other useful features, such as those obtained via independent component analysis (Pan <italic>et al.</italic>, <xref ref-type="bibr" rid="B91">2006</xref>) and invariant moments (Gurunathan <italic>et al.</italic>, <xref ref-type="bibr" rid="B45">2004</xref>), were also proposed. Another way for effective features extraction is to consider as many image transformations as possible, and thus generate a rich set of image features. For instance, Murphy <italic>et al.</italic> (<xref ref-type="bibr" rid="B88">2003</xref>) considered many features such as texture and moments to characterize the 3D protein location patterns associated with major subcellular organelles and structures. The WND-CHARM system (Orlov <italic>et al.</italic>, 2008) of multipurpose bioimage classification uses compound image features. Five types of features, including pixel statistics, textures, polynomial decompositions, high contrast features (e.g. object number, spatial distribution, size, shape, etc.), and standard image transforms (Fourier, wavelet, Chebyshev) were produced. These features together were used to classify image patterns. One problem with the rich feature set is that it may contain redundant features, which will degrade the performance of classifiers. The minimum-redundant maximum-relevant (mRMR) feature selection algorithm (Ding and Peng, <xref ref-type="bibr" rid="B30">2005</xref>; Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B98">2005b</xref>) has been used to determine an optimal set of least redundant features, yielding significantly improved recognition accuracy of gene expression patterns (Zhou and Peng, <xref ref-type="bibr" rid="B128">2007</xref>).</p></sec><sec id="SEC3.2"><title>3.2 Segmentation</title><p>Image segmentation is one of the most basic processing steps in many bioimage informatics applications. While the goal is simply to segment out the meaningful objects of interest in the respective image, this task is non-trivial in many cases. Very complicated cases also exist due to problems such as a low signal&#x02013;noise ratio and a big variability of image objects. Remarkably, bioimage segmentation strongly depends on the features used. For example, for chromatin composition, texture features can be used, whereas for nuclear morphology, the concavity features may be considered.</p><p>Practically speaking it seems intuitive to categorize image segmentation methods for molecular and cellular images based on the overall shape of an image object. One class of segmentation problems is to segment globular objects such as nuclei/cells in 2D or 3D images of cell-based assay, where nuclear compartment may be fluorescently labeled for localization of molecules. Several widely used methods, e.g. globular-template-based segmentation, watershed segmentation, Gaussian mixture model estimation and active contour/snake methods, which can be further improved by considering different shape or intensity cues of the objects (Cong and Parvin, <xref ref-type="bibr" rid="B28">1999</xref>; Han <italic>et al.</italic>, <xref ref-type="bibr" rid="B47">2007</xref>; Lin <italic>et al.</italic>, <xref ref-type="bibr" rid="B64">2003</xref>, <xref ref-type="bibr" rid="B65">2005</xref>; Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B73">2007c</xref>; Parvin <italic>et al.</italic>, <xref ref-type="bibr" rid="B92">2002</xref>). Gradient information will also provide useful cues in some cases (Li <italic>et al.</italic>, <xref ref-type="bibr" rid="B61">2007</xref>). Model-based merging was considered to reduce the over-segmentation (Lin <italic>et al.</italic>, <xref ref-type="bibr" rid="B65">2005</xref>; Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B73">2007c</xref>). Note that sometimes the globular object segmentation could be very tricky, due to the irregular stains of the objects. For example, for a DAPI-stained nucleus, its nucleolus (or nucleoli) may not be stained. As a result, the nucleus will appear to be hollow. This requires special processing such as hole filling before applying the watershed (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B73">2007c</xref>). Watershed segmentation has also been used for EM image segmentation where the object morphology is irregular and very complicated (Y. Mishchenko, personal communication).</p><p>Non-globular object segmentation is often more complicated. One problem of interest is the tracing of neurons in optical images. Some of the latest developments were discussed earlier in <xref ref-type="sec" rid="SEC2.4">Section 2.4</xref>. Generally, local search and fitting methods, such as the directional kernels (Al-Kofahi <italic>et al.</italic>, <xref ref-type="bibr" rid="B4">2002</xref>), <xref ref-type="bibr" rid="B5">2003</xref>) have been found effective. Some of these techniques have been commercialized in neuroanatomical analysis software such as Neurolucida (<ext-link ext-link-type="uri" xlink:href="http://www.mbfbioscience.com">http://www.mbfbioscience.com</ext-link>). Other available tools include the ImageJ plugin NeuronJ (Meijering <italic>et al.</italic>, <xref ref-type="bibr" rid="B82">2004</xref>), NeuriteTracer (Longair, <xref ref-type="bibr" rid="B75">2008</xref>).</p><p>Image object tracking in fluorescent time-lapse images is another well-studied topic that relies on image segmentation. Many pieces of related work were discussed in <xref ref-type="sec" rid="SEC2.3">Section 2.3</xref>.</p></sec><sec id="SEC3.3"><title>3.3 Registration</title><p>Bioimage registration is essential in many applications that need to compare multiple image subjects of different conditions. Quantitative measurements and visualization of comparing patterns in the registered images can be done directly in a &#x02018;standard&#x02019; space. Image registration was used in applications such as building the brain atlases (Carson <italic>et al.</italic>, <xref ref-type="bibr" rid="B24">2005</xref>; Ng <italic>et al.</italic>, <xref ref-type="bibr" rid="B90">2007</xref>; Toga and Thompson, <xref ref-type="bibr" rid="B116">2001</xref>), comparison of neuron morphology and gene expression patterns in fruit fly (Ahammad <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">2005</xref>; Jefferis <italic>et al.</italic>, <xref ref-type="bibr" rid="B55">2007</xref>; H. Peng <italic>et al.</italic>, unpublished data), cardiac imaging of Zebrafish embryos (Liebling <italic>et al.</italic>, 2005), standardization of <italic>C.elegans</italic> images (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B101">2008a</xref>). <xref ref-type="fig" rid="F3">Figure 3</xref> shows one example of the 3D registered fruit fly nervous system, where different GAL4 neuronal patterns highlighted in different colors are mapped into a &#x02018;standard&#x02019; space (H. Peng <italic>et al.</italic>, unpublished data). Many of the 2D and 3D image registration methods proposed for medical image analysis, such as the mutual information registration (Volla and Wells, 1997), spline-based elastic registration (Rohr <italic>et al.</italic>, <xref ref-type="bibr" rid="B104">2003</xref>), invariant moment feature-based registration (Shen and Davatzikos, <xref ref-type="bibr" rid="B109">2002</xref>), congealing registration (Miller, <xref ref-type="bibr" rid="B85">2006</xref>; Zollei <italic>et al.</italic>, <xref ref-type="bibr" rid="B129">2005</xref>), etc., can be extended to align the molecular and cellular images. However, due to the great complexity and variation of patterns, the big volume of images, (e.g. 2048&#x02009;&#x000d7;&#x02009;2048&#x02009;&#x000d7;&#x02009;300 pixels), and a low signal&#x02013;noise ratio, 3D bioimage registration remains very challenging in general.
<fig id="F3" position="float"><label>Fig. 3.</label><caption><p>Maximum projection of 3D registered and overlaid neuronal patterns of multiple fruit fly central complexes (top) and thoracic ganglia (bottom), each with a different GAL4 line (Peng <italic>et al.</italic>, unpublished data). Red: a205; Green: EB1; Cyan: NP2320; Yellow: NP6510; gray: NC82-labeled neuropil. Raw confocal images were produced by Julie Simpson and Phuong Chung.</p></caption><graphic xlink:href="btn346f3"/></fig></p><p>Image registration will also help to produce a panoramic scene of the 2D or 3D images that correspond to tiles of tissues. This is often called montaging or tiling. In serial EM, many physical sections are generated for imaging. Each section may also be imaged as many overlapping tiles. Hence, there are two alignment problems: first, stitching all corresponding tiles into a complete single picture, and second, aligning adjacent sections if they have different orientations and deformations (e.g. stretch, shear, compression) introduced during sample preparation stages such as sectioning and fixation/dehydration/embedding. The first alignment problem can be solved via maximizing the cross-correlation of overlapping regions of neighboring tiles. The second alignment problem can be solved via finding a global 2D affine transformation for adjacent sections, followed by slight local non-linear deformation. Many previous tutorials provide the details (Szeliski, <xref ref-type="bibr" rid="B115">2006</xref>).</p><p>Sometimes registration needs to be considered in the domain of extracted image objects, besides aforementioned pixel-domain image alignment. For fruit fly blastoderm embryos, each nucleus can be described using a point in the 3D space. Point cloud registration method was used to generate a virtual fruit fly embryo (Fowlkes <italic>et al.</italic>, <xref ref-type="bibr" rid="B36">2008</xref>). The fairly broad expression patterns of the reference markers, such as the transcriptional factor <italic>evenskipped</italic> which is expressed as seven stripes around an embryo, and the non-trivial variation of the number of nuclei (in the &#x000b1;10% range), make it difficult to achieve the single nucleus accuracy for the registered point clouds. For <italic>C.elegans</italic> and the embryonic central nervous system of fruit fly, both the single-cell-level automatic cell recognition technique (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B74">2008</xref>) and 3D annotation tool WANO (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B102">2008b</xref>) have been developed to determine the identities of cells/nuclei and produce digital point-cloud atlases at single-cell/nucleus resolution.</p></sec><sec id="SEC3.4"><title>3.4 Clustering, classification and annotation</title><p>Many applications such as phenotyping cells and determination of subcellular locations of proteins require the pattern clustering and classification techniques (Arif and Rajpoot, <xref ref-type="bibr" rid="B11">2007</xref>; Chen <italic>et al.</italic>, <xref ref-type="bibr" rid="B27">2006</xref>; Newberg and Murphy, <xref ref-type="bibr" rid="B89">2008</xref>). Multiresolution classification of HeLa cells was proposed (Chebira <italic>et al.</italic>, <xref ref-type="bibr" rid="B26">2007</xref>). Graph-partition-based clustering, such as the minimum-spanning-tree-cut (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B99">2006</xref>), was used to group potentially <italic>in situ</italic> mRNA expression patterns of co-regulated genes and thus to detect sequence motifs (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B100">2007</xref>). Pattern classification can also help other processing and analysis tasks, for instance the watershed segmentation and grouping of over-segmented objects (Lin <italic>et al.</italic>, <xref ref-type="bibr" rid="B65">2005</xref>; Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B73">2007c</xref>). Automatic determination of cell identities (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B74">2008</xref>) is also developed, which uses both the absolute 3D location of cells and their relative location patterns to determine the identities of cells. This technique is essential for both high-throughput measuring gene expression level at the single-cell level and manipulating single cells based on optogenetic methods. Cell identity tracking can also be combined with temporal information, as shown in the work to trace lineage of dividing embryonic cells of <italic>C.elegans</italic> (Bao <italic>et al.</italic>, <xref ref-type="bibr" rid="B15">2006</xref>).</p><p>Annotation of bioimage objects converts the image content information to concrete semantically meaningful information that is usually texts and can be conveniently organized and searched. This task is often accomplished manually, such as the anatomical and ontological annotation of the gene expression patterns collected for about 5000 fruit fly genes in BDGP database (<ext-link ext-link-type="uri" xlink:href="www.fruitfly.org">www.fruitfly.org</ext-link>). Automatic annotation of bioimage patterns has begun to be studied (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B100">2007</xref>; Zhou and Peng, <xref ref-type="bibr" rid="B128">2007</xref>). Bioimage patterns could correspond to many (e.g. 100 or more) anatomical and ontological annotation terms. Thus this problem can be formulated as pattern classification with hundreds of mutually non-exclusive classes, which falls outside of the framework of conventional multiclass classification that involves a much smaller number (e.g. 10) of mutually exclusive classes. This challenging annotation problem can be solved via parallel classifiers, each performing a bi-classification to indicate if a specific target annotation term should be assigned to the image pattern or not (Zhou and Peng, <xref ref-type="bibr" rid="B128">2007</xref>).</p></sec><sec id="SEC3.5"><title>3.5 Indexing and retrieval</title><p>Currently there are two ways to access the bioimage data in databases. The prevailing method is to provide and organize the text descriptors. These metadata are indexed and thus searchable. They serve as the proxy to find the real image data. Existing relational database indexing and searching techniques can be used. Comparison of biological image patterns is often complicated due to the lack of standards in nomenclature; therefore, it will be a big advantage if annotations stored in a bioimage database are organized based on the controlled/standard ontological vocabulary. The web-based annotation system for fruit fly gene expression patterns in BDGP (Tomancak <italic>et al.</italic>, <xref ref-type="bibr" rid="B117">2002</xref>) provides a set of controlled ontological words used by the curator to assign to an image displayed. Of note, techniques of biomedical ontology and semantic web techniques (<ext-link ext-link-type="uri" xlink:href="www.semanticweb.org">www.semanticweb.org</ext-link>) can be naturally blended into bioimage databases. New ontology systems were introduced, e.g. subcellular anatomy of the nervous system (Larson <italic>et al.</italic>, <xref ref-type="bibr" rid="B59">2007</xref>).</p><p>The second way is to enable content-based access of the image data in term of raw and processed data. Comparing image patterns requires aforementioned feature extraction, selection and data clustering and classification methods. Various distance metrics, such as Euclidean distances and the earth mover's distance (EMD) (Peleg <italic>et al.</italic>, <xref ref-type="bibr" rid="B95">1989</xref>), can be considered. Recent work (Ljosa <italic>et al.</italic>, <xref ref-type="bibr" rid="B70">2006</xref>) shows that a multiresolution LB-index approach can be used to index the EMD scores. Lower bounds were derived to compute EMD at various resolutions. This approach led to faster similarity query than conventional methods for a database of fluorescent confocal retina images consisting of microglial cells and blood vessels. Query and retrieval on the probability density functions, which may be modeled by adaptive-piecewise-linear approximations, have been developed (Ljosa and Singh, <xref ref-type="bibr" rid="B69">2007</xref>).</p></sec><sec id="SEC3.6"><title>3.6 Visualization</title><p>Bioimage visualization is a subfield of the general scientific data visualization. The widely used techniques for both the original and processed bioimages are volume, surface, flow visualization. Tools for interactive processing and visualization of images for protein surfaces, retinal optical coherence tomographic data and gene expression images of early stage fruit fly embryogenesis were recently developed (Staadt <italic>et al.</italic>, 2007). Scalable volume visualization was used to study cell lineage and gene expression of developing <italic>C.elegans</italic> embryos (Cedilnik <italic>et al.</italic>, <xref ref-type="bibr" rid="B25">2007</xref>). On the other hand, immersive visualization systems, where a user walks into the data volume/model, may enable one to analyze the data like playing a video game. A few systems, such as NCMIR's <italic>ATLAS in silico</italic> system that utilizes CalIT2&#x02019;s 100-million-pixel autosterographic display (West, <xref ref-type="bibr" rid="B123">2007</xref>), the ImmersaDesk<sup>TM</sup> system (Ai <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2005</xref>), etc., support such immersive visualization, which requires virtual reality methods.</p></sec></sec><sec id="SEC4"><title>4 AVAILABLE TOOLS</title><p>Many tools have been developed for various aspects of the above techniques as well as applications. Some popular tools are summarized below.</p><sec id="SEC4.1"><title>4.1 Image formats and I/O</title><p>Microscope vendors use different file formats to store their raw image data. In addition, users may add customary metadata/tags to the raw or processed images. It is very useful to be able to read, write and convert different file formats. ImageJ (<ext-link ext-link-type="uri" xlink:href="http://rsb.info.nih.gov/ij/">http://rsb.info.nih.gov/ij/</ext-link>, Abramoff <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">2004</xref>), empowered by a number of free codes/plugins contributed by volunteers, has the ability to read and write a number of bioimage file formats, such as the Bio-rad PIC file, Zeiss LSM file and others.</p><p>Embedding the reading/writing engines of different bioimage formats in one's own code is also desirable. One useful standalone Java library for importing/exporting various bioimage data is Bio-Formats (<ext-link ext-link-type="uri" xlink:href="http://www.loci.wisc.edu/ome/formats.html">http://www.loci.wisc.edu/ome/formats.html</ext-link>). It can be used in ImageJ, Matlab, etc. With the ability to parsing both pixels and metadata for a large number of formats, it finds a range of applications in the bioimage informatics. Sometimes these images, such as the Zeiss LSM files, are variants of the TIFF images, therefore can be handled using the open-source libtiff library (<ext-link ext-link-type="uri" xlink:href="http://www.libtiff.org/">http://www.libtiff.org/</ext-link>).</p></sec><sec id="SEC4.2"><title>4.2 Image analysis tools</title><p>ImageJ (<ext-link ext-link-type="uri" xlink:href="http://rsb.info.nih.gov/ij/">http://rsb.info.nih.gov/ij/</ext-link>, Abramoff <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">2004</xref>) is a Java-based cross-platform tool for biomedical image processing and measurement. A number of image analysis toolboxes such as fluorophore tracking, filament detection, etc., were developed by various groups (Unser, <xref ref-type="bibr" rid="B120">2008</xref>). ImageJ is not only useful for daily use to view and small-scale analysis of images, but can also be deployed to run large-scale analysis in batch.</p><p>ITK (<ext-link ext-link-type="uri" xlink:href="www.itk.org">www.itk.org</ext-link>, (Yoo <italic>et al.</italic>, <xref ref-type="bibr" rid="B125">2002</xref>) provides a number of image segmentation and registration functions. In this category similar tools include the Matlab image-processing toolbox and other third party toolbox such as the DIPimage toolbox (<ext-link ext-link-type="uri" xlink:href="www.diplib.org">www.diplib.org</ext-link>).</p><p>More and more sophisticated bioimage analysis tasks need tools to perform heavy duty image tasks such as 3D registration of animals&#x02019; brains, 3D automatic neuron tracing, etc. Several projects are currently underway, such as V3D (H. Peng <italic>et al.</italic>, unpublished data), which tries to integrate a suite of convenient 3D image segmentation, registration, standardization and visualization tools to improve the efficiency of the workflow. Several labs have begun to use the alpha test version of V3D to study the fruit fly nervous systems at embryonic, larval and adult developmental stages. ZFIQ (Zebrafish Image Quantitator) (Liu <italic>et al.</italic>, <xref ref-type="bibr" rid="B66">2008</xref>) is another toolkit, which provides a set of image analysis tools for quantitative, reproducible and accurate interpretation of zebrafish imaging data. Cell-ID (Gordon <italic>et al.</italic>, <xref ref-type="bibr" rid="B43">2007</xref>), an open-source cell finding and tracking package, was developed first for yeast cells, can be used for other regularly shaped cells as well. Other useful analysis packages include CellProfiler (Carpenter <italic>et al.</italic>, <xref ref-type="bibr" rid="B23">2006</xref>; Lamprecht <italic>et al.</italic>, <xref ref-type="bibr" rid="B58">2007</xref>), STARRYNITE (Bao <italic>et al.</italic>, <xref ref-type="bibr" rid="B15">2006</xref>), Neuron Image Quantitator (neuroniq.cbi-platform.net) and those listed at the NCMIR site (<ext-link ext-link-type="uri" xlink:href="http://ncmir.ucsd.edu/downloads/software">http://ncmir.ucsd.edu/downloads/software</ext-link>).</p></sec><sec id="SEC4.3"><title>4.3 Database and annotation tools</title><p>OME (Open Microscopy Environment) (openmicroscopy.org) (Swedlow <italic>et al.</italic>, <xref ref-type="bibr" rid="B113">2003</xref>) is a microscopic image and metadata management system. It is divided into several parts, the OME server, which implements image-based analysis or cellular localization and phenotypes, as well as an OME-XML schema language, and OMERO, which is a suite of java-based tools for data storage, management and annotation.</p><p>The UCSB Bisque system (<ext-link ext-link-type="uri" xlink:href="http://dough.ece.ucsb.edu/bisquik/">http://dough.ece.ucsb.edu/bisquik/</ext-link>) provides an integrated online environment for users to upload, search, edit and annotate images. It also includes a few analysis and visualization modules.</p><p>Several other systems can also build images database and manage tens of thousands of images and associated metadata entries in a scalable way; examples include XNAT (Extensible Neuroimaging Archive Toolkit, <ext-link ext-link-type="uri" xlink:href="www.xnat.org">www.xnat.org</ext-link>) (Marcus <italic>et al.</italic>, <xref ref-type="bibr" rid="B78">2007</xref>), Biotrue CDMS (<ext-link ext-link-type="uri" xlink:href="www.biotrue.net">www.biotrue.net</ext-link>) and Axiope e-CAT (<ext-link ext-link-type="uri" xlink:href="www.axiope.com">www.axiope.com</ext-link>).</p><p>Annotating segmented image objects in 3D is another interesting topic. One tool available is WANO (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B102">2008b</xref>), <ext-link ext-link-type="uri" xlink:href="http://research.janelia.org/peng/proj/wano/index.html">http://research.janelia.org/peng/proj/wano/index.html</ext-link>), a QT-based cross-platform 3D annotator, which provides a spreadsheet of all segmented 3D-image objects linked to both the 3D view of the raw image and that of the segmentation mask. WANO enables a user to quickly add or edit the annotations such as cell names/properties in images, as well as editing the segmentation results such as adding or removing segmented objects. This tool has been used to build digital atlases of <italic>C.elegans</italic> and fruit fly (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B72">2007b</xref>).</p></sec><sec id="SEC4.4"><title>4.4 Visualization tools</title><p>For visualization of multidimensional multicolor images, such as confocal image stacks, commercially available products include Amira (Mercury), Volocity (Improvision), etc. Free visualization tools include Voxx (<ext-link ext-link-type="uri" xlink:href="www.nephrology.iupui.edu/imaging/voxx/">www.nephrology.iupui.edu/imaging/voxx/</ext-link>), Chimera (<ext-link ext-link-type="uri" xlink:href="www.cgl.ucsf.edu/chimera/">www.cgl.ucsf.edu/chimera/</ext-link>), Volume Rover (cvcweb. <ext-link ext-link-type="uri" xlink:href="ices.utexas.edu/software/">ices.utexas.edu/software/</ext-link>), many ImageJ plugins, etc. Blender (<ext-link ext-link-type="uri" xlink:href="http://www.blender.org/">http://www.blender.org/</ext-link>) is often considered in rendering models.</p><p>For displaying and browsing large 2D/3D image set such as the stitched EM sections, each of which could easily exceed the size 100 000 pixels by 100 000 pixels, some tools such as Zoomify (<ext-link ext-link-type="uri" xlink:href="http://www.zoomify.com/">http://www.zoomify.com/</ext-link>) and HDView (Microsoft) can be used to build the atlas view of a big image, similar to the Google map.</p><p>To develop visualization systems, many studies have relied on VTK (<ext-link ext-link-type="uri" xlink:href="www.vtk.org">www.vtk.org</ext-link>), which provides multilanguage interfaces to a rich set of visualization functions. For heavy-duty visualization tasks such as large volume rendering, people may consider using OpenGL or even GPU programming directly. For building of cross-platform GUI, QT (<ext-link ext-link-type="uri" xlink:href="http://trolltech.com/products/qt">http://trolltech.com/products/qt</ext-link>) and Java are often considered.</p></sec></sec><sec id="SEC5"><title>5 OTHER RESOURCES</title><sec id="SEC5.1"><title>5.1 Bench test datasets</title><p>There are a number of bioimage databases available for various model organisms, including for example: the Allen Brain Atlas database (<ext-link ext-link-type="uri" xlink:href="www.brain-map.org">www.brain-map.org</ext-link>) with genome-wide <italic>in situ</italic> gene expression patterns for the mouse brain; the interactive and multiresolution database for scanned and annotated images of serial sections of both primate and non-primate brains (Brainmaps.org); the BDGP database (<ext-link ext-link-type="uri" xlink:href="www.fruitfly.org">www.fruitfly.org</ext-link>) containing <italic>in situ</italic> embryogenesis gene expression patterns of about 5000 fruit fly genes; the GFP expression pattern database for <italic>C.elegans</italic> (gfpworm.org) and the ZFin FishNet (<ext-link ext-link-type="uri" xlink:href="www.fishnet.org.au">www.fishnet.org.au</ext-link>, Bryson-Richardson, 2007) that is a 3D database of zebrafish development from the early embryo to adult.</p><p>For different disciplines, there are also many established databases, such as the 3D neuronal structure database Neuromorpho (neuromorpho.org) (Ascoli, <xref ref-type="bibr" rid="B12">2006</xref>), which arranges the neuronal structures based on animal species, brain regions, neuron types, research labs, etc., and also provides useful neuron structure measuring, comparison and visualization tools. Similarly useful databases include CCDB (ccdb.ucsd.edu), which provides a venue for sharing and mining cellular and subcellular data derived from light and electron microscopy, including correlated imaging. CCDB provides the raw data, reconstructed and segmented data for download and includes 2D images and animations. Another interesting database is PSLID (pslid.cbi.cmu.edu), a database of protein subcellular location images. This database collects 2D through 5D fluorescence microscope images, annotations and derived features in a relational schema. There are also efforts to establish some general bench test datasets. Some authors have contributed data for the OME bench test database currently with about 10 datasets (ome.grc.nia.nih.gov/iicbu2008/). The Biomedical Informatics Research Network (BIRN, <ext-link ext-link-type="uri" xlink:href="www.nbirn.net">www.nbirn.net</ext-link>) is a multisite collaboration to facilitate data sharing of different labs; biomedical images and associated metadata of various animal models are available for downloading.</p></sec><sec id="SEC5.2"><title>5.2 Conferences, special issues and books</title><p>There is an increasing interest for research meetings in this new area. The 2005 Bioimage Informatics meeting was held at Stanford University (bioimageinformatics.org). The 2008 meeting at UC Santa Barbara attracted about 150 frontier researchers in this field. The upcoming conference in 2009 will be held at Janelia Farm Research Campus, Howard Hughes Medical Institute. Many other events include workshops on Microscopic Image Analysis with Applications in Biology (miaab.org), several workshops related to bioimage analysis in the annual IEEE ISBI conferences (biomedicalimaging.org), NIST workshop on 2D/3D image content representation, analysis and retrieval (<ext-link ext-link-type="uri" xlink:href="www.nist.gov">www.nist.gov</ext-link>), etc.</p><p>There are several special issues of journals and books on the topics of bioimage informatics, molecular and cellular image analysis, etc. BMC Cell Biology published a special issue in 2007 (<ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2121/8?issue=S1">http://www.biomedcentral.com/1471-2121/8?issue=S1</ext-link>), including nine papers covering new image analysis and mining algorithms, data visualization, biological applications, enabling supercomputing techniques, and computer vision and machine learning methods to solve other biology problems. It also includes a short summary of the bioimage informatics challenges (Auer <italic>et al.</italic>, <xref ref-type="bibr" rid="B13">2007</xref>), including the demand for bioimage informatics techniques, the need of multiscale imaging, collaboration and communication between biologists and engineers, common bioimage informatics problems and bench test datasets and modeling. Other special editions include for example the IEEE Transactions on Image Processing 2005 special issue on Molecular and Cellular Bioimaging (edited by Murphy, R, Meijering, E. and Danuser, G.), etc. Artech Publishing House is going to publish a book on the Microscopic Image Analysis for Life Science Applications in 2008 (edited by Rittscher, J., Machiraju, R. and Wong, S.).</p></sec></sec><sec id="SEC6"><title>6 DISCUSSIONS AND CONCLUSION</title><p>While in the earlier sections, the molecular and cellular images are emphasized, many of the techniques can be used for other biological image or video data. Characterizing the behaviors of living animals in videos relies on a similar set of tracking techniques to phenotyping and tracking microtubule activities. Recent developments include tracking of <italic>C.elegans</italic>, fruit fly, mouse and fish (Armstrong, 2005; Branson and Belongie, <xref ref-type="bibr" rid="B19">2005</xref>; Fontaine <italic>et al.</italic>, <xref ref-type="bibr" rid="B34">2007</xref>; Fontaine <italic>et al.</italic>, <xref ref-type="bibr" rid="B35">2008</xref>; Fry <italic>et al.</italic>, <xref ref-type="bibr" rid="B37">2003</xref>; Geng <italic>et al.</italic>, <xref ref-type="bibr" rid="B39">2004</xref>); R. Kerr, personal communication; (Roussel <italic>et al.</italic>, <xref ref-type="bibr" rid="B105">2007</xref>; Tsechpenakis <italic>et al.</italic>, <xref ref-type="bibr" rid="B118">2007</xref>). Other examples, include the analysis of gel and microarray images (Angulo and Serra, <xref ref-type="bibr" rid="B10">2003</xref>; Jung and Cho, <xref ref-type="bibr" rid="B57">2002</xref>; White <italic>et al.</italic>, 2005; Young <italic>et al.</italic>, <xref ref-type="bibr" rid="B126">2004</xref>), etc.</p><p>Remarkably bioimage computing methods are also demanded to improve the quality and throughput of novel digital imaging techniques, e.g. the super-resolution PALM (Betzig <italic>et al.</italic>, <xref ref-type="bibr" rid="B16">2006</xref>) and correlative microscopy (Grabenbauer <italic>et al.</italic>, <xref ref-type="bibr" rid="B44">2005</xref>; Robinson <italic>et al.</italic>, <xref ref-type="bibr" rid="B103">2001</xref>). It is also possible to adaptively acquire fluorescence microscopic images with consideration of image classification accuracy (Merryman and Kova&#x0010d;evi&#x00107;, <xref ref-type="bibr" rid="B84">2005</xref>).</p><p>The ultimate evaluation standard of bioimage informatics is how these computational techniques can be used to enhance our understanding of the biological entities and ability to solve the respective problems. With a number of new computing tools and databases that are increasingly shared by different research labs, this new engineering biology field will see a boom in the coming years.</p></sec>
<sec sec-type="supplementary-material">
<title>Supplementary Material</title>
<supplementary-material id="PMC_1" content-type="local-data">
<caption>
<title>[Supplementary Data]</title>
</caption>
<media mimetype="text" mime-subtype="html" xlink:href="btn346_index.html"/>
<media xlink:role="associated-file" mimetype="image" mime-subtype="tiff" xlink:href="btn346_bioinf-2008-0889-File002.tif"/>
</supplementary-material>
</sec>
</body><back><ack><title>ACKNOWLEDGEMENTS</title><p>I thank Fuhui Long, Yuriy Mishchenko, Ting Zhao and the Associate Editor Jonathan Wren for all the suggestions, comments and criticisms that help improve the article significantly, Margaret Jefferies for improvement of the technical writing. I also thank Badrinath Roysam for providing <xref ref-type="fig" rid="F1">Figure 1</xref>, Julie Simpson and Phuong Chung for generating the raw images used for <xref ref-type="fig" rid="F3">Figure 3</xref>, and the anonymous reviewers for suggesting several references.</p><p><italic>Conflict of Interest</italic>: none declared.</p></ack><ref-list><title>REFERENCES</title><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Abramoff</surname><given-names>MD</given-names></name><etal/></person-group><article-title>Image processing with ImageJ</article-title><source>Biophoto. Int.</source><year>2004</year><volume>11</volume><fpage>36</fpage><lpage>42</lpage></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ahammad</surname><given-names>P</given-names></name><etal/></person-group><article-title>Joint nonparametric alignment for analyzing spatial gene expression patterns in Drosophila imaginal discs</article-title><source>IEEE CVPR 2005</source><year>2005</year><volume>2</volume><fpage>20</fpage><lpage>25</lpage></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ai</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Reconstruction and exploration of three-dimensional confocal microscopy data in an immersive virtual environment</article-title><source>Comput. Med. Imaging Graph.</source><year>2005</year><volume>29</volume><fpage>313</fpage><lpage>318</lpage><pub-id pub-id-type="pmid">15893451</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Al-Kofahi</surname><given-names>K</given-names></name><etal/></person-group><article-title>Rapid automated three-dimensional tracing of neurons from confocal image stacks</article-title><source>IEEE Trans. Inf. Technol. Biomed.</source><year>2002</year><volume>6</volume><fpage>171</fpage><lpage>187</lpage><pub-id pub-id-type="pmid">12075671</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Al-Kofahi</surname><given-names>K</given-names></name><etal/></person-group><article-title>Median based robust algorithms for tracing neurons from noisy confocal microscope images</article-title><source>IEEE Trans. Inf. Technol. Biomed.</source><year>2003</year><volume>7</volume><fpage>302</fpage><lpage>317</lpage><pub-id pub-id-type="pmid">15000357</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Altinok</surname><given-names>A</given-names></name><etal/></person-group><article-title>Activity analysis in microtubule videos by mixture of hidden Markov models</article-title><source>IEEE CVPR</source><year>2006</year><volume>2</volume><fpage>1662</fpage><lpage>1669</lpage></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Altnok</surname><given-names>A</given-names></name><etal/></person-group><article-title>Model based dynamics analysis in live cell microtubule image</article-title><source>BMC Cell Biol.</source><year>2007</year><volume>8</volume><issue>Suppl. 1</issue><fpage>S4</fpage><pub-id pub-id-type="pmid">17634094</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Amanda</surname><given-names>M</given-names></name><etal/></person-group><article-title>Automated microarray image analysis toolbox for MATLAB</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>3578</fpage><lpage>3579</lpage><pub-id pub-id-type="pmid">16046497</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ando</surname><given-names>R</given-names></name><etal/></person-group><article-title>Regulated fast nucleocytoplasmic shuttling observed by reversible protein highlighting</article-title><source>Science</source><year>2004</year><volume>306</volume><fpage>1370</fpage><lpage>1373</lpage><pub-id pub-id-type="pmid">15550670</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Angulo</surname><given-names>J</given-names></name><name><surname>Serra</surname><given-names>J</given-names></name></person-group><article-title>Automatic analysis of DNA microarray images using mathematical morphology</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><fpage>553</fpage><lpage>562</lpage><pub-id pub-id-type="pmid">12651712</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Arif</surname><given-names>M</given-names></name><name><surname>Rajpoot</surname><given-names>N</given-names></name></person-group><article-title>Classification of potential nuclei in prostate histology images using shape manifold learning</article-title><source>IEEE Int. Conf. Machine Vision.</source><year>2007</year><fpage>113</fpage><lpage>118</lpage></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ascoli</surname><given-names>G</given-names></name></person-group><article-title>Mobilizing the base of neuroscience data: the case of neuronal morphologies</article-title><source>Nat. Rev. Neurosci.</source><year>2006</year><volume>7</volume><fpage>318</fpage><lpage>324</lpage><pub-id pub-id-type="pmid">16552417</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Auer</surname><given-names>M</given-names></name><etal/></person-group><article-title>Development of multiscale biological image data analysis: review of 2006 international workshop on multiscale biological imaging, data mining and informatics, Santa Barbara, USA (BII06)</article-title><source>BMC Cell Biol.</source><year>2007</year><volume>8</volume><issue>Suppl. 1</issue><fpage>S1</fpage><pub-id pub-id-type="pmid">17634090</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bakal</surname><given-names>C</given-names></name><etal/></person-group><article-title>Quantitative morphological signatures define local signaling networks regulating cell morphology</article-title><source>Science</source><year>2007</year><volume>316</volume><fpage>1753</fpage><lpage>1756</lpage><pub-id pub-id-type="pmid">17588932</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Automated cell lineage tracing in Caenorhabditis elegans</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2006</year><volume>103</volume><fpage>2707</fpage><lpage>2712</lpage><pub-id pub-id-type="pmid">16477039</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Betzig</surname><given-names>E</given-names></name><etal/></person-group><article-title>Imaging intracellular fluorescent proteins at nanometer resolution</article-title><source>Science</source><year>2006</year><volume>313</volume><fpage>1642</fpage><lpage>1645</lpage><pub-id pub-id-type="pmid">16902090</pub-id></citation></ref><ref id="B17"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bjornsson</surname><given-names>CS</given-names></name><etal/></person-group><article-title>Associative image analysis: a method for automated quantification of 3D multi-parameter images of brain tissue</article-title><source>J. Neurosci. Methods</source><year>2008</year><publisher-name>in press</publisher-name></citation></ref><ref id="B18"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bozzola</surname><given-names>J</given-names></name><name><surname>Russell</surname><given-names>LD</given-names></name></person-group><source>Electron Microscopy.</source><year>1999</year><edition>2nd edn.</edition><publisher-name>Jones &#x00026; Bartlett Publishers</publisher-name></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Belongie</surname><given-names>S</given-names></name></person-group><article-title>Tracking multiple mouse contours (without too many samples)</article-title><source>Proceedings of the IEEE CVPR 2005.</source><year>2005</year><fpage>1039</fpage><lpage>1046</lpage></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bryson-Richardson</surname><given-names>R</given-names></name><etal/></person-group><article-title>FishNet: an online database of zebrafish anatomy</article-title><source>BMC Biol.</source><year>2007</year><volume>5</volume><fpage>34</fpage><pub-id pub-id-type="pmid">17705855</pub-id></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>HA</given-names></name><name><surname>Granato</surname><given-names>M</given-names></name></person-group><article-title>Modulation of locomotor activity in larval zebrafish during light adaptation</article-title><source>J. Exp. Biol.</source><year>2007</year><volume>210</volume><fpage>2526</fpage><lpage>2539</lpage><pub-id pub-id-type="pmid">17601957</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>H</given-names></name><etal/></person-group><article-title>Repulsive force based snake model to segment and track neuronal axons in 3D microscopy image stacks</article-title><source>NeuroImage</source><year>2006</year><volume>32</volume><fpage>1608</fpage><lpage>1620</lpage><pub-id pub-id-type="pmid">16861006</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>AE</given-names></name><etal/></person-group><article-title>CellProfiler: image analysis software for identifying and quantifying cell phenotypes</article-title><source>Genome Biol.</source><year>2006</year><volume>7</volume><fpage>R100</fpage><pub-id pub-id-type="pmid">17076895</pub-id></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carson</surname><given-names>JP</given-names></name><etal/></person-group><article-title>A digital atlas to characterize the mouse brain transcriptome</article-title><source>PLoS Comp. Biol.</source><year>2005</year><volume>1</volume><fpage>e41</fpage></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cedilnik</surname><given-names>A</given-names></name><etal/></person-group><article-title>Integration of information and volume visualization for analysis of cell lineage and gene expression during embryogenesis</article-title><source>Proc. SPIE</source><year>2007</year><volume>6809</volume></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chebira</surname><given-names>A</given-names></name><etal/></person-group><article-title>A multiresolution approach to automated classification of protein subcellular location images</article-title><source>BMC Bioinformatics</source><year>2007</year><volume>8</volume><fpage>210</fpage><pub-id pub-id-type="pmid">17578580</pub-id></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><etal/></person-group><article-title>Automated segmentation, classification, and tracking of cancer cell nuclei in time-lapse microscopy</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2006</year><volume>53</volume><fpage>762</fpage><lpage>766</lpage><pub-id pub-id-type="pmid">16602586</pub-id></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cong</surname><given-names>G</given-names></name><name><surname>Parvin</surname><given-names>B</given-names></name></person-group><article-title>Model based segmentation of nuclei</article-title><source>IEEE CVPR'99.</source><year>1999</year><fpage>23</fpage><lpage>25</lpage></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Danuser</surname><given-names>G</given-names></name><etal/></person-group><article-title>Tracking differential interference contrast diffraction line images with nanometre sensitivity</article-title><source>J. Microsc.</source><year>2000</year><volume>198</volume><fpage>34</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">10781207</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>C</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><article-title>Minimum redundancy feature selection from microarray gene expression data</article-title><source>J. Bioinform. Comput. Biol.</source><year>2005</year><volume>3</volume><fpage>185</fpage><lpage>205</lpage><pub-id pub-id-type="pmid">15852500</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dorn</surname><given-names>JF</given-names></name><etal/></person-group><article-title>Computational processing and analysis of dynamic fluorescence image data</article-title><source>Methods Cell Biol.</source><year>2008</year><volume>85</volume><fpage>497</fpage><lpage>538</lpage><pub-id pub-id-type="pmid">18155477</pub-id></citation></ref><ref id="B32"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Dorr</surname><given-names>AE</given-names></name><etal/></person-group><article-title>High resolution three-dimensional brain atlas using an average magnetic resonance image of 40 adult C57Bl/6J mice</article-title><source>Neuroimage</source><year>2008</year><publisher-name>in press</publisher-name></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Echeverri</surname><given-names>CJ</given-names></name><name><surname>Perrimon</surname><given-names>N</given-names></name></person-group><article-title>High-throughput RNAi screening in cultured cells: a user's guide</article-title><source>Nat. Rev. Genet.</source><year>2006</year><volume>7</volume><fpage>373</fpage><lpage>384</lpage><pub-id pub-id-type="pmid">16607398</pub-id></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fontaine</surname><given-names>E</given-names></name><etal/></person-group><article-title>Model-based tracking of multiple worms and fish</article-title><year>2007</year><comment>In <italic>ICCV Workshop on Dynamical Vision</italic></comment></citation></ref><ref id="B35"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fontaine</surname><given-names>E</given-names></name><etal/></person-group><article-title>Automated visual tracking for studying the ontogeny of zebrafish swimming</article-title><source>J. Exp. Biol.</source><year>2008</year><volume>211</volume><fpage>1305</fpage><lpage>1316</lpage><pub-id pub-id-type="pmid">18375855</pub-id></citation></ref><ref id="B36"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fowlkes</surname><given-names>C</given-names></name><etal/></person-group><article-title>A quantitative spatiotemporal atlas of gene expression in the drosophila blastoderm</article-title><source>Cell</source><year>2008</year><volume>133</volume><fpage>364</fpage><lpage>374</lpage><pub-id pub-id-type="pmid">18423206</pub-id></citation></ref><ref id="B37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fry</surname><given-names>S</given-names></name><etal/></person-group><article-title>The aerodynamics of free-flight maneuvers in Drosophila</article-title><source>Science</source><year>2003</year><volume>300</volume><fpage>495</fpage><lpage>498</lpage><pub-id pub-id-type="pmid">12702878</pub-id></citation></ref><ref id="B38"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gelasca</surname><given-names>ED</given-names></name><etal/></person-group><article-title>Evaluation and benchmark for biological image segmentation</article-title><source>Proceedings of the IEEE ICIP 2008.</source><year>2008</year><publisher-loc>San Diego, CA</publisher-loc></citation></ref><ref id="B39"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>W</given-names></name><etal/></person-group><article-title>Automatic tracking, feature extraction and classification of C. elegans phenotypes</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2004</year><volume>51</volume><fpage>1811</fpage><lpage>1820</lpage><pub-id pub-id-type="pmid">15490828</pub-id></citation></ref><ref id="B40"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Giuliano</surname><given-names>K</given-names></name><etal/></person-group><article-title>Advances in high content screening for drug discovery</article-title><source>Assay Drug Dev. Technol.</source><year>2003</year><volume>1</volume><fpage>565</fpage><lpage>577</lpage><pub-id pub-id-type="pmid">15090253</pub-id></citation></ref><ref id="B41"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>JR</given-names></name><name><surname>Glaser</surname><given-names>EM</given-names></name></person-group><article-title>Neuron imaging with Neurolucida &#x02013; a PC-based system for image combining microscopy</article-title><source>Comput. Med. Imaging Graph.</source><year>1990</year><volume>14</volume><fpage>307</fpage><lpage>317</lpage><pub-id pub-id-type="pmid">2224829</pub-id></citation></ref><ref id="B42"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Glory</surname><given-names>E</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><article-title>Automated subcellular location determination and high throughput microscopy</article-title><source>Dev. Cell</source><year>2007</year><volume>12</volume><fpage>7</fpage><lpage>16</lpage><pub-id pub-id-type="pmid">17199037</pub-id></citation></ref><ref id="B43"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>A</given-names></name><etal/></person-group><article-title>Single-cell quantification of molecules and rates using open-source microscope-based cytometry</article-title><source>Nat. Methods.</source><year>2007</year></citation></ref><ref id="B44"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grabenbauer</surname><given-names>M</given-names></name><etal/></person-group><article-title>Correlative microscopy and electron tomography of GFP through photooxidation</article-title><source>Nat. Methods</source><year>2005</year><volume>2</volume><fpage>857</fpage><lpage>862</lpage><pub-id pub-id-type="pmid">16278657</pub-id></citation></ref><ref id="B45"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gurunathan</surname><given-names>R</given-names></name><etal/></person-group><article-title>Identifying spatially similar gene expression patterns in early stage fruit fly embryo images: binary feature versus invariant moment digital representations</article-title><source>BMC Bioinformatics</source><year>2004</year><volume>5</volume><fpage>202</fpage><pub-id pub-id-type="pmid">15603586</pub-id></citation></ref><ref id="B46"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hadjidemetriou</surname><given-names>S</given-names></name><etal/></person-group><article-title>Automatic quantification of microtubule dynamics</article-title><source>Proceedings of the IEEE ISBI 2004.</source><year>2004</year></citation></ref><ref id="B47"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>J</given-names></name><etal/></person-group><article-title>Segmentation of mammosphere structures from volumetric data</article-title><source>IEEE ISBI 2007.</source><year>2007</year><fpage>524</fpage><lpage>527</lpage></citation></ref><ref id="B48"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Heim</surname><given-names>R</given-names></name><etal/></person-group><article-title>Improved green fluorescence</article-title><source>Nature</source><year>1995</year><volume>373</volume><fpage>663</fpage><lpage>664</lpage><pub-id pub-id-type="pmid">7854443</pub-id></citation></ref><ref id="B49"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Heintzmann</surname><given-names>R</given-names></name></person-group><article-title>Estimating missing information by maximum likelihood deconvolution</article-title><source>Micron</source><year>2007</year><volume>38</volume><fpage>136</fpage><lpage>144</lpage><pub-id pub-id-type="pmid">16914319</pub-id></citation></ref><ref id="B50"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hell</surname><given-names>SW</given-names></name></person-group><article-title>Toward fluorescence nanoscopy</article-title><source>Nat. Biotechnol.</source><year>2003</year><volume>21</volume><fpage>1347</fpage><lpage>1355</lpage><pub-id pub-id-type="pmid">14595362</pub-id></citation></ref><ref id="B51"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Heward</surname><given-names>JA</given-names></name><etal/></person-group><article-title>flyTracker: real-time analysis of insect courtship</article-title><source>Proceedings of Measuring Behavior 2005, 5th International Conference on Methods and Techniques in Behavioral Research</source><year>2005</year><publisher-loc>The Netherlands</publisher-loc><publisher-name>Wageningen</publisher-name><fpage>409</fpage><lpage>410</lpage><comment>August 30&#x02013;September 2 2005.</comment></citation></ref><ref id="B52"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>P</given-names></name></person-group><article-title>Interactive analysis of high-content cellular images via relevant feedback</article-title><year>2006</year><publisher-loc>CA, USA</publisher-loc><publisher-name>Santa Barbara</publisher-name></citation></ref><ref id="B53"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>V</given-names></name><etal/></person-group><article-title>Supervised learning of image restoration with convolutional networks</article-title><source>ICCV 2007.</source><year>2007</year></citation></ref><ref id="B54"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jaqaman</surname><given-names>K</given-names></name><etal/></person-group><article-title>Phenotypic clustering of yeast mutants based on kinetochore microtubule dynamics</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>1666</fpage><lpage>1673</lpage><pub-id pub-id-type="pmid">17483508</pub-id></citation></ref><ref id="B55"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jefferis</surname><given-names>GS</given-names></name><etal/></person-group><article-title>Comprehensive maps of Drosophila higher olfactory centers: spatially segregated fruit and pheromone representation</article-title><source>Cell</source><year>2007</year><volume>128</volume><fpage>1187</fpage><lpage>1203</lpage><pub-id pub-id-type="pmid">17382886</pub-id></citation></ref><ref id="B56"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>M</given-names></name><etal/></person-group><article-title>Automated extraction of microtubules and their plus-ends</article-title><source>IEEE Workshop on Applications of Computer Vision.</source><year>2005</year><fpage>336</fpage><lpage>341</lpage></citation></ref><ref id="B57"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>H.-Y</given-names></name><name><surname>Cho</surname><given-names>H.-G</given-names></name></person-group><article-title>An automatic block and spot indexing with k-nearest neighbors graph for microarray image analysis</article-title><source>Bioinformatics</source><year>2002</year><volume>18</volume><fpage>S141</fpage><lpage>S151</lpage><pub-id pub-id-type="pmid">12385996</pub-id></citation></ref><ref id="B58"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lamprecht</surname><given-names>MR</given-names></name><etal/></person-group><article-title>CellProfiler: free, versatile software for automated biological image analysis</article-title><source>Biotechniques</source><year>2007</year><volume>42</volume><fpage>71</fpage><lpage>75</lpage><pub-id pub-id-type="pmid">17269487</pub-id></citation></ref><ref id="B59"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Larson</surname><given-names>SD</given-names></name><etal/></person-group><article-title>A formal ontology of subcellular neuroanatomy</article-title><source>Front. Neuroinform</source><year>2007</year><volume>1</volume><fpage>3</fpage></citation></ref><ref id="B60"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lein</surname><given-names>E</given-names></name><etal/></person-group><article-title>Genome-wide atlas of gene expression in the adult mouse brain</article-title><source>Nature</source><year>2007</year><volume>445</volume><fpage>168</fpage><lpage>176</lpage><pub-id pub-id-type="pmid">17151600</pub-id></citation></ref><ref id="B61"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>G</given-names></name><etal/></person-group><article-title>3D cell nuclei segmentation based on gradient flow tracking</article-title><source>BMC Cell Biol.</source><year>2007</year><volume>8</volume><fpage>40</fpage><pub-id pub-id-type="pmid">17784958</pub-id></citation></ref><ref id="B62"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Liebling</surname><given-names>M</given-names></name><etal/></person-group><article-title>Four-dimensional cardiac imaging in living embryos via postacquisition synchronization of nongated slice sequences</article-title><source>J. Biomed. Opt.</source><year>2005</year><volume>10</volume><comment>eid 054001</comment></citation></ref><ref id="B63"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>C</given-names></name><etal/></person-group><article-title>Intelligent interfaces for mining large-scale rnai-hcs image databases</article-title><year>2007</year><publisher-loc>Boston, MA, USA</publisher-loc><comment>In <italic>IEEE 7th International Conference on Bioinformatics and Biomedical Engineering</italic></comment></citation></ref><ref id="B64"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>G</given-names></name><etal/></person-group><article-title>A hybrid 3-d watershed algorithm incorporating gradient cues &#x00026; object models for automatic segmentation of nuclei in confocal image stacks</article-title><source>Cytometry</source><year>2003</year><volume>56A</volume><fpage>23</fpage><lpage>36</lpage><pub-id pub-id-type="pmid">14566936</pub-id></citation></ref><ref id="B65"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>G</given-names></name><etal/></person-group><article-title>Hierarchical, model-based merging of multiple fragments for improved 3-D segmentation of nuclei</article-title><source>Cytometry</source><year>2005</year><volume>63A</volume><fpage>20</fpage><lpage>33</lpage><pub-id pub-id-type="pmid">15584021</pub-id></citation></ref><ref id="B66"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>T</given-names></name><etal/></person-group><article-title>ZFIQ: a software package for zebrafish biology</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><fpage>438</fpage><lpage>439</lpage><pub-id pub-id-type="pmid">18089619</pub-id></citation></ref><ref id="B67"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><etal/></person-group><article-title>Molecular signatures and gene expression at the single cell level in C. elegans</article-title><source>Stanford University Technical Report.</source><year>2008</year></citation></ref><ref id="B68"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Livet</surname><given-names>J</given-names></name><etal/></person-group><article-title>Transgenic strategies for combinatorial expression of fluorescent proteins in the nervous system</article-title><source>Nature</source><year>2007</year><volume>450</volume><fpage>56</fpage><lpage>62</lpage><pub-id pub-id-type="pmid">17972876</pub-id></citation></ref><ref id="B69"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ljosa</surname><given-names>V</given-names></name><name><surname>Singh</surname><given-names>AK</given-names></name></person-group><article-title>APLA: indexing arbitrary probability distributions</article-title><source>Proceedings of the 23rd International Conference on Data Engineering (ICDE).</source><year>2007</year></citation></ref><ref id="B70"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ljosa</surname><given-names>V</given-names></name><etal/></person-group><article-title>Indexing spatially sensitive distance measures using multi-resolution lower bounds</article-title><source>Proceedings of the 10th International Conference on Extending Database Technology.</source><year>2006</year><fpage>865</fpage><lpage>883</lpage></citation></ref><ref id="B71"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name><etal/></person-group><article-title>Phenotype clustering of breast epithelial cells in confocal images based on nuclear protein distribution analysis</article-title><source>BMC Cell Biol.</source><year>2007a</year><volume>8</volume><issue>Supp.1</issue><fpage>S3</fpage><pub-id pub-id-type="pmid">17634093</pub-id></citation></ref><ref id="B72"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name><etal/></person-group><article-title>A 3D digital cell atlas for the first larval stage of C. elegans hermaphrodite</article-title><source>HHMI JFRC Technical Report.</source><year>2007b</year></citation></ref><ref id="B73"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name><etal/></person-group><article-title>Automatic segmentation of nuclei in 3D microscopy images of C. elegans</article-title><source>Proceedings of the IEEE ISBI 2007.</source><year>2007c</year><fpage>536</fpage><lpage>539</lpage></citation></ref><ref id="B74"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name><etal/></person-group><article-title>Automatic recognition of cells (ARC) for 3D images of C. elegans</article-title><source>Lecture Notes in Computer Science: Research in Computational Molecular Biology.</source><year>2008</year><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>128</fpage><lpage>139</lpage></citation></ref><ref id="B75"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Longair</surname><given-names>M</given-names></name></person-group><year>2008</year></citation></ref><ref id="B76"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Luengo Hendriks</surname><given-names>CL</given-names></name><etal/></person-group><article-title>3D morphology and gene expression in the Drosophila blastoderm at cellular resolution I: data acquisition pipeline</article-title><source>Genome Biol.</source><year>2006</year><volume>7</volume><fpage>R123</fpage><pub-id pub-id-type="pmid">17184546</pub-id></citation></ref><ref id="B77"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Maack</surname><given-names>N</given-names></name><etal/></person-group><article-title>3D reconstruction of neural circuits from serial EM images</article-title><source>31st G&#x000f6;ttingen Neurobiology Conf.</source><year>2007</year><volume>31</volume><fpage>1195</fpage></citation></ref><ref id="B78"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>DS</given-names></name><etal/></person-group><article-title>The extensible neuroimaging archive toolkit (XNAT): an informatics platform for managing, exploring, and sharing neuroimaging data</article-title><source>Neuroinformatics</source><year>2007</year><volume>5</volume><fpage>11</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">17426351</pub-id></citation></ref><ref id="B79"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Martone</surname><given-names>ME</given-names></name><etal/></person-group><article-title>A cell centered database for electron tomographic data</article-title><source>J. Struct. Biol.</source><year>2002</year><volume>138</volume><fpage>145</fpage><lpage>155</lpage><pub-id pub-id-type="pmid">12160711</pub-id></citation></ref><ref id="B80"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Megason</surname><given-names>S</given-names></name><name><surname>Fraser</surname><given-names>S</given-names></name></person-group><article-title>Imaging in systems biology</article-title><source>Cell</source><year>2007</year><volume>130</volume><fpage>784</fpage><lpage>795</lpage><pub-id pub-id-type="pmid">17803903</pub-id></citation></ref><ref id="B81"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Megason</surname><given-names>SG</given-names></name><etal/></person-group><article-title>The digital fish project &#x02013; in toto imaging and fliptraps for digitizing development</article-title><source>FASEB J.</source><year>2008</year><volume>22</volume><fpage>253.3</fpage></citation></ref><ref id="B82"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Meijering</surname><given-names>E</given-names></name><etal/></person-group><article-title>Design and validation of a tool for neurite tracing and analysis in fluorescence microscopy images</article-title><source>Cytometry</source><year>2004</year><volume>58A</volume><fpage>167</fpage><lpage>176</lpage><pub-id pub-id-type="pmid">15057970</pub-id></citation></ref><ref id="B83"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Meijering</surname><given-names>E</given-names></name><etal/></person-group><article-title>Tracking in molecular bioimaging</article-title><source>IEEE Signal Proc. Mag.</source><year>2006</year><fpage>46</fpage><lpage>53</lpage></citation></ref><ref id="B84"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Merryman</surname><given-names>TE</given-names></name><name><surname>Kova&#x0010d;evi&#x00107;</surname><given-names>J</given-names></name></person-group><article-title>An adaptive multirate algorithm for acquisition of fluorescence microscopy data sets</article-title><source>IEEE Trans. Image Proc</source><year>2005</year><volume>14</volume><fpage>1246</fpage><lpage>1253</lpage></citation></ref><ref id="B85"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>E</given-names></name></person-group><article-title>Data driven image models through continuous joint alignment</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2006</year><volume>28</volume><fpage>236</fpage><lpage>250</lpage><pub-id pub-id-type="pmid">16468620</pub-id></citation></ref><ref id="B86"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moffat</surname><given-names>J</given-names></name><etal/></person-group><article-title>A lentiviral RNAi library for human and mouse genes applied to an arrayed viral high-content screen</article-title><source>Cell</source><year>2006</year><volume>124</volume><fpage>1283</fpage><lpage>1298</lpage><pub-id pub-id-type="pmid">16564017</pub-id></citation></ref><ref id="B87"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>DB</given-names></name></person-group><source>Fundamentals of Light Microscopy and Electronic Imaging.</source><year>2001</year><publisher-name>Wiley&#x02013;Liss Inc</publisher-name></citation></ref><ref id="B88"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>RF</given-names></name><etal/></person-group><article-title>Robust numerical features for description and classification of subcellular location patterns in fluorescence microscope images</article-title><source>J. VLSI Sig. Proc.</source><year>2003</year><volume>35</volume><fpage>311</fpage><lpage>321</lpage></citation></ref><ref id="B89"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Newberg</surname><given-names>J</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><article-title>A framework for the automated analysis of subcellular patterns in human protein atlas images</article-title><source>J. Proteome Res.</source><year>2008</year><volume>9</volume></citation></ref><ref id="B90"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>L</given-names></name><etal/></person-group><article-title>Neuroinformatics for genome-wide 3-d gene expression mapping in the mouse brain</article-title><source>IEEE/ACM Trans. Comput. Biol.Bioinform.</source><year>2007</year><volume>4</volume><fpage>382</fpage><lpage>393</lpage><pub-id pub-id-type="pmid">17666758</pub-id></citation></ref><ref id="B91"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>JY</given-names></name><etal/></person-group><article-title>Automatic mining of fruit fly embryo images</article-title><source>Proceedings of the 12th ACM SIGKDD 2006.</source><year>2006</year></citation></ref><ref id="B92"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Parvin</surname><given-names>B</given-names></name><etal/></person-group><article-title>BioSig: an imaging bioinformatic system for studying phenomics</article-title><source>Computer</source><year>2002</year><volume>35</volume><fpage>65</fpage><lpage>71</lpage></citation></ref><ref id="B93"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Parvin</surname><given-names>B</given-names></name><etal/></person-group><article-title>Iterative voting for inference of structural saliency and localization of subcellular structures</article-title><source>IEEE Trans. on Image Process.</source><year>2007</year><volume>16</volume><fpage>615</fpage><lpage>623</lpage></citation></ref><ref id="B94"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Pawley</surname><given-names>JB</given-names></name></person-group><source>Handbook of Biological Confocal Microscopy.</source><year>2006</year><edition>3rd edn.</edition><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name></citation></ref><ref id="B95"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peleg</surname><given-names>S</given-names></name><etal/></person-group><article-title>A unified approach to the change of resolution: space and gray-level</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>1989</year><volume>11</volume><fpage>739</fpage><lpage>742</lpage></citation></ref><ref id="B96"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name></person-group><article-title>Comparing in situ mRNA expression patterns of Drosophila embryos</article-title><source>Proceedings of the RECOMB 2004.</source><year>2004</year><publisher-loc>USA</publisher-loc><publisher-name>San Diego</publisher-name><fpage>157</fpage><lpage>166</lpage></citation></ref><ref id="B97"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>Reconstructing a developmental time series of 3D gene expression patterns in Drosophila embryos</article-title><source>2005 Drosophlia Meeting</source><year>2005a</year><publisher-loc>CA</publisher-loc><publisher-name>San Diego</publisher-name><comment>Available at <ext-link ext-link-type="uri" xlink:href="http://research.janelia.org/peng/papersall/docpdf/2005_FlyMeeting_poster.pdf">http://research.janelia.org/peng/papersall/docpdf/2005_FlyMeeting_poster.pdf</ext-link></comment></citation></ref><ref id="B98"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2005b</year><volume>27</volume><fpage>1226</fpage><lpage>1238</lpage><pub-id pub-id-type="pmid">16119262</pub-id></citation></ref><ref id="B99"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>Clustering gene expression patterns of fly embryos</article-title><source>Proceedings of the IEEE ISBI 2006.</source><year>2006</year><fpage>1144</fpage><lpage>1147</lpage></citation></ref><ref id="B100"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>Automatic image analysis for gene expression patterns of fly embryos</article-title><source>BMC Cell Biol.</source><year>2007</year><volume>8</volume><issue>Supp. 1</issue><fpage>S7</fpage><pub-id pub-id-type="pmid">17634097</pub-id></citation></ref><ref id="B101"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>Straightening Caenorhabditis elegans images</article-title><source>Bioinformatics</source><year>2008a</year><volume>24</volume><fpage>234</fpage><lpage>242</lpage><pub-id pub-id-type="pmid">18025002</pub-id></citation></ref><ref id="B102"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>WANO: a 3D bioimage annotation system</article-title><source>HHMI JFRC Technical Report.</source><year>2008b</year></citation></ref><ref id="B103"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>JM</given-names></name><etal/></person-group><article-title>Correlative fluorescence and electron microscopy on ultrathin cryosections: bridging the resolution gap</article-title><source>J. Histochem. Cytochem.</source><year>2001</year><volume>49</volume><fpage>803</fpage><lpage>808</lpage><pub-id pub-id-type="pmid">11410605</pub-id></citation></ref><ref id="B104"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rohr</surname><given-names>K</given-names></name><etal/></person-group><article-title>Spline-based elastic image registration, integration of landmark errors and orientation attributes</article-title><source>Comput. Vis. Image Underst.</source><year>2003</year><volume>90</volume><fpage>153</fpage><lpage>168</lpage></citation></ref><ref id="B105"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roussel</surname><given-names>N</given-names></name><etal/></person-group><article-title>A computational model for C. elegans locomotory behavior: application to multi-worm tracking</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2007</year><volume>54</volume><fpage>1786</fpage><lpage>1797</lpage><pub-id pub-id-type="pmid">17926677</pub-id></citation></ref><ref id="B106"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Roysam</surname><given-names>B</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Rittscher</surname><given-names>J</given-names></name><etal/></person-group><article-title>The FARSIGHT project: associative multi-dimensional image analysis methods for optical microscopy</article-title><source>Microscopic Image Analysis for Life Science Applications.</source><year>2008</year><publisher-name>Artech Publishing House</publisher-name></citation></ref><ref id="B107"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rust</surname><given-names>M</given-names></name><etal/></person-group><article-title>Sub-diffraction-limit imaging by stochastic optical reconstruction microscopy (STORM)</article-title><source>Nat. Methods</source><year>2006</year><volume>3</volume><fpage>793</fpage><lpage>796</lpage><pub-id pub-id-type="pmid">16896339</pub-id></citation></ref><ref id="B108"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sepp</surname><given-names>K</given-names></name><etal/></person-group><article-title>From flies to mice: identification of neural outgrowth genes using genome-wide RNAi</article-title><source>PLoS Genet.</source><year>2008</year></citation></ref><ref id="B109"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>D</given-names></name><name><surname>Davatzikos</surname><given-names>C</given-names></name></person-group><article-title>HAMMER: heirarchical attribute matching mechanism for elastic registration</article-title><source>IEEE Trans. Med. Imaging</source><year>2002</year><volume>21</volume><fpage>1421</fpage><lpage>1439</lpage><pub-id pub-id-type="pmid">12575879</pub-id></citation></ref><ref id="B110"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>J</given-names></name><name><surname>Malik</surname><given-names>J</given-names></name></person-group><article-title>Normalized cuts and image segmentation</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2000</year><volume>22</volume><fpage>888</fpage><lpage>905</lpage></citation></ref><ref id="B111"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shimomura</surname><given-names>O</given-names></name><etal/></person-group><article-title>Extraction, purification and properties of aequorin, a bioluminescent protein from the luminous hydromedusan, Aequorea</article-title><source>J. Cell Comp. Physiol.</source><year>1962</year><volume>59</volume><fpage>223</fpage><lpage>239</lpage><pub-id pub-id-type="pmid">13911999</pub-id></citation></ref><ref id="B112"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Smal</surname><given-names>I</given-names></name><etal/></person-group><article-title>Particle filtering for multiple object tracking in dynamic fluorescence microscopy images: application to microtubule growth analysis</article-title><source>IEEE Trans. Med. Imaging.</source><year>2008</year></citation></ref><ref id="B113"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Swedlow</surname><given-names>JR</given-names></name><etal/></person-group><article-title>Informatics and quantitative analysis in biological imaging</article-title><source>Science</source><year>2003</year><volume>300</volume><fpage>100</fpage><lpage>102</lpage><pub-id pub-id-type="pmid">12677061</pub-id></citation></ref><ref id="B114"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Swidan</surname><given-names>F</given-names></name><etal/></person-group><article-title>MAD: minimum shared decomposition of DAGs for multitarget tracking</article-title><source>HHMI JFRC Technical Report.</source><year>2007</year></citation></ref><ref id="B115"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Szeliski</surname><given-names>R</given-names></name></person-group><article-title>Image alignment and stitching: a tutorial</article-title><year>2006</year><volume>2</volume><fpage>1</fpage><lpage>104</lpage></citation></ref><ref id="B116"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Toga</surname><given-names>AW</given-names></name><name><surname>Thompson</surname><given-names>PM</given-names></name></person-group><article-title>The role of image registration in brain mapping</article-title><source>Image Vis. Comput.</source><year>2001</year><volume>19</volume><fpage>3</fpage><lpage>24</lpage></citation></ref><ref id="B117"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tomancak</surname><given-names>P</given-names></name><etal/></person-group><article-title>Systematic determination of patterns of gene expression during Drosophila embryogenesis</article-title><source>Genome Biol.</source><year>2002</year><volume>3</volume><comment>research0088.1-0088.14</comment></citation></ref><ref id="B118"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tsechpenakis</surname><given-names>T</given-names></name><etal/></person-group><article-title>Tracking C. elegans populations in fluid environments for the study of different locomotory behaviors. In</article-title><source>Proceedings of the MIAAB 2007.</source><year>2007</year></citation></ref><ref id="B119"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tsien</surname><given-names>RY</given-names></name></person-group><article-title>Imagining imaging's future</article-title><source>Nat. Rev. Mol. Cell Biol.</source><year>2003</year><volume>4</volume><fpage>SS16</fpage><lpage>SS21</lpage><pub-id pub-id-type="pmid">14587522</pub-id></citation></ref><ref id="B120"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Unser</surname><given-names>M</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Davos</surname><given-names>GR</given-names></name></person-group><article-title>Advanced image processing and analysis using ImageJ</article-title><source>8th European Light Microscopy Initiative Meeting</source><year>2008</year><publisher-loc>Switzerland</publisher-loc><comment>May 27&#x02013;30, 2008</comment></citation></ref><ref id="B121"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Viola</surname><given-names>P</given-names></name><name><surname>Wells</surname><given-names>WM</given-names></name></person-group><article-title>Alignment by maximization of mutual information</article-title><source>Int. J. Comput. Vis.</source><year>1997</year><volume>24</volume><fpage>137</fpage><lpage>154</lpage></citation></ref><ref id="B122"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Vu</surname><given-names>N</given-names></name><name><surname>Manjunath</surname><given-names>BS</given-names></name></person-group><article-title>Graph cut segmentation of neuronal structures from transmission electron micrographs</article-title><source>Proceedings of the IEEE ICIP 2008</source><year>2008</year><publisher-loc>San Diego, CA.</publisher-loc><comment>October 2008.</comment></citation></ref><ref id="B123"><citation citation-type="book"><person-group person-group-type="author"><name><surname>West</surname><given-names>RG</given-names></name></person-group><article-title>ATLAS in silico</article-title><source>ACM SIGGRAPH 2007 Art Gallery</source><year>2007</year><volume>225</volume><publisher-loc>California</publisher-loc><publisher-name>San Diego</publisher-name><comment>August 05&#x02013;09, 2007</comment></citation></ref><ref id="B124"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Parvin</surname><given-names>B</given-names></name></person-group><article-title>Harmonic cuts and regualrized centroid transform for localization of subcellular structures</article-title><source>IEEE Trans. Bioeng.</source><year>2003</year><volume>50</volume><fpage>469</fpage><lpage>476</lpage></citation></ref><ref id="B125"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Yoo</surname><given-names>TS</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Westwood</surname><given-names>J</given-names></name></person-group><article-title>Engineering and algorithm design for an image processing API: a technical report on ITK &#x02013; the insight toolkit</article-title><source>Proceedings of the Medicine Meets Virtual Reality.</source><year>2002</year><publisher-loc>Amsterdam</publisher-loc><publisher-name>IOS Press</publisher-name><fpage>586</fpage><lpage>592</lpage></citation></ref><ref id="B126"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>N</given-names></name><etal/></person-group><article-title>GelScape: a web-based server for interactively annotating, manipulating, comparing and archiving 1D and 2D gel images</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>976</fpage><lpage>978</lpage><pub-id pub-id-type="pmid">14764570</pub-id></citation></ref><ref id="B127"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Murphy</surname><given-names>RF</given-names></name></person-group><article-title>Automated learning of generative models for subcellular location: building blocks for systems biology</article-title><source>Cytometry</source><year>2007</year><volume>71A</volume><fpage>978</fpage><lpage>990</lpage><pub-id pub-id-type="pmid">17972315</pub-id></citation></ref><ref id="B128"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><article-title>Automatic recognition and annotation of gene expression patterns of fly embryos</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>589</fpage><lpage>596</lpage><pub-id pub-id-type="pmid">17237064</pub-id></citation></ref><ref id="B129"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zollei</surname><given-names>L</given-names></name><etal/></person-group><article-title>Efficient population registration of 3D data</article-title><year>2005</year><comment>In <italic>ICCV Workshop on Computer Vision for Biomedical Image Applications: Current Techniques and Future Trends</italic></comment></citation></ref></ref-list></back></article>





