<?xml version='1.0' encoding='US-ASCII'?>
<!DOCTYPE article PUBLIC "-//APA//DTD APA Journal Archive DTD v1.0 20130715//EN" "http://xml.apa.org/serials/jats-dtds-1.0/APAjournal-archive.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" xml:lang="en" structure-type="article" dtd-version="1.0">
<front>
<journal-meta>
<journal-title-group>
<journal-title xml:lang="en">Journal of Experimental Psychology: Human Perception and Performance</journal-title></journal-title-group>
<issn pub-type="print">0096-1523</issn>
<issn pub-type="online">1939-1277</issn>
<publisher>
<publisher-name>American Psychological Association</publisher-name></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="apaID">xhp_39_5_1457</article-id>
<article-id pub-id-type="doi">10.1037/a0031631</article-id>
<article-id pub-id-type="pi-uid">2013-04455-001</article-id>
<article-categories>
<subj-group subj-group-type="toc-heading">
<subject>Reports</subject>
</subj-group>
</article-categories>
<title-group><article-title>Elastic Facial Movement Influences Part-Based but Not Holistic Processing</article-title>
</title-group>
<contrib-group content-type="journal-editors">
<contrib contrib-type="editor" corresp="no" xlink:type="simple"><string-name><given-names>James T.</given-names> <surname>Enns</surname></string-name> <role>Editor</role></contrib>
</contrib-group>
<contrib-group content-type="primary-authors">
<contrib rid="aff1" contrib-type="author" corresp="no" xlink:type="simple">
<string-name>
<given-names>Naiqi G.</given-names> <surname>Xiao</surname></string-name>
</contrib>
<contrib rid="aff2" contrib-type="author" corresp="no" xlink:type="simple">
<string-name>
<given-names>Paul C.</given-names> <surname>Quinn</surname></string-name>
</contrib>
<contrib rid="aff3" contrib-type="author" corresp="no" xlink:type="simple">
<string-name>
<given-names>Liezhong</given-names> <surname>Ge</surname></string-name>
</contrib>
<contrib rid="aff4 corr1" contrib-type="author" corresp="yes" xlink:type="simple">
<string-name>
<given-names>Kang</given-names> <surname>Lee</surname></string-name>
</contrib>
<aff id="aff1">Dr. Eric Jackman Institute of Child Study, University of Toronto, Toronto, Ontario, Canada, and Department of Psychology, Zhejiang Sci-Tech University, Zhejiang, China</aff>
<aff id="aff2">Department of Psychology, University of Delaware</aff>
<aff id="aff3">Department of Psychology, Zhejiang Sci-Tech University</aff>
<aff id="aff4">Dr. Eric Jackman Institute of Child Study, University of Toronto, and Department of Psychology, University of California, San Diego</aff>
</contrib-group>
<author-notes>
<p align="left">This research is supported by grants from the Natural Science and Engineering Research Council of Canada, National Institutes of Health (R01 HD046526), the Natural Science Foundation of China (60910006, 31028010, 31070908), the Zhejiang Provincial Natural Science Foundation of China (Y2100970), and the Zhejiang QianJiang Talent Foundation (QJC1002010 1013371-M).</p>
<corresp id="corr1">
<addr-line>Kang Lee, Dr. Eric Jackman Institute of Child Study, University of Toronto, Toronto ON M5R 2X2, Canada</addr-line> <ext-link specific-use="live" xlink:href="mailto:kang.lee@utoronto.ca" ext-link-type="email" xlink:type="simple">kang.lee@utoronto.ca</ext-link></corresp>
</author-notes>
<pub-date pub-type="online"><string-date><month number="2">February</month> <day>11</day>, <year>2013</year></string-date></pub-date>
<pub-date pub-type="print"><string-date><month number="10">October</month> <year>2013</year></string-date></pub-date>
<volume>39</volume>
<issue>5</issue>
<fpage>1457</fpage>
<lpage>1467</lpage>
<history>
<string-date content-type="received"><month number="9">September</month> <day>23</day>, <year>2012</year></string-date>
<string-date content-type="revised"><month number="11">November</month> <day>13</day>, <year>2012</year></string-date>
<string-date content-type="accepted"><month number="12">December</month> <day>13</day>, <year>2012</year></string-date>
</history>
<permissions copyright-status="active">
<copyright-statement>&#169; 2013 American Psychological Association</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder>American Psychological Association</copyright-holder>
</permissions>
<abstract xml:lang="en">
<p align="left">Face processing has been studied for decades. However, most of the empirical investigations have been conducted using static face images as stimuli. Little is known about whether static face processing findings can be generalized to real-world contexts in which faces are constantly moving. The present study investigated the nature of face processing (holistic vs. part-based) in elastic moving faces. Specifically, we focused on whether elastic moving faces, as compared with static ones, can facilitate holistic or part-based face processing. Using the composite paradigm, we asked participants to remember either an elastic moving face (i.e., a face that blinks and chews) or a static face, and then tested with a static composite face. The composite effect was (a) significantly smaller in the dynamic condition than in the static condition, (b) consistently found with different face encoding times (Experiments 1&#8211;3), and (c) present for the recognition of both upper and lower face parts (Experiment 4). These results suggest that elastic facial motion facilitates part-based processing rather than holistic processing. Thus, whereas previous work with static faces has emphasized an important role for holistic processing, the current work highlights an important role for featural processing with moving faces.</p>
</abstract>
<kwd-group xml:lang="en">
<kwd>elastic facial movement</kwd>
<kwd>holistic processing</kwd>
<kwd>part-based processing</kwd>
<kwd>composite face paradigm</kwd>
</kwd-group>
</article-meta></front>
<body>
<sec id="s1">
<p align="left">Object motion provides enriched information about the world. Movement facilitates the processing of multidimensional profiles of objects as well as their temporal and spatial relationships. One of the most salient moving objects we encounter everyday is the human face. Faces perform various movements, which can be categorized into two types: elastic and rigid. <italic>Elastic facial movement</italic> refers to the transient structural transformation of the facial skeletal musculature. For example, a simple smile comprises more than 17 facial muscle movements. <italic>Rigid facial movement</italic> refers to transient changes in face orientation while the facial structure remains unchanged (head turning and nodding). In many circumstances, both types of movements take place concurrently.</p>
<p align="left">Research has revealed that facial movements can facilitate face recognition (e.g., <xref ref-type="bibr" id="cr2-1" rid="c2">Butcher, Lander, Fang, &amp; Costen, 2011</xref>; <xref ref-type="bibr" id="cr10-1" rid="c10">Knight &amp; Johnston, 1997</xref>), a phenomenon that we refer to as the <italic>facial motion beneficial effect</italic>. However, the underlying mechanisms of this effect remain unclear. In the present study, we focused on the influence of elastic facial movement on the manner by which faces are processed, specifically investigating its effect on holistic and part-based processing in face recognition.</p>
</sec>
<sec id="s2">
<title>Facial Motion Beneficial Effect</title>
<p align="left">It is well established in the literature that learning moving faces leads to superior recognition performance compared with static faces (<xref ref-type="bibr" id="cr10-2" rid="c10">Knight &amp; Johnston, 1997</xref>; <xref ref-type="bibr" id="cr12-1" rid="c12">Lander &amp; Bruce, 2003</xref>, <xref ref-type="bibr" id="cr13-1" rid="c13">2004</xref>; <xref ref-type="bibr" id="cr14-1" rid="c14">Lander, Bruce, &amp; Hill, 2001</xref>; <xref ref-type="bibr" id="cr15-1" rid="c15">Lander, Christie, &amp; Bruce, 1999</xref>; <xref ref-type="bibr" id="cr16-1" rid="c16">Lander &amp; Chuang, 2005</xref>; <xref ref-type="bibr" id="cr17-1" rid="c17">Lander, Chuang, &amp; Wickham, 2006</xref>; <xref ref-type="bibr" id="cr18-1" rid="c18">Lander &amp; Davies, 2007</xref>; <xref ref-type="bibr" id="cr27-1" rid="c27">O&#8217;Toole et al., 2011</xref>; <xref ref-type="bibr" id="cr28-1" rid="c28">O&#8217;Toole, Roark, &amp; Abdi, 2002</xref>; <xref ref-type="bibr" id="cr30-1" rid="c30">Otsuka et al., 2009</xref>; <xref ref-type="bibr" id="cr31-1" rid="c31">Pike, Kemp, Towell, &amp; Phillips, 1997</xref>; <xref ref-type="bibr" id="cr38-1" rid="c38">Roark, Barrett, Spence, Abdi, &amp; O&#8217;Toole, 2003</xref>; <xref ref-type="bibr" id="cr44-1" rid="c44">Thornton &amp; Kourtzi, 2002</xref>). For example, <xref ref-type="bibr" id="cr39-1" rid="c39">Schiff, Banka, and de Bordes Galdi (1986)</xref> reported that moving faces in videos were more accurately identified than static faces. This facial motion beneficial effect for face recognition remained even when learned dynamic faces were compared with learned static images of multiple profiles of a face (<xref ref-type="bibr" id="cr1-1" rid="c1">Bulf &amp; Turati, 2010</xref>; <xref ref-type="bibr" id="cr12-2" rid="c12">Lander &amp; Bruce, 2003</xref>; <xref ref-type="bibr" id="cr30-2" rid="c30">Otsuka et al., 2009</xref>; <xref ref-type="bibr" id="cr32-1" rid="c32">Pilz, Thornton, &amp; B&#252;lthoff, 2006</xref>). Furthermore, evidence from previous studies indicates that this motion beneficial effect is a result of the dynamic nature of the moving faces (<xref ref-type="bibr" id="cr11-1" rid="c11">Lander &amp; Bruce, 2000</xref>, <xref ref-type="bibr" id="cr13-2" rid="c13">2004</xref>; <xref ref-type="bibr" id="cr15-2" rid="c15">Lander et al., 1999</xref>; <xref ref-type="bibr" id="cr18-2" rid="c18">Lander &amp; Davies, 2007</xref>). <xref ref-type="bibr" id="cr13-3" rid="c13">Lander and Bruce (2004)</xref>, for example, compared the recognition accuracy of learned moving faces at different video playback speeds. They found that the highest face recognition accuracy was for those learned at a natural speed, which implies that faces moving at their natural speed are better encoded and subsequently recognized. Taken together, these studies provide strong evidence to suggest that the dynamic information in moving faces facilitates improved face recognition.</p>
<p align="left">Despite consistent findings in support of the facial motion facilitation effect, the cause of the effect remains unclear. Some researchers have suggested that the beneficial effect may stem from the fact that facial movement optimizes facial information processing, which in turn leads to better recognition of dynamic faces than static ones (<xref ref-type="bibr" id="cr1-2" rid="c1">Bulf &amp; Turati, 2010</xref>; <xref ref-type="bibr" id="cr28-2" rid="c28">O&#8217;Toole et al., 2002</xref>; <xref ref-type="bibr" id="cr29-1" rid="c29">Otsuka, Hill, Kanazawa, Yamaguchi, &amp; Spehar, 2012</xref>; <xref ref-type="bibr" id="cr30-3" rid="c30">Otsuka et al., 2009</xref>; <xref ref-type="bibr" id="cr31-2" rid="c31">Pike et al., 1997</xref>; <xref ref-type="bibr" id="cr38-2" rid="c38">Roark et al., 2003</xref>). However, which particular aspect of facial information processing has been optimized has not been specified.</p>
<p align="left">It has been widely recognized that face information is processed in at least two qualitatively different manners: holistic and part-based processing (<xref ref-type="bibr" id="cr3-1" rid="c3">Calder, Rhodes, Johnson, &amp; Haxby, 2011</xref>; <xref ref-type="bibr" id="cr25-1" rid="c25">Mondloch, Pathman, Maurer, Le Grand, &amp; de Schonen, 2007</xref>; <xref ref-type="bibr" id="cr26-1" rid="c26">Moscovitch, Winocur, &amp; Behrmann, 1997</xref>; <xref ref-type="bibr" id="cr41-1" rid="c41">Tanaka &amp; Farah, 1993</xref>; <xref ref-type="bibr" id="cr51-1" rid="c51">Young, Hellawell, &amp; Hay, 1987</xref>). <italic>Holistic face processing</italic> refers to the tendency to integrate facial information as a unified whole or gestalt, whereas <italic>part-based processing</italic> focuses on the processing of facial features (e.g., eyes, nose, and mouth) in isolation. According to existing studies, adults, who are face-processing experts, predominantly employ the holistic method (<xref ref-type="bibr" id="cr21-1" rid="c21">McKone, 2008</xref>; <xref ref-type="bibr" id="cr34-1" rid="c34">Richler, Cheung, &amp; Gauthier, 2011</xref>; <xref ref-type="bibr" id="cr35-1" rid="c35">Richler, Mack, Gauthier, &amp; Palmeri, 2009</xref>). For example, <xref ref-type="bibr" id="cr34-2" rid="c34">Richler, Cheung, and Gauthier (2011)</xref> found that holistic face processing predicts face recognition ability in adults. <xref ref-type="bibr" id="cr46-1" rid="c46">Wang, Li, Fang, Tian, and Liu (2012)</xref> have also recently confirmed this association by providing evidence for a correlation between individual differences in holistic processing and face recognition accuracy. Holistic face processing additionally has been found to play an important role in superior recognition of own race faces compared with other race faces (<xref ref-type="bibr" id="cr6-1" rid="c6">Harrison et al., 2011</xref>; <xref ref-type="bibr" id="cr7-1" rid="c7">Hayward, Crookes, Favelle, &amp; Rhodes, 2011</xref>; <xref ref-type="bibr" id="cr22-1" rid="c22">Michel, Corneille, &amp; Rossion, 2007</xref>; <xref ref-type="bibr" id="cr23-1" rid="c23">Michel, Rossion, Han, Chung, &amp; Caldara, 2006</xref>), with own race face processing employing significantly more holistic processing. In addition, face recognition deficits, which are commonly observed in prosopagnosia and autism populations, can be explained by impairments in holistic face processing (<xref ref-type="bibr" id="cr33-1" rid="c33">Ramon, Busigny, &amp; Rossion, 2010</xref>; <xref ref-type="bibr" id="cr43-1" rid="c43">Teunisse &amp; de Gelder, 2003</xref>). Taken together, the existing evidence suggests that expert-level face processing in adults depends on holistic face processing as opposed to part-based processing.</p>
<p align="left">It should be noted that all of these findings have been obtained with the use of static faces as stimuli. However, in everyday life, most of the faces we encounter are moving faces. It is primarily with dynamically moving faces, not static ones, that we typically perform various tasks such as detection, discrimination, and recognition. It is entirely unclear whether findings with static faces can be generalized to dynamic moving faces. More specifically, it is not clear how, or even whether, facial movement influences holistic or part-based processing of faces.</p>
</sec>
<sec id="s3">
<title>Facial Movement&#8217;s Influence on Holistic Versus Part-Based Processing</title>
<p align="left">Only a few studies have investigated how facial movement influences the manner in which faces are processed or, more specifically, whether facial motion leads to greater holistic processing or part-based processing. One set of studies has used the face inversion paradigm as an indirect method to address this question. It is believed that inversion disproportionally disrupts holistic face processing but not part-based processing (<xref ref-type="bibr" id="cr5-1" rid="c5">Freire, Lee, &amp; Symons, 2000</xref>; <xref ref-type="bibr" id="cr49-1" rid="c49">Yin, 1969</xref>). <xref ref-type="bibr" id="cr45-1" rid="c45">Thornton, Mullins, and Banahan (2011)</xref> examined face gender identification in both static and moving faces. They found that participants needed significantly more time to judge the gender of inverted moving faces than that of upright moving faces, whereas gender identification for static faces was unaffected by face inversion. Based on this finding, the researchers concluded that facial movement facilitates holistic processing. However, <xref ref-type="bibr" id="cr8-1" rid="c8">Hill and Johnston (2001)</xref> found participants to be more accurate in judging the gender of moving faces in both the upright and inverted conditions. Furthermore, <xref ref-type="bibr" id="cr9-1" rid="c9">Knappmeyer, Thornton, and B&#252;lthoff (2003)</xref> showed that identity judgment based on facial movement was also not influenced by inversion. Recent studies have further challenged the traditional view that inversion disrupts holistic face processing more so than part-based processing. More recently, inversion has been shown to impair not only holistic processing, but also part-based processing (e.g., <xref ref-type="bibr" id="cr52-1" rid="c52">Yovel &amp; Kanwisher, 2004</xref>). This finding raises considerable doubts about the appropriateness of using inversion to address the holistic versus part-based processing question.</p>
<p align="left">The face composite effect has come to be regarded as a more direct and reliable measure of holistic face processing (<xref ref-type="bibr" id="cr4-1" rid="c4">Cheung, Richler, Phillips, &amp; Gauthier, 2011</xref>; <xref ref-type="bibr" id="cr6-2" rid="c6">Harrison et al., 2011</xref>; <xref ref-type="bibr" id="cr21-2" rid="c21">McKone, 2008</xref>; <xref ref-type="bibr" id="cr34-3" rid="c34">Richler, Cheung, &amp; Gauthier, 2011</xref>; <xref ref-type="bibr" id="cr35-2" rid="c35">Richler et al., 2009</xref>; <xref ref-type="bibr" id="cr51-2" rid="c51">Young et al., 1987</xref>; see <xref ref-type="bibr" id="cr42-1" rid="c42">Tanaka &amp; Gordon, 2011</xref>, for a review). This effect refers to the phenomenon in which identification of a certain face part (upper or lower face) is involuntarily affected by the other face part. For example, when a face is made of two face parts that belong to two different persons, the identification of one face part is impeded by the other face part when the two parts are fully aligned. Researchers have regarded this interference as evidence of holistic processing, demonstrating the automatic integration of the whole face to form a face gestalt. This argument has been further supported by the fact that the misalignment of two face parts or face inversion has the ability to reduce or eliminate this interference due to the destruction of the face gestalt (<xref ref-type="bibr" id="cr21-3" rid="c21">McKone, 2008</xref>; <xref ref-type="bibr" id="cr24-1" rid="c24">Mondloch &amp; Maurer, 2008</xref>; <xref ref-type="bibr" id="cr37-1" rid="c37">Richler, Wong, &amp; Gauthier, 2011</xref>; <xref ref-type="bibr" id="cr51-3" rid="c51">Young et al., 1987</xref>).</p>
<p align="left">Using the face composite effect paradigm, <xref ref-type="bibr" id="cr48-1" rid="c48">Xiao, Quinn, Ge, and Lee (2012)</xref> recently examined the influence of rigid facial movement on holistic versus part-based processing. In their study, participants saw a sequence of images of a face from different orientations and were asked to remember the face. Then, they were shown a static composite face, either aligned or misaligned, and asked to identify whether the upper face part of the composite face belonged to the same person they saw in the sequential face images. The major dynamic versus static manipulation was centered on how the images of a face from different orientations were displayed.</p>
<p align="left">In the dynamic condition, the face images from different orientations were shown sequentially in a natural order and at a natural speed, which could be perceived as the face turning from one side to another. In the static condition, the face images from different orientations were displayed at the same speed but in a randomized order (Experiment 1) or in the same natural order but with long intervals between images (Experiments 2 and 3). Thus, in the static condition, participants could not perceive coherent facial movements, although they saw exactly the same images of a face from different orientations.</p>
<p align="left"><xref ref-type="bibr" id="cr48-2" rid="c48">Xiao et al. (2012)</xref> observed the typical face composite effect in the static condition in each of the three experiments: Participants recognized the upper face part better when it was misaligned with the lower foil face part than when it was aligned. However, in the dynamic condition of each of the three experiments, the face composite effect disappeared. This finding suggests that rigid facial movement during face familiarization promotes part-based face processing rather than holistic face processing, which consequently reduces the holistic interference from the irrelevant face part. Xiao et al. further suggested that the predictable rigid facial motion allowed observers to readily attend to a certain face part during the familiarization stage, thereby enabling them to withstand interference from an irrelevant face part during the testing stage.</p>
<p align="left">However, this explanation might not be applicable to elastic facial movement, as the two types of facial movements present completely different movement patterns. Previous studies have suggested that the facial information embedded in rigid (e.g., head rotation and nodding) and elastic (e.g., facial expression, oral speech, and gaze) facial movement is different (<xref ref-type="bibr" id="cr12-3" rid="c12">Lander &amp; Bruce, 2003</xref>; <xref ref-type="bibr" id="cr28-3" rid="c28">O&#8217;Toole et al., 2002</xref>; <xref ref-type="bibr" id="cr38-3" rid="c38">Roark et al., 2003</xref>). Rigid facial movements provide multiple viewpoints of a face and display coherent face orientation changes (i.e., head turning and nodding). Thus, rigid motion by definition does not contain any changes related to face structure or features. This coherent predictable nature of movement makes it possible to maintain attention to certain facial features across different viewpoints. However, elastic facial movements, by definition, involve changes in facial features and the structural relationships among them. One possibility is that the changing nature of facial features during elastic motion makes it difficult for observers to sustain their attention. In addition, elastic facial motions are often idiosyncratic and sometimes provide characteristic information unique to a face&#8217;s owner (i.e., dynamic identity). As a result, observers may resort to using a more holistic method to process the dynamic face (holistic processing hypothesis). Alternatively, it is possible that the changes in face parts during elastic motion draw more attention to facial features, which leads to increased part-based processing (part-based processing hypothesis). The present study was designed to examine these two hypotheses by addressing a specific issue: how elastic facial movement influences the manner by which faces are processed.</p>
</sec>
<sec id="s4">
<title>The Present Study</title>
<p align="left">Here, we examined the effect of elastic facial movement on face processing by using the composite face paradigm. In Experiments 1 through 4, participants were first familiarized with a dynamic or a static target face. The dynamic target face display consisted of an individual facing the participants while blinking and chewing silently. The reason for choosing silent chewing movement as the source of elastic motion was because it does not include expressive, semantic, or attention cues, making it ideal to study the pure effect of facial movement. The static target face was a single image of the same face. Following the familiarization phase, a composite static face appeared. It consisted of upper and lower face parts from two different faces, which were either aligned to form a face gestalt or misaligned. The participants&#8217; task was to judge whether the upper or lower parts of the composite faces belonged to the target face.</p>
<p align="left">Similar to existing studies with static faces (e.g., <xref ref-type="bibr" id="cr24-2" rid="c24">Mondloch &amp; Maurer, 2008</xref>; <xref ref-type="bibr" id="cr51-4" rid="c51">Young et al., 1987</xref>), we used response accuracy differences between recognizing the aligned and misaligned composite faces (i.e., the composite effect) to index the manner in which facial elastic motion affected face processing. If the target face was processed holistically, worse performance should be observed for the aligned composite face than for the misaligned one. In other words, a composite effect should be observed. However, if participants processed the target face in a part-based manner, then the face composite effect should not be observed. That is, we should observe equal accuracy in recognizing face parts in the aligned and misaligned conditions.</p>
<p align="left">By comparing the composite effect in the dynamic condition with that in the static one, we can infer how elastic facial movement influences the manner in which face information is processed. A larger composite effect in the dynamic condition compared with the static condition would indicate that elastic facial movement facilitates participants&#8217; processing of the target face more holistically. On the other hand, a smaller composite effect in the dynamic condition compared with the static condition would suggest that elastic facial movement facilitates part-based processing.</p>
<p align="left">In Experiments 1&#8211;3, we asked participants to learn and recognize the upper face parts of the target composite faces. In Experiment 4, we asked participants to recognize the lower face parts to examine whether the results of Experiments 1&#8211;3 could be generalized to lower face identification.</p>
</sec>
<sec id="s5">
<title>Experiments 1&#8211;3</title>
<p align="left">Experiments 1&#8211;3 were designed to examine how elastic facial movement influences face recognition by using the face composite paradigm (<xref ref-type="bibr" id="cr20-1" rid="c20">Maurer, Le Grand, &amp; Mondloch, 2002</xref>; <xref ref-type="bibr" id="cr21-4" rid="c21">McKone, 2008</xref>; <xref ref-type="bibr" id="cr24-3" rid="c24">Mondloch &amp; Maurer, 2008</xref>; <xref ref-type="bibr" id="cr25-2" rid="c25">Mondloch et al., 2007</xref>; <xref ref-type="bibr" id="cr34-4" rid="c34">Richler, Cheung, &amp; Gauthier, 2011</xref>; <xref ref-type="bibr" id="cr35-3" rid="c35">Richler et al., 2009</xref>; <xref ref-type="bibr" id="cr36-1" rid="c36">Richler, Tanaka, Brown, &amp; Gauthier, 2008</xref>; <xref ref-type="bibr" id="cr51-5" rid="c51">Young et al., 1987</xref>). Specifically, we compared the composite effect in the dynamic condition with that in the static condition to understand whether elastic facial movement encourages either holistic or part-based face processing. In addition, the elastic facial movement&#8217;s influence was investigated with three different stimulus presentation durations in Experiments 1, 2, and 3 to ascertain whether facial motion&#8217;s impact is influenced by encoding time. If encoding time affects the motion effect, then we should observe different sized effects between the three experiments. In particular, the longer the duration, the greater the motion effect.</p>
<sec id="s6" disp-level="subsect1">
<title>Method</title>
<sec id="s7" disp-level="subsect2">
<title>Participants</title>
<p align="left">Twenty-four Chinese participants (seven men) participated in Experiment 1, and another 48 participants took part in Experiment 2 (<italic>N</italic> = 24, seven men) and Experiment 3 (<italic>N</italic> = 24, eight men). All participants had normal or corrected-to-normal vision, and they had not met any of the models whose faces would be used in the experiment. Participants took part in the experiment after giving their informed consent. They participated in only one of the three experiments.</p>
</sec>
<sec id="s8" disp-level="subsect2">
<title>Materials and procedure</title>
<p align="left">In Experiment 1, participants saw and were asked to remember a target face. In the dynamic condition, front-facing faces that were silently blinking and chewing were presented to participants (see <xref ref-type="fig" id="fgc1-1" rid="fig1">Figure 1</xref>). The faces were those of 20 Chinese models (10 men and 10 women), who were required to pose with neutral expressions and avoid any head movements. Following the presentation of the target face for 600 ms, a 500-ms visual mask was presented at the center of the screen. A static composite test face showed up immediately after the offset of the visual mask. The composite test face was comprised of upper and lower face parts, which came from two different faces. There were two types of test trials: target face test trials and foil face test trials. In the target face test trials, the upper part of the composite face was from the target face, whereas the lower part was from a different person that the participants had not seen before. For half of the target face test trials, the upper and the lower face parts were aligned to form a whole face (i.e., the aligned condition), whereas in the other half of the trials, the two were misaligned at about the midpoint of the face (i.e., the misaligned condition; see <xref ref-type="fig" id="fgc2-1" rid="fig2">Figure 2</xref>).<xref ref-type="fig-anchor" rid="fig1"/><xref ref-type="fig-anchor" rid="fig2"/></p>
<p align="left">In the foil face test trials, the upper foil test face came from a face image different from the target face. The foil face and target face images were identical except that the target face&#8217;s eyes and nose were replaced with those from additional faces. These additional faces were themselves never seen by participants in the present study. The image-editing software Photoshop was used to ensure that the foil faces with eye and nose replacements looked natural. The resultant foil faces were perceived as belonging to entirely different persons from the target faces although they shared the same face contour.</p>
<p align="left">When the target or foil test face was presented, participants were asked to recognize whether the upper face part was the same person as the target face by pressing keys. Participants were supposed to respond &#8220;same person&#8221; in the target test trials and &#8220;different person&#8221; in the foil test trials.</p>
<p align="left">For the static condition, the procedure was exactly the same as that in the dynamic condition, except the target faces were static face pictures rather than moving face videos. These face pictures were extracted from the face videos. For each model&#8217;s face video, six static face pictures (two for the closed mouth images, two for the open mouth images, and two for the middle point between open and closed mouth) were extracted and were randomly presented in the static trials. All of the face videos and pictures were sized to 640 &#215; 480 pixels and were presented on 17-in. monitors with a resolution of 1,024 &#215; 768 pixels.</p>
<p align="left">For Experiments 2 and 3, the procedure and stimuli were identical to those in Experiment 1 except for the target face presentation duration. The target faces were shown for 1,200 ms in Experiment 2 and 1,800 ms in Experiment 3.</p>
<p align="left">To avoid potential interference between the dynamic and static trials, 20 models&#8217; faces were equally split into two sets (five men and five women for each set), which were used in either the dynamic or static condition. For half of the participants, faces in Set 1 were only shown in the dynamic trials and those in Set 2 were only shown in the static trials, and vice versa for the other half of the participants.</p>
<p align="left">All of the participants went through 160 experimental trials, which were equally divided into 2 (target face type: dynamic and static) &#215; 2 (composite face alignment: aligned and misaligned) &#215; 2 (composite face type: target and foil) = 8 conditions. All the trials were presented in a random order.</p>
<p align="left">A set of four practice trials was administered before the experimental trials to familiarize participants with the experimental procedure. The faces used in these practice trials were not shown in the experimental trials.</p>
</sec>
</sec>
<sec id="s9" disp-level="subsect1">
<title>Results and Discussion</title>
<p align="left">The measurement used in the present study was participants&#8217; response accuracy. According to previous studies, only accuracy data from the target composite face trials were taken into account (e.g., <xref ref-type="bibr" id="cr24-4" rid="c24">Mondloch &amp; Maurer, 2008</xref>; <xref ref-type="bibr" id="cr51-6" rid="c51">Young et al., 1987</xref>) because it is regarded as more reliable to examine whether faces are processed holistically or in a part-based manner (<xref ref-type="bibr" id="cr37-2" rid="c37">Richler, Wong, &amp; Gauthier, 2011</xref>).</p>
<p align="left"><xref ref-type="fig" id="fgc3-1" rid="fig3">Figure 3</xref> shows that the mean accuracy in Experiments 1, 2, and 3. For Experiment 1, a 2 (target face type) &#215; 2 (composite face alignment) repeated measures analysis of variance (ANOVA) was conducted on response accuracy. Consistent with previous findings, test faces were more accurately recognized in the dynamic condition than in the static one (<italic>M</italic><sub location="post">dynamic</sub> = 0.82, <italic>M</italic><sub location="post">static</sub> = 0.76), <italic>F</italic>(1, 23) = 7.01, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .23, <italic>p</italic> = .014. In addition, the misaligned test composite faces were better recognized than the aligned faces (<italic>M</italic><sub location="post">misaligned</sub> = 0.86, <italic>M</italic><sub location="post">aligned</sub> = 0.72), <italic>F</italic>(1, 23) = 22.32, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .49, <italic>p</italic> &lt; .001. This finding suggests that the test faces were processed in a holistic manner regardless of condition.<xref ref-type="fig-anchor" rid="fig3"/></p>
<p align="left">Next, we explored whether the degree of holistic and part-based face processing differed in the dynamic and static conditions by examining whether the composite effect was the same between the dynamic and static conditions. A significant interaction was found between target face type and alignment, <italic>F</italic>(1, 23) = 5.26, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .19, <italic>p</italic> = .031, indicating that the size of the composite effect in the dynamic and static conditions was different. We calculated the face composite effect in the dynamic and static conditions by subtracting response accuracy for aligned faces from that for misaligned faces. As shown in <xref ref-type="fig" id="fgc3-2" rid="fig3">Figure 3</xref>, dynamic faces led to a smaller composite effect than those in the static condition (<italic>M</italic><sub location="post">dynamic</sub> = 0.10, <italic>M</italic><sub location="post">static</sub> = 0.17). Furthermore, simple effects analyses showed that moving faces led to better recognition of aligned than of misaligned composite faces (<italic>p</italic> &lt; .050). However, no difference was found in recognition of misaligned composite faces between the dynamic and static conditions (<italic>p</italic> &gt; .050). Thus, elastic facial movement decreased the amount of holistic interference caused by aligned face parts, suggesting that elastic facial movement led participants to process facial information in a more part-based manner.</p>
<p align="left">It should be noted that the part-based processing promoted by elastic facial movement does not necessarily mean that motion provided additional information to the user nor that it improved recognition. In fact, there was no difference in recognition among the misaligned composite faces between the two conditions. Instead, facial motion seems to facilitate more part-based processing. This argument can be further supported with an individual differences analysis on the correlation between the composite effect size in the dynamic and static conditions among participants. The Pearson correlation showed a significant positive correlation between the two (<italic>r</italic> = .52, <italic>p</italic> = .009; see <xref ref-type="fig" id="fgc4-1" rid="fig4">Figure 4</xref>). This correlation suggests that elastic facial movement did not completely change face processing from holistic to part-based in an all-or-none fashion. Otherwise, we should not have observed any correlation between the dynamic and static conditions in composite effect size. Rather, elastic movement shifted the manner by which participants processed faces from more holistic to more part-based.<xref ref-type="fig-anchor" rid="fig4"/></p>
<p align="left">For Experiment 2, we found the same results as those in Experiment 1. The two-way ANOVA showed a significant main effect for both target face type and test face alignment factors. Participants&#8217; responses were more accurate when they learned dynamic faces than static ones (<italic>M</italic><sub location="post">dynamic</sub> = 0.88, <italic>M</italic><sub location="post">static</sub> = 0.81), <italic>F</italic>(1, 23) = 23.37, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .50, <italic>p</italic> &lt; .001. The alignment of the upper and lower part of the composite faces affected participants&#8217; recognition of the upper part (<italic>M</italic><sub location="post">misaligned</sub> = 0.89, <italic>M</italic><sub location="post">aligned</sub> = 0.80), <italic>F</italic>(1, 23) = 14.70, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .39, <italic>p</italic> &lt; .001. More important, it showed that the size of the composite effect in the dynamic condition was significantly smaller than that in the static condition, <italic>F</italic>(1, 23) = 8.87, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .28, <italic>p</italic> = .006, which again indicates that face processing was different when learning dynamic faces compared with static ones. Simple effects analyses revealed that, for misaligned faces, no significant difference in recognition between dynamic and static conditions was found (<italic>p</italic> &gt; .050). However, for aligned composite faces, face recognition was significantly better in the dynamic condition than in the static condition (<italic>p</italic> &lt; .050), suggesting that when participants learned the elastic moving faces as compared with the static ones, their processing became more part-based. In addition, this processing difference was supported by a significant correlation between the size of participants&#8217; composite effects between the dynamic and static conditions (see <xref ref-type="fig" id="fgc4-2" rid="fig4">Figure 4</xref>; <italic>r</italic> = .63, <italic>p</italic> = .001). This latter result once again indicates that elastic facial movement boosted part-based processing when learning dynamic faces compared with static ones, rather than completely changing the manner of face processing from holistic to part-based.</p>
<p align="left">As in Experiments 1 and 2, we conducted identical analyses for Experiment 3. Both the ANOVA and correlation analysis revealed the same results as those from the previous experiments. As shown in <xref ref-type="fig" id="fgc3-3" rid="fig3">Figure 3</xref>, elastic facial movement led to better recognition (<italic>M</italic><sub location="post">dynamic</sub> = 0.81, <italic>M</italic><sub location="post">static</sub> = 0.75), <italic>F</italic>(1, 23) = 9.17, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .29, <italic>p</italic> = .006. Misaligned composite faces were better recognized than aligned ones (<italic>M</italic><sub location="post">misaligned</sub> = 0.86, <italic>M</italic><sub location="post">aligned</sub> = 0.70), <italic>F</italic>(1, 23) = 44.73, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .66, <italic>p</italic> &lt; .001. The interaction between the two factors also showed significance, <italic>F</italic>(1, 23) = 6.69, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .23, <italic>p</italic> = .017, indicating that composite size was different between the dynamic and static conditions. The simple effects analyses once again replicated the results from Experiments 1 and 2: Elastic facial movement facilitated upper face part recognition for aligned faces (<italic>p</italic> &lt; .050), but not for misaligned faces (<italic>p</italic> &gt; .050). The significant correlation between the composite effect in the dynamic and static conditions (<italic>r</italic> = .45, <italic>p</italic> = .031) demonstrated that elastic facial movement increased the degree to which part-based face processing was employed, but did not entirely shift face processing from holistic to part-based.</p>
<p align="left">Results from Experiments 1&#8211;3 consistently revealed an elastic motion effect, which showed that elastic moving faces led to a smaller composite effect than static faces. The next analysis focused on whether this elastic motion effect was affected by the face presentation duration used in Experiments 1, 2, and 3. We conducted a 2 (target face type) &#215; 2 (composite face alignment) &#215; 3 (presenting duration) three-way mixed ANOVA on the accuracy data from the three experiments. No significant effects involving the presentation duration factor were found (<italic>p</italic>s &gt; .10; see <xref ref-type="fig" id="fgc5-1" rid="fig5">Figure 5</xref>). Thus, the elastic motion effect was robust across the different durations of face presentation.<xref ref-type="fig-anchor" rid="fig5"/></p>
<p align="left">In sum, the three experiments consistently showed that elastic facial movement led to a smaller composite effect. This elastic motion effect suggests that elastic facial movement may promote part-based face processing. However, an alternative explanation emerges as this effect may derive from the particular moving pattern of the chewing and blinking faces because this facial movement occurs primarily in the mouth area, that is, the lower face part. On the other hand, the blinking occurring in the upper face part is relatively infrequent. The dynamic contrast between two face parts could lead the upper face part to be perceived as relatively more stable than the lower chewing face part, thereby allowing the upper face part information to be more easily accessed. Thus, participants might have more easily processed the upper part of the face than the lower one, resulting in better performance in the dynamic than the static condition. This argument suggests that the motion effect might merely apply to situations in which recognition of the upper face part is required.</p>
<p align="left">In Experiment 4, we addressed this potential issue by asking participants to recognize the lower instead of upper face part. If the smaller composite effect in the dynamic condition was due to general part-based processing facilitation, we should continue to observe this effect in the lower face part recognition task. Alternatively, if the initial results were due to the particular unbalanced moving pattern in the chewing faces, then we should observe a comparable composite effect in the dynamic and static conditions.</p>
</sec>
</sec>
<sec id="s10">
<title>Experiment 4</title>
<sec id="s11" disp-level="subsect1">
<title>Method</title>
<sec id="s12" disp-level="subsect2">
<title>Participants</title>
<p align="left">Nineteen undergraduate students (eight men) with normal or corrected-to-normal vision participated in the current experiment. None of them had participated in the previous experiments or knew the models in the experiments.</p>
</sec>
<sec id="s13" disp-level="subsect2">
<title>Materials and procedure</title>
<p align="left">The stimuli in the present experiment were identical to those in the previous ones except for the composite faces. The upper part of the composite faces was always a different person from the person in the target face. The lower part of the target composite faces was always the same person as the person in the target face. The lower parts of the foil composite faces had the same face contour as those of the target composite faces, except that their inner face features (i.e., nose and mouth) were replaced with those from other models&#8217; face feature images, which were never shown in the present study.</p>
<p align="left">The procedure was identical to that in Experiment 2 (1,200-ms presentation duration), with the only exception being task requirement. In the present experiment, participants were asked to identify whether the lower face part of the composite faces was the same person as in the target faces.</p>
</sec>
</sec>
<sec id="s14" disp-level="subsect1">
<title>Results and Discussion</title>
<p align="left">As shown in <xref ref-type="fig" id="fgc6-1" rid="fig6">Figure 6</xref>, the present results were similar to those in Experiments 1&#8211;3, which was confirmed by a 2 (target face type) &#215; 2 (composite face alignment) ANOVA. Learning dynamic faces led to overall better recognition (<italic>M</italic> = 0.72) compared with learning static ones (<italic>M</italic> = 0.62), <italic>F</italic>(1, 18) = 18.52, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .51, <italic>p</italic> &lt; .001. The facial movement beneficial effect was replicated when identifying lower composite face parts. In addition, better recognition was also observed in the misaligned condition (<italic>M</italic> = 0.71) than the aligned one (<italic>M</italic> = 0.63), <italic>F</italic>(1, 18) = 9.70, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .35, <italic>p</italic> = .006. More important, the interaction was significant, <italic>F</italic>(1, 18) = 7.14, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .28, <italic>p</italic> = .016, with a smaller composite effect in the dynamic condition (<italic>M</italic> = 0.04) than in the static condition (<italic>M</italic> = 0.13). Thus, despite the fact that we changed the task demand and asked participants to recognize the lower face parts, the same elastic motion effect was observed.<xref ref-type="fig-anchor" rid="fig6"/></p>
<p align="left">The individual differences analysis also showed that the composite effect in the dynamic and static conditions was significantly correlated (<italic>r</italic> = .47, <italic>p</italic> = .043). This correlation corresponded with those in the previous experiments, suggesting that facial movement only changed the degree of using part-based processing relative to holistic processing.</p>
<p align="left">To confirm the similarity between findings in the current and previous experiments, we directly compared the composite effect in the present experiment (lower recognition) with that in Experiment 2 (upper recognition), given that both conditions used the same 1,200-ms stimulus presentation time. A 2 (task) &#215; 2 (target face type) mixed ANOVA was conducted on the size of the composite effect. Each participant&#8217;s composite effect score was calculated by subtracting his or her aligned face recognition accuracy from that in the misaligned trials. As expected, the effect of target face type showed a larger composite effect in the static than the dynamic condition, <italic>F</italic>(1, 41) = 15.92, &#951;<sub location="post" arrange="stack">p</sub><sup location="post" arrange="stack">2</sup> = .28, <italic>p</italic> &lt; .001. However, neither the main effect of experiment nor the interaction reached significance (<italic>p</italic>s &gt; .724). This finding suggests that neither the size of the composite effect nor the motion effect that facilitates part-based processing is affected by the demand of the recognition task.</p>
<p align="left">In the lower face part recognition task, the present experiment successfully replicated the finding that elastically moving faces led to a smaller composite effect than for static faces. The similar findings within the upper and the lower face recognition tasks indicate that the effect of facial movement is not limited to recognition of particular face parts, reflecting elastic movement&#8217;s relatively pervasive influence on the manner in which faces are processed.</p>
<p align="left">In sum, we have found evidence that the elastic facial motion effect is relatively robust in both upper and lower face part recognition. Thus, results from Experiments 1&#8211;4 together suggest that elastic facial movement leads to more part-based face processing. In spite of the consistency of results across Experiments 1&#8211;4, one crucial question remains: Is the elastic motion effect in face recognition related to participants&#8217; change in face processing manner from holistic to part-based? We tested this possibility by examining the correlation between the degree of change in processing manner and the degree to which the recognition advantage was facilitated by facial movement. We calculated the degree of change in processing manner by subtracting the composite effect in the dynamic condition from that in the static condition (i.e., the size of the motion facilitation effect). The recognition advantage was determined by subtracting recognition accuracy in the static condition from that in the dynamic condition. A Pearson correlation was performed to examine the relationship between these two measurements based on the data from Experiments 1&#8211;4. Data from five participants were not included in the analysis because their scores on one or the other measure were greater than 2 standard deviations from the mean. The degree to which part-based processing was used was found to be positively correlated with improved recognition for the facial movement condition (see <xref ref-type="fig" id="fgc7-1" rid="fig7">Figure 7</xref>; <italic>r</italic> = .38, <italic>p</italic> &lt; .001). Although causation cannot be inferred based on this correlational result, it does suggest a potential link between elastic facial movement&#8217;s facilitation of part-based processing and improved recognition performance.<xref ref-type="fig-anchor" rid="fig7"/></p>
</sec>
</sec>
<sec id="s15">
<title>General Discussion</title>
<p align="left">In the present study, we examined the effect of elastic facial movement on the manner by which faces are processed. Specifically, we tested whether facial motion facilitates either holistic or part-based face processing. We obtained four major findings. First, facial motion facilitates improved face recognition, replicating a robust effect in the literature (<xref ref-type="bibr" id="cr2-2" rid="c2">Butcher et al., 2011</xref>; <xref ref-type="bibr" id="cr8-2" rid="c8">Hill &amp; Johnston, 2001</xref>; <xref ref-type="bibr" id="cr10-3" rid="c10">Knight &amp; Johnston, 1997</xref>; <xref ref-type="bibr" id="cr12-4" rid="c12">Lander &amp; Bruce, 2003</xref>, <xref ref-type="bibr" id="cr13-4" rid="c13">2004</xref>; <xref ref-type="bibr" id="cr16-2" rid="c16">Lander &amp; Chuang, 2005</xref>; <xref ref-type="bibr" id="cr30-4" rid="c30">Otsuka et al., 2009</xref>). Second and more important, we found that elastic facial movement leads to a significantly smaller composite effect, suggesting that elastic facial movement facilitates part-based, not holistic, face processing. Third, the effect was found in three experiments that varied in exposure time. This finding suggests that the facial motion&#8217;s part-based processing facilitation effect is relatively robust and apparently unaffected by how much time participants have to encode the target face. Fourth, the facial movement effect was also found regardless of task demand (i.e., recognizing either the upper or lower part of the face).</p>
<p align="left">In the present study, the face composite effect was used to obtain direct evidence indicating that elastic facial movement promotes part-based face processing. In addition, analyses of individual differences showed that elastic facial movement increases the degree to which participants use part-based processing in extracting face identity information. That is, elastic facial movement does not completely change participants&#8217; face processing strategy from a holistic to a part-based manner in an all-or-none fashion.</p>
<p align="left">The current study, to our knowledge, is the first to provide direct evidence for an influence of elastic facial movement on the manner in which faces are processed. Our finding that elastic facial movement promotes part-based face processing is in line with results from previous studies that have used indirect measures. For example, <xref ref-type="bibr" id="cr8-3" rid="c8">Hill and Johnston (2001)</xref> showed that facial motion could facilitate gender judgment in both upright and inverted faces, thereby suggesting that the effect of facial motion is preserved with face inversion. Also, findings from <xref ref-type="bibr" id="cr9-2" rid="c9">Knappmeyer et al. (2003)</xref> indicated that there was no difference in the amount of motion facilitation when making identity judgments for upright and inverted faces. Given that inverting faces has been thought to mainly disrupt holistic face processing, the finding that facial movement facilitates recognition of inverted faces to the same extent as upright faces suggests that facial movement exerts its effect mainly on part-based, and not holistic, processing.</p>
<p align="left">Why would elastic facial movement facilitate part-based rather than holistic processing? There exist at least two nonmutually exclusive possibilities. First, the effect may be a result of the attention that elastic facial movement draws to individual face parts (<xref ref-type="bibr" id="cr19-1" rid="c19">Lander, Hill, Kamachi, &amp; Vatikiotis-Bateson, 2007</xref>). As shown in previous studies, although holistic processing is regarded as dominant in face perception, part-based processing becomes dominant when faces possess distinguishing features (e.g., big nose, hairstyle; <xref ref-type="bibr" id="cr26-2" rid="c26">Moscovitch et al., 1997</xref>; <xref ref-type="bibr" id="cr40-1" rid="c40">Sergent, 1985</xref>; <xref ref-type="bibr" id="cr50-1" rid="c50">Young, Ellis, Flude, McWeeny, &amp; Hay, 1986</xref>). Elastic movement is a product of the motion of several facial parts, and it is possible that motion of these facial features might cause them to appear more salient than those that remain static, thus acting as attention attractors. Participants&#8217; attention is likely driven to these face parts involuntarily, as opposed to allocation of attention across the whole face area. This behavior, in turn, would result in a smaller composite effect.</p>
<p align="left">The second possibility is that facilitation of part-based processing is driven by the changing face structure, which is also a product of elastic movements. When engaged in elastic motion, spatial relations between facial features change. Holistic face processing relies heavily on the spatial structure of a face; shifting spatial relationships make it difficult to process the face as a whole. Consequently, face processing must rely on part-based processing to interpret facial information. One of these possibilities, or a combination of both, likely led participants to rely on part-based face processing more so in the dynamic condition than in the static condition.</p>
<p align="left">In line with present findings, <xref ref-type="bibr" id="cr48-3" rid="c48">Xiao et al. (2012)</xref> recently provided evidence for the idea that rigid facial movements also facilitate part-based face processing by showing a smaller composite effect in the dynamic face condition relative to the static face condition. Rigid facial movement differs from elastic facial movement in that it does not include any changes in facial structure. It mainly consists of face viewpoint changes, for example, nodding and head turning. The authors suggested this rigid motion effect to be a product of coherent face viewpoint changes that provided a relatively stable viewing condition for observers to attend to face parts rather than the whole face. Consequently, promotion of this part-based processing led to a smaller composite effect.</p>
<p align="left">The present findings taken together with those of <xref ref-type="bibr" id="cr48-4" rid="c48">Xiao et al. (2012)</xref> have important implications for our understanding of the exact nature of face processing in the real world. The faces we encounter in the real world are constantly moving. However, most of our current knowledge about face processing is obtained from studies using static faces as stimuli. For example, the dominance of holistic face processing is a principal theory that was discovered and supported through these static face studies. The present findings suggest, however, that individuals rely on less, not more, holistic processing when viewing ecologically valid moving faces. This conclusion implies that natural face processing may not be done primarily in a holistic manner, and that face processing in natural situations might not look like what we have learned from static face studies. If this is indeed the case, we must seriously reassess the vast existing evidence derived from studies using static faces.</p>
<p align="left">What does this motion facilitation process signify for the processing of natural faces? One possibility that can be inferred from the present results is that facial movement might lead to processing of facial information that is most crucial to the task at hand. The current experiments asked participants to recognize a face part, and participants explicitly knew this. Thus, facial movements promoted the processing of part-based face information in order to adapt to this situation. As some recent studies have argued, holistic face processing is thought to reflect a rigid perceptual mechanism (<xref ref-type="bibr" id="cr37-3" rid="c37">Richler, Wong, &amp; Gauthier, 2011</xref>). However, the current findings show that this rigidity can be weakened by the introduction of facial movement, which optimizes face processing and allows adaptation to the task requirement. In both the current study and in <xref ref-type="bibr" id="cr48-5" rid="c48">Xiao et al. (2012)</xref>, the task was face part recognition, whereas in the real world we encounter various face-related tasks all the time, such as identifying gender, age, or emotional status. It would therefore be worthwhile to examine the facial motion effect in various tasks. If facial motion can flexibly influence performance according to task requirements, different effects would be predicted.</p>
<p align="left">It should be noted that, in the present study, we only tested recognition of static composite faces; however, face recognition in the real world almost always involving moving faces. Ideally, one should use a 2 (static vs. dynamic familiarization faces) &#215; 2 (static vs. dynamic test faces) design to assess fully the role of motion on face part-based or holistic processing. However, at present, it is technically difficult to produce dynamic composite faces because composite faces require matching of the two face parts. For static faces, this matching can be achieved based solely on image properties, such as skin color, face feature position, and so forth. For dynamic faces, this matching has to be done based both on image properties and movement patterns. Matching movement patterns requires that the two face parts move synchronously so as to be perceived as a single face. If there is a mismatch in the moving pattern, the aligned composite faces would no longer be perceived as a whole. It is this moving pattern matching issue that challenges the current technology. Nevertheless, the present design has one advantage. All existing studies of the face composite effect have used static test faces. By using the static faces as the test stimuli, we were able to compare the present findings with the existing ones. In particular, the present study must be able to replicate the robust face composite effect in the static condition to ensure that the motion effect observed was not due to specifics of our face stimuli. However, when technology improves in the future, the 2 &#215; 2 design mentioned above should be used.</p>
<p align="left">Previous face processing studies have suggested that holistic and part-based processing can occur both at the encoding and retrieval stages (<xref ref-type="bibr" id="cr36-2" rid="c36">Richler et al., 2008</xref>; <xref ref-type="bibr" id="cr47-1" rid="c47">Wenger &amp; Ingvalson, 2003</xref>). In the current study, the fact that the smaller composite effect in the elastic motion condition remained stable despite variations in the duration of face presentation (Experiments 1&#8211;3) suggests that it likely occurs at the face information retrieval stage rather than at the encoding stage. In Experiments 1&#8211;3, faces were presented for 600, 1,200, and 1,800 ms, respectively; observers&#8217; encoding time was therefore limited to these presentation durations. No differences in the motion effect were observed among any of these encoding times, suggesting the facial motion might not influence the encoding process. Otherwise, we should have found different motion effects for these experiments. The data are thus consistent with the idea that elastic motion might facilitate face information retrieval in a part-based manner. However, it should be noted, that this retrieval assumption has not been directly examined, and it would be worthwhile to test this by conducting a systematic investigation with particular paradigms.</p>
<p align="left">Because this work and that of <xref ref-type="bibr" id="cr48-6" rid="c48">Xiao et al. (2012)</xref> used only the composite effect as a measurement of part-based or holistic processing, it would be premature to conclude that elastic facial movement facilitates part-based face processing under all circumstances. Future studies should use other direct methods to further examine this relationship, for example, the part&#8211;whole paradigm (<xref ref-type="bibr" id="cr41-2" rid="c41">Tanaka &amp; Farah, 1993</xref>). The part&#8211;whole effect occurs when recognition of a face part (e.g., eyes, nose, or mouth) is more difficult when it is isolated than when it is presented as part of a face. Although both the part&#8211;whole effect and the composite effect index holistic face processing, recent studies have found that the two are not exactly the same, implying that they might reflect different aspects of face processing (e.g., <xref ref-type="bibr" id="cr46-2" rid="c46">Wang et al., 2012</xref>). More important, it would be worthwhile to test the difference between the two effects to determine whether the present findings could be replicated with the part&#8211;whole paradigm. Furthermore, because the part&#8211;whole paradigm focuses on a specific facial feature (e.g., eyes, nose, or mouth), it would be ideal for examining the effect of facial motion on a particular facial feature, which would, in turn, contribute to a more comprehensive understanding of the role of facial movement in face processing.</p>
</sec>
</body>
<back>
<ref-list use-in-PI="yes"><title>References</title>
<ref><mixed-citation publication-type="journal" meta="no" id="c1" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bulf</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Turati</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2010</year>). <article-title>The role of rigid motion in newborns&#8217; face recognition</article-title>. <source>Visual Cognition</source>, <volume>18</volume>, <fpage>504</fpage>&#8211;<lpage>512</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/13506280903272037</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c2" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Butcher</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Fang</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Costen</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2011</year>). <article-title>The effect of motion at encoding and retrieval for same- and other-race face recognition</article-title>. <source>British Journal of Psychology</source>, <volume>102</volume>, <fpage>931</fpage>&#8211;<lpage>942</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1111/j.2044-8295.2011.02060.x</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c3" xlink:type="simple"><person-group person-group-type="editor"><string-name><surname>Calder</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Rhodes</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>M. H.</given-names></string-name>, &amp; <string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name></person-group> (<role>Eds.</role>). (<year>2011</year>). <source>The Oxford handbook of face perception</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c4" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Cheung</surname>, <given-names>O. S.</given-names></string-name>, <string-name><surname>Richler</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>W. S.</given-names></string-name>, &amp; <string-name><surname>Gauthier</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Does temporal integration of face parts reflect holistic processing?</article-title> <source>Psychonomic Bulletin &amp; Review</source>, <volume>18</volume>, <fpage>476</fpage>&#8211;<lpage>483</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.3758/s13423-011-0051-7</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c5" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Freire</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Symons</surname>, <given-names>L. A.</given-names></string-name></person-group> (<year>2000</year>). <article-title>The face-inversion effect as a deficit in the encoding of configural information: Direct evidence</article-title>. <source>Perception</source>, <volume>29</volume>, <fpage>159</fpage>&#8211;<lpage>170</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1068/p3012</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c6" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Harrison</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Richler</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Mack</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Palmeri</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Hayward</surname>, <given-names>W. G.</given-names></string-name>, &amp; <string-name><surname>Gauthier</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2011</year>). <article-title>The complete design lets you see the whole picture: Differences in holistic processing contribute to face-inversion and other-race effects</article-title>. <source>Journal of Vision</source>, <volume>11</volume>, <fpage>625</fpage>. doi: <pub-id pub-id-source="author-published" pub-id-type="doi">10.1167/11.11.625</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c7" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hayward</surname>, <given-names>W. G.</given-names></string-name>, <string-name><surname>Crookes</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Favelle</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Rhodes</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Why are face composites difficult to recognize?</article-title> <source>Journal of Vision</source>, <volume>11</volume>, <fpage>668</fpage>. doi: <pub-id pub-id-source="author-published" pub-id-type="doi">10.1167/11.11.668</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c8" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hill</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Johnston</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Categorizing sex and identity from the biological motion of faces</article-title>. <source>Current Biology</source>, <volume>11</volume>, <fpage>880</fpage>&#8211;<lpage>885</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/S0960-9822(01)00243-3</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c9" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Knappmeyer</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Thornton</surname>, <given-names>I. M.</given-names></string-name>, &amp; <string-name><surname>B&#252;lthoff</surname>, <given-names>H. H.</given-names></string-name></person-group> (<year>2003</year>). <article-title>The use of facial motion and facial form during the processing of identity</article-title>. <source>Vision Research</source>, <volume>43</volume>, <fpage>1921</fpage>&#8211;<lpage>1936</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/S0042-6989(03)00236-0</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c10" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Knight</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Johnston</surname>, <given-names>A.</given-names></string-name></person-group> (<year>1997</year>). <article-title>The role of movement in face recognition</article-title>. <source>Visual Cognition</source>, <volume>4</volume>, <fpage>265</fpage>&#8211;<lpage>273</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/713756764</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c11" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Bruce</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Recognizing famous faces: Exploring the benefits of facial motion</article-title>. <source>Ecological Psychology</source>, <volume>12</volume>, <fpage>259</fpage>&#8211;<lpage>272</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1207/S15326969ECO1204_01</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c12" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Bruce</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2003</year>). <article-title>The role of motion in learning new faces</article-title>. <source>Visual Cognition</source>, <volume>10</volume>, <fpage>897</fpage>&#8211;<lpage>912</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/13506280344000149</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c13" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Bruce</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Repetition priming from moving faces</article-title>. <source>Memory &amp; Cognition</source>, <volume>32</volume>, <fpage>640</fpage>&#8211;<lpage>647</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.3758/BF03195855</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c14" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Bruce</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Hill</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Evaluating the effectiveness of pixelation and blurring on masking the identity of familiar faces</article-title>. <source>Applied Cognitive Psychology</source>, <volume>15</volume>, <fpage>101</fpage>&#8211;<lpage>116</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1002/1099-0720(200101/02)15:1&lt;101::AID-ACP697&gt;3.0.CO;2-7</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c15" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Christie</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Bruce</surname>, <given-names>V.</given-names></string-name></person-group> (<year>1999</year>). <article-title>The role of movement in the recognition of famous faces</article-title>. <source>Memory &amp; Cognition</source>, <volume>27</volume>, <fpage>974</fpage>&#8211;<lpage>985</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.3758/BF03201228</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c16" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Chuang</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Why are moving faces easier to recognize?</article-title> <source>Visual Cognition</source>, <volume>12</volume>, <fpage>429</fpage>&#8211;<lpage>442</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/13506280444000382</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c17" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Chuang</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Wickham</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Recognizing face identity from natural and morphed smiles</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>59</volume>, <fpage>801</fpage>&#8211;<lpage>808</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/17470210600576136</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c18" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Davies</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Exploring the role of characteristic motion when learning new faces</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>60</volume>, <fpage>519</fpage>&#8211;<lpage>526</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/17470210601117559</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c19" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lander</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hill</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kamachi</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Vatikiotis-Bateson</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2007</year>). <article-title>It&#8217;s not what you say but the way you say it: Matching faces and voices</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>33</volume>, <fpage>905</fpage>&#8211;<lpage>914</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0096-1523.33.4.905</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c20" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Maurer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Le Grand</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Mondloch</surname>, <given-names>C. J.</given-names></string-name></person-group> (<year>2002</year>). <article-title>The many faces of configural processing</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>6</volume>, <fpage>255</fpage>&#8211;<lpage>260</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/S1364-6613(02)01903-4</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c21" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>McKone</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Configural processing and face viewpoint</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>34</volume>, <fpage>310</fpage>&#8211;<lpage>327</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0096-1523.34.2.310</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c22" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Michel</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Corneille</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Rossion</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Race categorization modulates holistic face encoding</article-title>. <source>Cognitive Science</source>, <volume>31</volume>, <fpage>911</fpage>&#8211;<lpage>924</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/03640210701530805</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c23" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Michel</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rossion</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chung</surname>, <given-names>C.-S.</given-names></string-name>, &amp; <string-name><surname>Caldara</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Holistic processing is finely tuned for faces of one&#8217;s own race</article-title>. <source>Psychological Science</source>, <volume>17</volume>, <fpage>608</fpage>&#8211;<lpage>615</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1111/j.1467-9280.2006.01752.x</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c24" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Mondloch</surname>, <given-names>C. J.</given-names></string-name>, &amp; <string-name><surname>Maurer</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2008</year>). <article-title>The effect of face orientation on holistic processing</article-title>. <source>Perception</source>, <volume>37</volume>, <fpage>1175</fpage>&#8211;<lpage>1186</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1068/p6048</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c25" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Mondloch</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Pathman</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Maurer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Le Grand</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>de Schonen</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2007</year>). <article-title>The composite face effect in six-year-old children: Evidence of adult-like holistic face processing</article-title>. <source>Visual Cognition</source>, <volume>15</volume>, <fpage>564</fpage>&#8211;<lpage>577</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/13506280600859383</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c26" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Moscovitch</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Winocur</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Behrmann</surname>, <given-names>M.</given-names></string-name></person-group> (<year>1997</year>). <article-title>What is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>9</volume>, <fpage>555</fpage>&#8211;<lpage>604</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1162/jocn.1997.9.5.555</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c27" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>O&#8217;Toole</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Weimer</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Roark</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Ayyad</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Barwick</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Dunlop</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Recognizing people from dynamic and static faces and bodies: Dissecting identity with a fusion approach</article-title>. <source>Vision Research</source>, <volume>51</volume>, <fpage>74</fpage>&#8211;<lpage>83</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.visres.2010.09.035</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c28" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>O&#8217;Toole</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Roark</surname>, <given-names>D. A.</given-names></string-name>, &amp; <string-name><surname>Abdi</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Recognizing moving faces: A psychological and neural synthesis</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>6</volume>, <fpage>261</fpage>&#8211;<lpage>266</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/S1364-6613(02)01908-3</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c29" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Otsuka</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Hill</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kanazawa</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Yamaguchi</surname>, <given-names>M. K.</given-names></string-name>, &amp; <string-name><surname>Spehar</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Perception of Mooney faces by young infants: The role of local feature visibility, contrast polarity, and motion</article-title>. <source>Journal of Experimental Child Psychology</source>, <volume>111</volume>, <fpage>164</fpage>&#8211;<lpage>179</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.jecp.2010.10.014</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c30" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Otsuka</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Konishi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kanazawa</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Yamaguchi</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Abdi</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>O&#8217;Toole</surname>, <given-names>A. J.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Recognition of moving and static faces by young infants</article-title>. <source>Child Development</source>, <volume>80</volume>, <fpage>1259</fpage>&#8211;<lpage>1271</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1111/j.1467-8624.2009.01330.x</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c31" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Pike</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Kemp</surname>, <given-names>R. I.</given-names></string-name>, <string-name><surname>Towell</surname>, <given-names>N. A.</given-names></string-name>, &amp; <string-name><surname>Phillips</surname>, <given-names>K. C.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Recognizing moving faces: The relative contribution of motion and perspective view information</article-title>. <source>Visual Cognition</source>, <volume>4</volume>, <fpage>409</fpage>&#8211;<lpage>438</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/713756769</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c32" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Pilz</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Thornton</surname>, <given-names>I. M.</given-names></string-name>, &amp; <string-name><surname>B&#252;lthoff</surname>, <given-names>H. H.</given-names></string-name></person-group> (<year>2006</year>). <article-title>A search advantage for faces learned in motion</article-title>. <source>Experimental Brain Research</source>, <volume>171</volume>, <fpage>436</fpage>&#8211;<lpage>447</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1007/s00221-005-0283-8</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c33" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Ramon</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Busigny</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Rossion</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Impaired holistic processing of unfamiliar individual faces in acquired prosopagnosia</article-title>. <source>Neuropsychologia</source>, <volume>48</volume>, <fpage>933</fpage>&#8211;<lpage>944</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.neuropsychologia.2009.11.014</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c34" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Richler</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Cheung</surname>, <given-names>O. S.</given-names></string-name>, &amp; <string-name><surname>Gauthier</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Holistic processing predicts face recognition</article-title>. <source>Psychological Science</source>, <volume>22</volume>, <fpage>464</fpage>&#8211;<lpage>471</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1177/0956797611401753</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c35" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Richler</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Mack</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Gauthier</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Palmeri</surname>, <given-names>T. J.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Holistic processing of faces happens at a glance</article-title>. <source>Vision Research</source>, <volume>49</volume>, <fpage>2856</fpage>&#8211;<lpage>2861</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.visres.2009.08.025</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c36" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Richler</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Tanaka</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>D. D.</given-names></string-name>, &amp; <string-name><surname>Gauthier</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Why does selective attention to parts fail in face processing?</article-title> <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>34</volume>, <fpage>1356</fpage>&#8211;<lpage>1368</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/a0013080</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c37" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Richler</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Wong</surname>, <given-names>Y. K.</given-names></string-name>, &amp; <string-name><surname>Gauthier</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Perceptual expertise as a shift from strategic interference to automatic holistic processing</article-title>. <source>Current Directions in Psychological Science</source>, <volume>20</volume>, <fpage>129</fpage>&#8211;<lpage>134</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1177/0963721411402472</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c38" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Roark</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Barrett</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Spence</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Abdi</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>O&#8217;Toole</surname>, <given-names>A. J.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Psychological and neural perspectives on the role of motion in face recognition</article-title>. <source>Behavioral and Cognitive Neuroscience Reviews</source>, <volume>2</volume>, <fpage>15</fpage>&#8211;<lpage>46</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1177/1534582303002001002</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c39" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schiff</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Banka</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>de Bordes Galdi</surname>, <given-names>G.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Recognizing people seen in events via dynamic &#8220;mug shots&#8221;</article-title>. <source>American Journal of Psychology</source>, <volume>99</volume>, <fpage>219</fpage>&#8211;<lpage>231</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.2307/1422276</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c40" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Sergent</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1985</year>). <article-title>Influence of task and input factors on hemispheric involvement in face processing</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>11</volume>, <fpage>846</fpage>&#8211;<lpage>861</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0096-1523.11.6.846</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c41" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Tanaka</surname>, <given-names>J. W.</given-names></string-name>, &amp; <string-name><surname>Farah</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>1993</year>). <article-title>Parts and wholes in face recognition</article-title>. <source>Quarterly Journal of Experimental Psychology: Human Experimental Psychology</source>, <volume>46</volume>(<issue>A</issue>), <fpage>225</fpage>&#8211;<lpage>245</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/14640749308401045</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c42" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Tanaka</surname>, <given-names>J. W.</given-names></string-name>, &amp; <string-name><surname>Gordon</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2011</year>). <chapter-title>Features, configuration and holistic face processing</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>A.</given-names> <surname>Calder</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rhodes</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Johnson</surname></string-name>, &amp; <string-name><given-names>J.</given-names> <surname>Haxby</surname></string-name></person-group> (<role>Eds.</role>), <source>The Oxford handbook of face perception</source> (pp. <fpage>177</fpage>&#8211;<lpage>194</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c43" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Teunisse</surname>, <given-names>J.-P.</given-names></string-name>, &amp; <string-name><surname>de Gelder</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Face processing in adolescents with autistic disorder: The inversion and composite effects</article-title>. <source>Brain and Cognition</source>, <volume>52</volume>, <fpage>285</fpage>&#8211;<lpage>294</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/S0278-2626(03)00042-3</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c44" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Thornton</surname>, <given-names>I. M.</given-names></string-name>, &amp; <string-name><surname>Kourtzi</surname>, <given-names>Z.</given-names></string-name></person-group> (<year>2002</year>). <article-title>A matching advantage for dynamic human faces</article-title>. <source>Perception</source>, <volume>31</volume>, <fpage>113</fpage>&#8211;<lpage>132</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1068/p3300</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c45" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Thornton</surname>, <given-names>I. M.</given-names></string-name>, <string-name><surname>Mullins</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Banahan</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Motion can amplify the face-inversion effect</article-title>. <source>Psihologija</source>, <volume>44</volume>, <fpage>5</fpage>&#8211;<lpage>22</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.2298/PSI1101005T</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c46" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Tian</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Individual differences in holistic processing predict face recognition ability</article-title>. <source>Psychological Science</source>, <volume>23</volume>, <fpage>169</fpage>&#8211;<lpage>177</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1177/0956797611420575</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c47" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Wenger</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Ingvalson</surname>, <given-names>E. M.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Preserving informational separability and violating decisional separability in facial perception and recognition</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>29</volume>, <fpage>1106</fpage>&#8211;<lpage>1118</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0278-7393.29.6.1106</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c48" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>N. G.</given-names></string-name>, <string-name><surname>Quinn</surname>, <given-names>P. C.</given-names></string-name>, <string-name><surname>Ge</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Lee</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Rigid facial motion influences featural, but not holistic, face processing</article-title>. <source>Vision Research</source>, <volume>57</volume>, <fpage>26</fpage>&#8211;<lpage>34</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.visres.2012.01.015</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c49" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Yin</surname>, <given-names>R. K.</given-names></string-name></person-group> (<year>1969</year>). <article-title>Looking at upside-down faces</article-title>. <source>Journal of Experimental Psychology</source>, <volume>81</volume>, <fpage>141</fpage>&#8211;<lpage>145</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/h0027474</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c50" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Young</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Ellis</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Flude</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>McWeeny</surname>, <given-names>K. H.</given-names></string-name>, &amp; <string-name><surname>Hay</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Face&#8211;name interference</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>12</volume>, <fpage>466</fpage>&#8211;<lpage>475</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0096-1523.12.4.466</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c51" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Young</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Hellawell</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Hay</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>1987</year>). <article-title>Configurational information in face perception</article-title>. <source>Perception</source>, <volume>16</volume>, <fpage>747</fpage>&#8211;<lpage>759</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1068/p160747</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c52" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Yovel</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Face perception: Domain specific, not process specific</article-title>. <source>Neuron</source>, <volume>44</volume>, <fpage>889</fpage>&#8211;<lpage>898</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/S0896-6273(04)00728-7</pub-id></mixed-citation></ref>
</ref-list>
</back>
<floats-group>
<fig id="fig1">
<label>1</label>
<caption><p align="left">Illustrations of the dynamic and static target face conditions. The individual whose face appears here gave signed consent for his likeness to be published in this article.</p></caption>
<graphic copyright="inherit" id="fig1a" xlink:href="xhp_39_5_1457_fig1a.tif" xlink:type="simple"/></fig>
<fig id="fig2">
<label>2</label>
<caption><p align="left">Examples of composite faces. The upper panel faces are target aligned and misaligned faces; the bottom panel faces are foil aligned and misaligned faces. The individual whose face appears here gave signed consent for his likeness to be published in this article.</p></caption>
<graphic copyright="inherit" id="fig2a" xlink:href="xhp_39_5_1457_fig2a.tif" xlink:type="simple"/></fig>
<fig id="fig3">
<label>3</label>
<caption><p align="left">Mean accuracy of target face recognition in Experiments 1&#8211;3. Error bars represent unit standard error.</p></caption>
<graphic copyright="inherit" id="fig3a" xlink:href="xhp_39_5_1457_fig3a.tif" xlink:type="simple"/></fig>
<fig id="fig4">
<label>4</label>
<caption><p align="left">The relation of the composite effect size between the dynamic and static conditions. The solid lines represent the regression line. The dashed line is a theoretical line representing perfect correlation between the size of the composite effect in the dynamic and static conditions.</p></caption>
<graphic copyright="inherit" id="fig4a" xlink:href="xhp_39_5_1457_fig4a.tif" xlink:type="simple"/></fig>
<fig id="fig5">
<label>5</label>
<caption><p align="left">The size of the composite effect for the dynamic and static conditions in Experiments 1&#8211;3. The error bars represent unit standard error.</p></caption>
<graphic copyright="inherit" id="fig5a" xlink:href="xhp_39_5_1457_fig5a.tif" xlink:type="simple"/></fig>
<fig id="fig6">
<label>6</label>
<caption><p align="left">Mean accuracy of target composite face recognition in Experiment 4 (left). Error bars represent unit standard error. The relation of the composite effect size between the dynamic and the static conditions (right). The solid line indicates the regression line, and the dashed line is a theoretical line representing perfect correlation between the size of the composite effect in the dynamic and static conditions.</p></caption>
<graphic copyright="inherit" id="fig6a" xlink:href="xhp_39_5_1457_fig6a.tif" xlink:type="simple"/></fig>
<fig id="fig7">
<label>7</label>
<caption><p align="left">The relation between the size of part-based processing facilitated by elastic motion and the size of motion facilitation on recognition. The solid line represents the regression line.</p></caption>
<graphic copyright="inherit" id="fig7a" xlink:href="xhp_39_5_1457_fig7a.tif" xlink:type="simple"/></fig></floats-group></article>