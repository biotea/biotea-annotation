<?xml version='1.0' encoding='US-ASCII'?>
<!DOCTYPE article PUBLIC "-//APA//DTD APA Journal Archive DTD v1.0 20130715//EN" "http://xml.apa.org/serials/jats-dtds-1.0/APAjournal-archive.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" xml:lang="en" structure-type="article" dtd-version="1.0">
  
<front>
    
<journal-meta>
      
<journal-title-group>
<journal-title xml:lang="en">Journal of Personnel Psychology</journal-title>
</journal-title-group>
      
<issn pub-type="print">1866-5888</issn>
      
<issn pub-type="online">2190-5150</issn>
      
<publisher>
<publisher-name>Hogrefe Publishing</publisher-name></publisher>
    
</journal-meta>
    
    
<article-meta>
<article-id pub-id-type="apaID">prs_12_4_157</article-id>
<article-id pub-id-type="doi">10.1027/1866-5888/a000091</article-id>
<article-id pub-id-type="pi-uid">2013-34354-001</article-id>
<article-categories>
<subj-group subj-group-type="toc-heading">
<subject>Original Article</subject>
</subj-group>
        
        
      
</article-categories>
<title-group><article-title>A Meta-Analysis of Interviews and Cognitive Ability</article-title><subtitle>Back to the Future?</subtitle>
  <alt-title alt-title-type="article-banner">Original Article</alt-title>
 </title-group>
<contrib-group content-type="primary-authors">
        
<contrib contrib-type="author" corresp="yes" rid="aff1 corr1" xlink:type="simple"><string-name>
<given-names>Philip L.</given-names>
          <surname>Roth</surname></string-name>
</contrib>
        
<contrib contrib-type="author" corresp="no" rid="aff2" xlink:type="simple"><string-name>
<given-names>Allen I.</given-names>
          <surname>Huffcutt</surname></string-name>
</contrib>
        
<aff id="aff1">Department of Management, Clemson University, SC, USA</aff>
        
<aff id="aff2">Department of Psychology, Bradley University, Peoria, IL, USA</aff>
      </contrib-group><author-notes><corresp id="corr1"><addr-line>Philip L. Roth</addr-line><addr-line>Department of Management</addr-line><addr-line>Clemson University</addr-line><addr-line>P.O. Box 1305</addr-line><addr-line>Clemson, SC 29634-1305</addr-line><addr-line>USA</addr-line><phone>+1
          864 656-1039</phone><fax>+1 864 656-1039</fax><ext-link specific-use="live" xlink:href="mailto:rothp@clemson.edu" ext-link-type="email" xlink:type="simple">rothp@clemson.edu</ext-link></corresp>
</author-notes>
<pub-date pub-type="print"><string-date><year>2013</year></string-date></pub-date><volume>12</volume>
<issue>4</issue>
<fpage>157</fpage>
<lpage>169</lpage>
      
      
      
    
<permissions copyright-status="active">
<copyright-year>2013</copyright-year>
<copyright-holder>Hogrefe Publishing</copyright-holder>
</permissions>
<abstract xml:lang="en">
        
<p align="left">The topic of what interviews measure has received a great deal of attention over the years. One line of
          research has investigated the relationship between interviews and the construct of cognitive ability. A
          previous meta-analysis reported an overall corrected correlation of .40 (<xref ref-type="bibr" id="cr33-1" rid="c33">Huffcutt, Roth, &amp; McDaniel, 1996</xref>). A more recent meta-analysis reported a
          noticeably lower corrected correlation of .27 (<xref ref-type="bibr" id="cr5-1" rid="c5">Berry, Sackett, &amp;
            Landers, 2007</xref>). After reviewing both meta-analyses, it appears that the two studies
          posed different research questions. Further, there were a number of coding judgments in Berry et al. that
          merit review, and there was no moderator analysis for educational versus employment interviews. As a result,
          we reanalyzed the work by Berry et al. and found a corrected correlation of .42 for employment interviews (.15
          higher than Berry et al., a 56% increase). Further, educational interviews were associated with a
          corrected correlation of .21, supporting their influence as a moderator. We suggest a better estimate of the
          correlation between employment interviews and cognitive ability is .42, and this takes us &#8220;back to the
          future&#8221; in that the better overall estimate of the employment interviews &#8211; cognitive ability
          relationship is roughly .40. This difference has implications for what is being measured by interviews and
          their incremental validity.</p>
      
</abstract>
<kwd-group xml:lang="en">
<kwd>selection</kwd>
<kwd>interviews</kwd>
<kwd>meta-analysis</kwd>
</kwd-group>
</article-meta>
  </front>
  
<body>
<sec id="s1">
      
<p align="left">Employment interviews are one of the most frequently used
        approaches for personnel selection (e.g., <xref ref-type="bibr" id="cr1-1" rid="c1">Arvey &amp; Campion,
          1982</xref>). Reasons for interest in interviews include evidence of predictive validity (e.g.,
          <xref ref-type="bibr" id="cr41-1" rid="c41">McDaniel, Whetzel, Schmidt, &amp; Maurer, 1994</xref>;
          <xref ref-type="bibr" id="cr78-1" rid="c78">Wiesner &amp; Cronshaw, 1988</xref>), relatively small
        ethnic group differences (e.g., <xref ref-type="bibr" id="cr32-1" rid="c32">Huffcutt &amp; Roth,
          1998</xref>), and positive applicant reactions (<xref ref-type="bibr" id="cr27-1" rid="c27">Hausknecht, Day, &amp; Thomas, 2004</xref>).</p>
      
<p align="left">One important line of interviewing research involves
        meta-analysis of the interviews &#8211; cognitive ability relationship (e.g., <xref ref-type="bibr" id="cr5-2" rid="c5">Berry, Sackett, &amp; Landers, 2007</xref>; <xref ref-type="bibr" id="cr18-1" rid="c18">Cortina, Goldstein, Payne, Davison, &amp; Gilliland, 2000</xref>; <xref ref-type="bibr" id="cr33-2" rid="c33">Huffcutt, Roth, &amp; McDaniel, 1996</xref>). This relationship is nontrivial for a
        variety of reasons, including understanding what constructs interviews capture (e.g., <xref ref-type="bibr" id="cr26-1" rid="c26">Harris, 1999</xref>; <xref ref-type="bibr" id="cr31-1" rid="c31">Huffcutt,
          Conway, Roth, &amp; Stone, 2001</xref>) addressing the issue of incremental validity, and
        modeling the effects of selection systems on quality of hires and adverse impact (e.g., <xref ref-type="bibr" id="cr5-3" rid="c5">Berry et al., 2007</xref>; <xref ref-type="bibr" id="cr21-1" rid="c21">DeCorte,
          Lievens, &amp; Sackett, 2006</xref>; <xref ref-type="bibr" id="cr60-1" rid="c60">Schmidt &amp;
          Hunter, 1998</xref>; <xref ref-type="bibr" id="cr63-1" rid="c63">Schmitt, Rogers, Chan, Sheppard,
          &amp; Jennings, 1997</xref>; <xref ref-type="bibr" id="cr74-1" rid="c74">Viswesvaran &amp; Ones,
          1995</xref>). Finally, meta-analyses are often important studies because of the ability to
        address research artifacts and identify trends. Yet, such meta-analyses are also limited by the data that goes
        into them (<xref ref-type="bibr" id="cr8-1" rid="c8">Bobko &amp; Stone-Romero, 1998</xref>).</p>
      
<p align="left">The results of the most recent meta-analysis in this area by
          <xref ref-type="bibr" id="cr5-4" rid="c5">Berry et al. (2007)</xref> suggested that the interviews
        &#8211; cognitive ability correlation (corrected <italic>r</italic> = .27) was smaller than previously thought.
        In contrast, a previous meta-analysis reported an overall interviews &#8211; cognitive ability corrected
        relationship of .40, and a relationship of .38 when interviewers did not have access to cognitive ability scores
          (<xref ref-type="bibr" id="cr33-3" rid="c33">Huffcutt et al., 1996</xref>).</p>
      
<p align="left">There are many strengths of Berry et al.&#8217;s meta-analysis,
        such as considering different mechanisms that could cause range restriction (as per <xref ref-type="bibr" id="cr56-1" rid="c56">Sackett, Lievens, Berry, &amp; Landers, 2007</xref>). Further, the authors
        examined a number of moderators such as structure, content, and &#8220;cognitive saturation&#8221; of
        interviews to further understand this relationship. Indeed, one of the underlying themes of their work was the
        importance of the &#8220;&#8230; analysis of each primary study before including it in a meta-analysis&#8221;
        (Berry et al., p. 846 and 869). Unfortunately, there are also limitations in the analysis by Berry et al. One
        set of limitations involves coding judgments on a number of studies. A second limitation involves the lack of a
        moderator analysis for the variable of employment versus educational settings (more on this below). Both
        limitations could change the results of analyses and the conclusions drawn from those results.</p>
      
<p align="left">The purpose of this manuscript is to reanalyze the work of
          <xref ref-type="bibr" id="cr5-5" rid="c5">Berry et al. (2007)</xref>. We focus primarily upon
        garnering insight into the extent to which interviews are related to the construct of cognitive ability. Within
        this effort, we also highlight the importance of careful coding of data and moderator analyses on meta-analytic
        conclusions.</p>
    
</sec>
<sec id="s2">
      
<title>The Importance of Cognitive Ability in Interview Ratings</title>
      
<p align="left">Understanding the role of constructs measured by various
        predictors of job performance continues to grow in importance. Researchers have suggested that understanding the
        constructs that underlie predictors is important, and that understanding underlying constructs can help explain
        why certain tests predict job performance and why certain tests are associated with different levels of adverse
        impact (e.g., <xref ref-type="bibr" id="cr2-1" rid="c2">Arthur &amp; Villado, 2008</xref>, see also
          <xref ref-type="bibr" id="cr7-1" rid="c7">Bobko, Roth, &amp; Potosky, 1999</xref>).</p>
      
<sec id="s3" disp-level="subsect1">
        
<title>Our Logical Position</title>
        
<p align="left">Logically, we suggest that cognitive ability should relate, at
          least moderately, to ratings in a large portion of interviews (<xref ref-type="bibr" id="cr24-1" rid="c24">Hambrick, 2007</xref>; see <xref ref-type="bibr" id="cr33-4" rid="c33">Huffcutt et al.,
            1996</xref>, for more discussion of this). First, a variety of questions will elicit
          information related to cognitive ability. Technical questions, problem-solving questions, and questions
          related to learning about policies and procedures are likely to relate to applicant cognitive ability
            (<xref ref-type="bibr" id="cr31-2" rid="c31">Huffcutt et al., 2001</xref>). This effect could be
          direct in that technical or problem-solving questions could partially or largely assess cognitive ability.
          Further, some questions may elicit cognitive ability indirectly, such as those that require candidates to
          describe past accomplishments, under the premise that higher cognitive ability may have contributed (at least
          in part) to that better performance (<xref ref-type="bibr" id="cr34-1" rid="c34">Hunter &amp; Hunter,
            1984</xref>).</p>
        
<p align="left">Second, we suggest that cognitive ability is likely to relate
          to answers to questions not overtly targeting cognitive ability. For instance, higher levels of cognitive
          ability should allow interviewees to: (a) understand questions more completely, (b) organize relevant
          experiences or intentions more cogently, and (c) demonstrate faster responses due to higher mental processing
          speeds. For example, <xref ref-type="bibr" id="cr31-3" rid="c31">Huffcutt et al. (2001)</xref>
          reported correlations of approximately .2 between cognitive and personality-related interview ratings for the
          factors of extraversion (.21), conscientiousness (.16), agreeableness (.23), and emotional stability (.21),
          even though it is generally accepted that personality and cognitive ability are largely orthogonal
            (<xref ref-type="bibr" id="cr45-1" rid="c45">Mount &amp; Barrick, 1995</xref>). Thus, even
          interview ratings of constructs generally thought not to have overlap with cognitive ability tend to relate
          somewhat to cognitive ability.</p>
        
<p align="left">Third, higher levels of cognitive ability may allow
          individuals to better use impression management techniques (<xref ref-type="bibr" id="cr3-1" rid="c3">Barrick,
            Shaffer, &amp; DeGrassi, 2009</xref>). That is, cognitive ability may allow interviewees to
          more accurately examine feedback from interviewers as they engage in tactics such as ingratiation and
          self-promotion (<xref ref-type="bibr" id="cr52-1" rid="c52">Robie, Komar, &amp; Brown, 2010</xref>).
          Finally, interview ratings often appear to be based on single factors and/or general impressions
            (<xref ref-type="bibr" id="cr54-1" rid="c54">Roth &amp; Campion, 1992</xref>, see also related
          work by <xref ref-type="bibr" id="cr39-1" rid="c39">Lance, Lapointe, and Fisicaro (1994)</xref>.
          Cognitive ability could easily saturate such general impressions.</p>
        
<p align="left">In summary, our logical position suggests that the majority of
          interview overall ratings will likely be related to cognitive ability. Further, we believe it will be
          extremely difficult to eliminate the influence of cognitive ability, such that even interviews specifically
          designed to avoid or minimize its influence will have some relationship to cognitive ability. We also note
          that our logical position suggests that other predictors such as assessment centers, work samples, and
          situational judgment tests may also be at least moderately related to cognitive ability (<xref ref-type="bibr" id="cr20-1" rid="c20">Dayan, Fox, &amp; Kasten, 2008</xref>; <xref ref-type="bibr" id="cr53-1" rid="c53">Roth, Bobko, &amp; McFarland, 2005</xref>; <xref ref-type="bibr" id="cr77-1" rid="c77">Whetzel, McDaniel, &amp; Nguyen, 2008</xref>). Yet our primary interest is the interviews
          &#8211; cognitive ability relationship and we focus on a rigorous empirical test of that relationship.</p>
      
</sec>
    
</sec>
<sec id="s4">
      
<title>Previous Meta-Analyses on Interviews and Cognitive Ability</title>
      
<p align="left">Three previous meta-analyses have examined the extent to which
        interviews capture cognitive ability. <xref ref-type="bibr" id="cr33-5" rid="c33">Huffcutt et al.
          (1996)</xref> reported a fully corrected correlation of .40 for their overall analysis. Further,
        Huffcutt et al. isolated studies in which interviewers did not appear to have access to test scores, and
        reported a fully corrected <italic>r</italic> of .38. The latter estimate is important given a reasonable
        judgment call made by <xref ref-type="bibr" id="cr5-6" rid="c5">Berry et al. (2007)</xref> to exclude
        studies in which interviewers likely had access to applicants&#8217; cognitive ability scores. Thus, the value
        of .38 will also serve as one of the benchmarks later in this study.</p>
      
<p align="left">Two other meta-analyses focused on how interviews are related to
        a variety of constructs (e.g., cognitive ability, personality, job knowledge). <xref ref-type="bibr" id="cr57-1" rid="c57">Salgado and Moscoso (2002)</xref> reported fully corrected correlations of .28 and .41
        for the interviews &#8211; cognitive ability relationship for structured (they used the term
        &#8220;behavioral&#8221;) and unstructured (&#8220;conventional&#8221;) interviews, respectively.
          <xref ref-type="bibr" id="cr18-2" rid="c18">Cortina et al. (2000)</xref> reported a value of .27
        (corrected only for range restriction) for highly structured interviews. Given that both meta-analyses focused
        on multiple variables, the authors were not able to report many moderator analyses, such as whether test scores
        were definitely or plausibly available to interviewers.</p>
      
<p align="left">Overall, there is some divergence in results for previous
        analyses. However, the work by <xref ref-type="bibr" id="cr33-6" rid="c33">Huffcutt et al.
          (1996)</xref> stands out given it is the most highly cited article and it is the primary
        reference point against which <xref ref-type="bibr" id="cr5-7" rid="c5">Berry et al. (2007)</xref>
        compared their results. Berry et al.&#8217;s work is the most recent meta-analysis and stands as a potentially
        weighty estimate of the relationship. As a result, more analysis is needed to resolve differences in this
        literature between the competing estimates of the interviews &#8211; cognitive ability relationship to inform
        the field of the best estimate(s) of this relationship.</p>
    
</sec>
<sec id="s5">
      
<title>The Most Recent Meta-Analysis</title>
      
<p align="left"><xref ref-type="bibr" id="cr5-8" rid="c5">Berry et al.
          (2007)</xref> reported a fully corrected mean <italic>r</italic> of .27 between interviews and
        cognitive ability. They also reported a fully corrected mean <italic>r</italic> of .29 for studies in which
        participants were job applicants (i.e., applicant samples with little or no range restriction). Such results are
        logically important, as they suggest that interviews capture less cognitive ability variance than previously
        thought. Such results are also important for the incremental validity of interviews (which we discuss below).
        Important methodological issues are also raised as the authors state &#8220;&#8230; of most importance to
        meta-analysis in general is our treatment of range restriction and the effect this had on corrected
        estimates&#8221; (<xref ref-type="bibr" id="cr5-9" rid="c5">Berry et al., 2007, p. 863</xref>). They
        go on to discuss how different range restriction mechanisms might influence research results (more on this
        below).</p>
      
<p align="left">There are several important issues about <xref ref-type="bibr" id="cr5-10" rid="c5">Berry et al. (2007)</xref> that deserve further consideration, as they bring
        data to bear on the question of how highly interviews are related to cognitive ability. We address these issues
        as our primary focus below. Secondarily, and consistent with the purpose of our manuscript, we highlight the
        importance of these issues in a broader sense to meta-analytic researchers.</p>
      
<sec id="s6" disp-level="subsect1">
        
<title>Inclusion Criteria</title>
        
<p align="left">The issue of inclusion criteria is an important issue in
          meta-analysis (<xref ref-type="bibr" id="cr17-1" rid="c17">Cooper, 1982</xref>; <xref ref-type="bibr" id="cr55-1" rid="c55">Rothstein, 2003</xref>; <xref ref-type="bibr" id="cr76-1" rid="c76">Wanous,
            Sullivan, &amp; Malinak, 1989</xref>). The process begins by clearly defining the population of
          interest (<xref ref-type="bibr" id="cr46-1" rid="c46">Murphy &amp; Newman, 2003</xref>). For
          example, some entrepreneurial researchers have compared the risk propensity of entrepreneurs and managers
          (e.g., <xref ref-type="bibr" id="cr65-1" rid="c65">Stewart &amp; Roth, 2001</xref>), while others
          have compared the risk propensity of high-growth and low-growth entrepreneurs (e.g., <xref ref-type="bibr" id="cr43-1" rid="c43">Miner &amp; Raju, 2004</xref>). The two approaches have yielded markedly
          different results (<xref ref-type="bibr" id="cr43-2" rid="c43">Miner &amp; Raju, 2004</xref>;
            <xref ref-type="bibr" id="cr66-1" rid="c66">Stewart &amp; Roth, 2004</xref>, see also
            <xref ref-type="bibr" id="cr71-1" rid="c71">Van Iddekinge, Roth, Raymark, &amp; Odle-Dusseau,
            2012</xref> for the importance of inclusion criteria).</p>
        
<p align="left">A major departure in the <xref ref-type="bibr" id="cr5-11" rid="c5">Berry et al. (2007)</xref> and <xref ref-type="bibr" id="cr33-7" rid="c33">Huffcutt et
            al. (1996)</xref> interview meta-analyses involves the research question (and the types of
          interviews) the researchers cumulated. Huffcutt et al. were clear that only employment-related interviews were
          included (see their p. 462). In contrast, Berry et al. were explicit in including both educational and
          employment interviews (p. 842). That is, Berry et al. used the results of studies in which individuals were
          interviewed for entrance into undergraduate and graduate schools, as well as interviews designed for
          employment purposes.</p>
        
<p align="left">Past selection narrative reviews and meta-analyses have
          generally focused on employment interviews rather than on educational interviews. For example, the titles of
          several past influential literature reviews reveal the focus of the work: <italic>The employment interview: A
            summary and review of recent research</italic> (<xref ref-type="bibr" id="cr1-2" rid="c1">Arvey &amp; Campion,
            1982</xref>), <italic>Structuring employment interviews to improve reliability, validity, and
            users&#8217; reactions</italic> (<xref ref-type="bibr" id="cr13-1" rid="c13">Campion et al.,
            1997</xref>), <italic>Beyond employment interview validity: A comprehensive narrative review of
            recent research and trends over time</italic> (<xref ref-type="bibr" id="cr48-1" rid="c48">Posthuma, Morgeson,
            &amp; Campion, 2002</xref>, see also work by <xref ref-type="bibr" id="cr25-1" rid="c25">Harris,
            1989</xref>, and <xref ref-type="bibr" id="cr79-1" rid="c79">Williamson, Campion, Malos, Roehling,
            &amp; Campion, 1997</xref>). Meta-analyses on interview validity (e.g., <xref ref-type="bibr" id="cr30-1" rid="c30">Huffcutt &amp; Arthur, 1994</xref>; <xref ref-type="bibr" id="cr41-2" rid="c41">McDaniel et al., 1994</xref>) and ethnic group differences (<xref ref-type="bibr" id="cr32-2" rid="c32">Huffcutt &amp; Roth, 1998</xref>) have also focused on employment
          interviews. Overall, it appears that most prior work in this area has focused on employment interviews. A
          focus on employment interviews also allows for a consistent inclusion criterion for correlations and effect
          sizes in meta-analytic matrix investigations of organizational selection systems (e.g., <xref ref-type="bibr" id="cr7-2" rid="c7">Bobko et al., 1999</xref>; <xref ref-type="bibr" id="cr21-2" rid="c21">DeCorte
            et al., 2006</xref>, <xref ref-type="bibr" id="cr22-1" rid="c22">DeCorte, Lievens, &amp; Sackett,
            2007</xref>).</p>
        
<p align="left">The inclusion of educational interviews in an organizational
          meta-analysis may also make important assumptions. Most employment interviews are designed to assess the
          knowledge, skills, and abilities (KSAs) required by a given job or job family (<xref ref-type="bibr" id="cr31-4" rid="c31">Huffcutt et al., 2001</xref>). Educational interviews likely target skills needed in
          various stages of education. However, the overlap in KSAs assessed by interviews conducted in these two
          settings is unknown. Therefore, researchers interested in including educational samples in their analyses
          would appear to bear the logical burden of showing similarity of KSAs before making such a decision (or
          perhaps conducting moderator analyses).</p>
        
<p align="left">Finally, we would expect educational interviews to have lower
          correlations with cognitive ability. Most of the educational interviews in this literature were specifically
          and explicitly designed to minimize the role of cognitive ability, and authors reported this emphasis (e.g.,
            <xref ref-type="bibr" id="cr64-1" rid="c64">Shahani, Dipboye, &amp; Gehrlein, 1991</xref>). Also,
            <xref ref-type="bibr" id="cr12-1" rid="c12">Calkins, Richards, McCanse, Burgess, and Willoughby
            (1974)</xref> explicitly designed interviews to focus on noncognitive variables in order to
          complement the use of cognitive test scores and minimize adverse impact in admissions. In contrast, there was
          little information in the employment studies to suggest that cognitively related questions and ratings were
          minimized by design. As noted earlier, this does not mean that we expect such educational correlations to be
          zero. Rather, we expect interview ratings from educational studies to generally be associated with smaller
          correlations with measures of cognitive ability than the employment studies. A reviewer asked us to further
          clarify our position on this issue. We are not suggesting that learning ability is more or less important in
          either employment or educational settings. Rather, our argument is that the design of educational studies
          incorporated into current meta-analyses of the interviews &#8211; cognitive ability relationship will likely
          be associated with smaller correlations given a general trend toward minimizing cognitive ability in such
          studies.</p>
      
</sec>
      
<sec id="s7" disp-level="subsect1">
        
<title>Coding</title>
        
<p align="left">Extracting the data and determining how to code it can
          influence analyses (<xref ref-type="bibr" id="cr6-1" rid="c6">Bobko &amp; Roth, 2008</xref>;
            <xref ref-type="bibr" id="cr8-2" rid="c8">Bobko &amp; Stone-Romero, 1998</xref>). In particular,
          the extraction and coding of data can involve judgment (<xref ref-type="bibr" id="cr76-2" rid="c76">Wanous et
            al., 1989</xref>). Such judgments have also been categorized as the &#8216;data evaluation
          phase&#8217; in the education and applied psychology literatures (<xref ref-type="bibr" id="cr17-2" rid="c17">Cooper, 1982</xref>; <xref ref-type="bibr" id="cr55-2" rid="c55">Rothstein,
            2003</xref>). While there has been discussion about how to index coding agreement (e.g.,
            <xref ref-type="bibr" id="cr11-1" rid="c11">Burke &amp; Landis, 2003</xref>), relatively less
          literature directly and empirically addresses how the coding of data can influence meta-analytic conclusions.
          In one of the few studies in this area, <xref ref-type="bibr" id="cr10-1" rid="c10">Bullock and Svyantek
            (1985)</xref> noted and demonstrated that the quality of meta-analytic conclusions is dependent
          on the clarity and execution of the coding scheme.</p>
        
<p align="left">We examined some of <xref ref-type="bibr" id="cr5-12" rid="c5">Berry et al.&#8217;s (2007)</xref> decisions regarding the extraction of the data from
          primary studies. We also coded relevant studies to examine employment versus educational interviews as a
          possible moderator to continue to add to our understanding of the interviews &#8211; cognitive ability
          relationships.</p>
      
</sec>
    
</sec>
<sec id="s8">
      
<title>Focus of Our Reanalysis</title>
      
<p align="left"><xref ref-type="bibr" id="cr5-13" rid="c5">Berry et al.
          (2007)</xref> used an innovative taxonomy of range restriction mechanisms to address the various
        mechanisms that can cause restriction in a selection context. To facilitate analysis, they grouped the primary
        studies into three categories of studies that could be analyzed. The first category comprised applicant pool
        studies that suffer from little or no range restriction. Studies in this condition involved subjects who had not
        been screened on another predictor of job performance (e.g., a situational judgment test or a work sample
        exercise) before being interviewed. That is, an interview and a test of cognitive ability could be administered
        at the first stage of selection. Given that many researchers correct results back to the (unscreened) applicant
        pool, it appears that there may be little or no need for correction in such studies.</p>
      
<p align="left">The second category comprised studies that suffer from direct
        range restriction. Such studies often involved multiple hurdles in which the test of cognitive ability or the
        interview was administered first, and the correlation between the two variables was computed on the individuals
        who passed the first hurdle. For example, an organization might screen on a test of cognitive ability and
        interview the higher scoring individuals (thanks to a reviewer for suggesting the use of examples and greater
        discussion of range restriction issues). Thus, it is clear there is restriction of range in these studies.
        Further, there is often information available to understand the mechanism for restriction and to correct study
        values using this information.</p>
      
<p align="left">The third category comprised job incumbent studies in which the
        interviews &#8211; cognitive ability relationship was estimated using data from job incumbents.
          <xref ref-type="bibr" id="cr5-14" rid="c5">Berry et al. (2007)</xref> justified the use of indirect
        range restriction correction for such a condition because nearly all organizations use interviews in selection,
        but the interviews used in actual selection may not be those studied with an incumbent sample.</p>
      
<p align="left">Accordingly, we find it hard to endorse using studies in the
        incumbent category, especially given the importance of understanding the mechanisms that actually caused range
        restriction. A variety of mechanisms could induce range restriction in incumbent studies. First, initial
        selection could be based on a variety of other instruments (e.g., situational judgment tests, personality
        tests), and it is often not possible to know which instruments were used in incumbent studies (or the level of
        range restriction) or if there were multiple selection systems used across time in hiring incumbents. Second,
        there could be restriction due to voluntary turnover, involuntary turnover, and/or promotions
          (<xref ref-type="bibr" id="cr50-1" rid="c50">Pritchard, Maxwell, &amp; Jordon, 1984</xref>). Data on
        such events are seldom (if ever) reported in primary studies.</p>
      
<p align="left">Thus, it would appear virtually impossible to clearly understand
        the nature and influence of range restriction in many incumbent studies. Correcting for unknown mechanisms
        appears to be inconsistent with <xref ref-type="bibr" id="cr5-15" rid="c5">Berry et al.&#8217;s
          (2007)</xref> procedure to understand the specific mechanisms inducing range restriction and then
        carefully correct for those mechanisms. Further, correcting for only one possible mechanism (e.g., another type
        of interview) could downwardly bias correlations because other mechanisms causing restriction are not accounted
        for in the correction process. All told, we do not believe it is possible to accurately correct estimates in
        this category of studies (given the logic of the original analysis). Thus, we do not consider incumbent studies
        in our reanalysis.</p>
      
<p align="left">In sum, we reanalyze all the studies from <xref ref-type="bibr" id="cr5-16" rid="c5">Berry et al. (2007)</xref> in their applicant pool and direct range
        restriction categories. We explicitly focus on the importance of extracting and coding information, and we also
        examine the role of educational versus employment interviews.</p>
    
</sec>
<sec id="s9">
      
<title>Method</title>
      
<p align="left">We started our analysis with the statistics provided in Table 1
        of <xref ref-type="bibr" id="cr5-17" rid="c5">Berry et al. (2007)</xref>.<xref ref-type="fn" id="fnc1-1" rid="fn1"><sup location="post">1</sup></xref> That is, we examined all studies for the two conditions (i.e., applicant and
        direct range restriction) where researchers could understand the range restriction mechanism and model the
        mechanism. The first author retrieved all of the studies from these two conditions and reviewed them to check
        the coding by Berry et al. If there were questions, the first author emailed the authors of the study to clarify
        specific questions or to ask for more information. Once the initial data gathering was complete, the first
        author shared notes, emails, and any other information with the second author to check coding results. Below we
        note modifications to the data from Berry et al.&#8217;s Table 1 following discussion between the two
          authors.<xref ref-type="fn" id="fnc2-1" rid="fn2"><sup location="post">2</sup></xref> Both authors were professors with
        experience on multiple previous meta-analyses.</p>
      
<p align="left">We also used reliability estimates for interviews and cognitive
        ability tests that should be highly similar to the estimates used by <xref ref-type="bibr" id="cr5-18" rid="c5">Berry et al. (2007)</xref>. Like Berry et al., we examined the distribution of values for
        interview unreliability from Conway et al. (<xref ref-type="bibr" id="cr15-1" rid="c15">1995</xref>,
        see Table 4) and made our best estimates how to classify the interview from each study (as did Berry et al.). We
        thank Berry et al. for their professional and cordial sharing of their reliability data with us.</p>
    
</sec>
<sec id="s10">
      
<title>Results: Analysis of Applicant Pool Studies</title>
      
<p align="left">We first attempted to recreate the results reported by
          <xref ref-type="bibr" id="cr5-19" rid="c5">Berry et al. (2007)</xref>. We report our analyses of
        applicant pool studies in the first row of <xref ref-type="table" id="tbc1-1" rid="tbl1">Table
          1</xref>. We found the same observed mean of .24, and our
        corrected mean of .292 matches to two decimals the corrected value of .29 from Berry and colleagues. Thus, we
        were able to recreate their results. The 80% credibility interval for correlations ranged from .13 to .46. Such
        a range of scores is consistent with one or more potential moderators (thanks to a reviewer for suggesting we
        note this result). Next, we examined the influence of including/excluding five studies (or sets of studies) on
        applicant results.<xref ref-type="table-anchor" rid="tbl1"/></p>
      
<p align="left">First, we note several points about <xref ref-type="bibr" id="cr64-2" rid="c64">Shahani et al. (1991)</xref>, who studied an educational interview for
        college admission. Many students could not be interviewed, and the mechanisms and correlates of such selective
        inclusion are unclear. The authors indicated that, &#8220;Of 3,873 applicants, 2,583 (65%) participated in an
        unstructured interview for the year in which the study was conducted. Students who were not interviewed received
        a hardship waiver (e.g., did not live near an alumnus interviewer, could not travel to the university) or
        self-selected themselves out of the admissions process&#8221; (p. 1050). It is unclear why some individuals
        withdrew from the interview process and if there was range restriction. Thus, it is unclear if the study
        belonged to the applicant condition. A second important issue is that this interview was designed to focus on
        KSAs such as oral communication skills in order to augment other parts of the college selection process that
        focused on academic and cognitive skills (we return to this issue below).</p>
      
<p align="left">In addition, the sample size for <xref ref-type="bibr" id="cr64-3" rid="c64">Shahani et al. (1991)</xref> (<italic>N</italic> = 2,583) represents 37% of the entire
        applicant pool condition, and approximately 29% of the entire sample on which <xref ref-type="bibr" id="cr5-20" rid="c5">Berry et al.&#8217;s (2007)</xref> analyses were based. Thus, the results of this study
        could have had an undue influence on the overall results. Meta-analysts should consider the role of such
        potential influential cases (<xref ref-type="bibr" id="cr40-1" rid="c40">Lipsey &amp; Wilson,
          2001</xref>), such as by reporting analyses with and without such large samples (e.g.,
          <xref ref-type="bibr" id="cr47-1" rid="c47">Ones, Viswesvaran, &amp; Schmidt, 1993</xref>). We
        temporarily removed Shahani et al. for the reasons noted above. Doing so increased the corrected correlation
        between interviews and cognitive ability to .35, confirming that this study was at least somewhat influential.
        Later, we compare how this study, as an educational study, contrasted to employment interview results (as we
        address the moderator issue below).</p>
      
<p align="left">Second, placing <xref ref-type="bibr" id="cr68-1" rid="c68">Tziner
          and Dolan (1982)</xref> in the applicant condition may involve a coding error. When describing
        the interview, Tziner and Dolan indicated that scores varied from 1 (low) to 7 (high) but that &#8220;&#8230;
          <italic>only</italic> (italics added) scores of 4 or more were represented in the sample because candidates
        who scored less were not accepted for training&#8221; (p. 271). Further, there was also restriction based on
        the test of cognitive ability (p. 271). Thus, this study is subject to double range restriction and belongs to
        Berry et al.&#8217;s range restriction on both predictors&#8217; category (Category 4). We removed this study
        from our analysis, which did not change our overall estimate appreciably.</p>
      
<p align="left">Third, we removed <xref ref-type="bibr" id="cr28-1" rid="c28">Hilliard (2001)</xref> from the applicant pool condition, as the analyses were not conducted at
        the entire applicant pool level. Hilliard wrote &#8220;The interview is the second stage of the selection
        process for job applicants &#8211; the first stage is a job specific written test, which candidates must pass
        to proceed to the interview&#8221; (p. 35) and &#8220;All qualified applicants were invited to attend the
        written test &#8230;. The candidates who obtained passing scores on the written test were invited to schedule
        an interview&#8221; (p. 45). Further, Hilliard explained that &#8220;&#8230; the department reviews the
        scores (of the written test), and will usually use 70% as the pass/fail score&#8221; (p. 37). Removing
        Hilliard&#8217;s estimate increased the interviews &#8211; cognitive ability correlation for this category to
        .36 (rounded to two decimal places).</p>
      
<p align="left">Fourth, we removed the results of the two studies by
          <xref ref-type="bibr" id="cr44-1" rid="c44">Motowidlo et al. (1992)</xref>. The description of the
        participants was somewhat ambiguous, so we contacted the primary authors to determine if there had been any
        previous screening on other predictors. For their first study, with a correlation of .07 (<italic>N</italic> =
        107), the authors noted the participants were likely screened on a test of cognitive ability and maybe on a
        situational judgment test. In addition, it appears that some of the interviewees volunteered to take part in the
        study even though they were told they would not be considered for the job. That is, they were not truly
        applicants (see p. 574).</p>
      
<p align="left">The second study from <xref ref-type="bibr" id="cr44-2" rid="c44">Motowidlo et al. (1992)</xref>, with a correlation of .17 (<italic>N</italic> = 875), was
        definitely screened based on a test of cognitive ability and a situational judgment test according to the
        authors. Thus, it appears that this sample of participants was not comprised of job applicants. As a result, we
        removed both samples from our calculations.</p>
      
<p align="left">Finally, we also changed the reliability of <xref ref-type="bibr" id="cr69-1" rid="c69">Van Iddekinge and Eidson (2005)</xref> to .75 (instead of .92). We
        corresponded with the authors, who noted the interview was a behavioral interview with no prohibition against
        probing. The corrected mean correlation changed to .42.</p>
      
<p align="left">In summary, the new mean corrected <italic>r</italic> between
        interviews and cognitive ability tests is .42. We note two points about this value. First, it is based solely on
        employment interviews administered to job applicants. We can contrast this figure to the single study of an
        educational interview (<xref ref-type="bibr" id="cr64-4" rid="c64">Shahani et al., 1991</xref>) in
        which the observed <italic>r</italic> was .16. Correcting this value for unreliability in the interview using an
        estimate of .72 (which is also how <xref ref-type="bibr" id="cr5-21" rid="c5">Berry et al.,
          2007</xref>, coded it), and for unreliability in the cognitive test using an estimate of .90,
        yields a corrected correlation of approximately .20. This result suggests that interview type (employment vs.
        educational) may be a potential moderator variable (we return to this issue later). Second, the employment
        correlation of .42 is quite similar to the earlier overall value of .40, or the value of .38 which is based only
        upon employment studies in which interviewers did not have access to the cognitive ability scores
          (<xref ref-type="bibr" id="cr33-8" rid="c33">Huffcutt et al., 1996</xref>).</p>
    
</sec>
<sec id="s11">
      
<title>Results: Direct Range Restriction Studies</title>
      
<p align="left">We also examined the direct range restriction study category of
          <xref ref-type="bibr" id="cr5-22" rid="c5">Berry et al. (2007)</xref>. Again, we used all the values
        from their <xref ref-type="table" id="tbc1-2" rid="tbl1">Table 1</xref>. We both found a mean uncorrected
        correlation of .14 noted in <xref ref-type="table" id="tbc2-1" rid="tbl2">Table 2</xref>, which matches Berry et al.&#8217;s estimate (our mean was .1446). We found a
        corrected mean of .243 which is similar to Berry et al.&#8217;s corrected mean correlation of .24. The 80%
        credibility interval for correlations ranged from .05 to .43. This range of correlations is consistent with one
        or more potential moderators. Again, we note the importance of several studies or sets of studies.<xref ref-type="table-anchor" rid="tbl2"/></p>
      
<p align="left">First, we removed two studies that were based on incumbent
        samples. <xref ref-type="bibr" id="cr9-1" rid="c9">Bosshardt (1993)</xref> wrote that &#8220;&#8230;
        the interview and criterion measures were administered to samples of electricians and supervisors&#8221; (p.
        100) and that &#8220;The general sampling strategy was to select ten electricians (those with the least job
        tenure) from each of the 12 company plants&#8221; (p. 117). <xref ref-type="bibr" id="cr72-1" rid="c72">Van
          Iddekinge, Roth, Sager, and Heffner (2005)</xref> also used job incumbents. Excluding these two
        studies resulted in a corrected mean interviews &#8211; cognitive ability correlation of .28.</p>
      
<p align="left">Second, <xref ref-type="bibr" id="cr16-1" rid="c16">Conway and
          Peneno (1999)</xref> studied students applying for the job of resident hall assistant and found a
        negative interview &#8211; cognitive ability correlation (<italic>r</italic> = &#8722;.05, <italic>N</italic>
        = 145). The students were screened on grade point average (GPA). Thus, the source of range restriction is
          <italic>indirect</italic> rather than direct since screening occurred on GPA (see <xref ref-type="bibr" id="cr61-1" rid="c61">Schmidt, Oh, &amp; Le, 2006</xref> for an extended discussion on this
        issue). In addition, GPA may not be a good proxy for mental ability. For example, correlations between subtests
        of the Graduate Record Exam (GRE) and undergraduate GPA range from only .18&#8211;.24 (<xref ref-type="bibr" id="cr38-1" rid="c38">Kuncel, Hezlett, &amp; Ones, 2001</xref>). Overall, we believe it is
        appropriate to remove this study, and doing so increased the corrected correlation to .32.</p>
      
<p align="left">Third, we think it is appropriate to add three studies to this
        category to accurately reflect mechanisms of range restriction. Readers might recall that <xref ref-type="bibr" id="cr28-2" rid="c28">Hilliard (2001)</xref> involved direct range restriction on interviews from
        a first hurdle cognitive ability test. Thus, we added this result to our analyses (<italic>r</italic> = .10,
          <italic>N</italic> = 149). We also added the two studies by Van Iddekinge and Henry (<xref ref-type="bibr" id="cr70-1" rid="c70">2006</xref>: Study 1, <italic>r</italic> = .25, <italic>N</italic> = 203;
        Study 2, <italic>r</italic> = .23, <italic>N</italic> = 187). Berry et al. coded it as plausible that the
        interviewers had access to the test scores. We understand how Berry et al. came to this conclusion, as Van
        Iddekinge and Henry did not mention the issue of access. We contacted the authors, and they clearly stated that
        the interviewers did not have access to test scores. Adding in these studies, the resulting mean corrected
          <italic>r</italic> was still .32.</p>
      
<p align="left">Fourth, we were conflicted about including <xref ref-type="bibr" id="cr36-1" rid="c36">Johnson (1990)</xref> in our analyses. This work contributed three small
        samples (Study 1, <italic>r</italic> = .13, <italic>N</italic> = 31; Study 2, <italic>r</italic> = .24,
          <italic>N</italic> = 31; and Study 3, <italic>r</italic> = .08, <italic>N</italic> = 30). It is clear that
        MCAT scores were used for selection, inducing direct range restriction. Yet, Johnson indicated that GPA also was
        used in medical school admissions (p. 18). In this case, the study should be categorized as having multiple
        range restriction mechanisms, and therefore could be placed in Berry et al.&#8217;s double range restriction
        category (which they did not analyze). Others would suggest that the combination of factors would best be
        characterized as indirect range restriction (see <xref ref-type="bibr" id="cr61-2" rid="c61">Schmidt et al.,
          2006</xref>). We tentatively retained this study to make every reasonable effort to agree with
        Berry et al.<xref ref-type="fn" id="fnc3-1" rid="fn3"><sup location="post">3</sup></xref></p>
      
<p align="left">Fifth, the study by <xref ref-type="bibr" id="cr75-1" rid="c75">Walters, Miller, and Ree (1993)</xref> reported on the use of an interview for selecting
        aircraft pilot trainees. In the first hurdle, applicants were selected based on: (a) cognitive ability from the
        AFQT and BAT tests, (b) personality variables such as self-confidence and risk taking, and c) response speed in
        responding to certain items. Thus, it is not restricted based only on direct range restriction of cognitive
        ability or interviews (since two personality variables were also used in selection).</p>
      
<p align="left">More importantly, we could not find any interview &#8211;
        cognitive ability correlations in this article. Berry et al. reported that <italic>r</italic> = .05
          (<italic>N</italic> = 223). Correspondence with one author of the study with Huffcutt (in <xref ref-type="bibr" id="cr30-2" rid="c30">1994</xref>) revealed an interview &#8211; cognitive ability correlation
        of .74, though it was unclear if this was corrected or uncorrected (further attempts at correspondence yielded
        no new information). Further, <xref ref-type="bibr" id="cr75-2" rid="c75">Walters et al. (1993)</xref>
        wrote that the tests and interview likely measured the same set of constructs (p. 36). This also suggests that a
        correlation of .05 is highly unlikely. Based on the likelihood of incorrect coding and the inability to
        implement accurate corrections, we omitted it from our analyses. The new corrected mean <italic>r</italic>
        without Walters et al. is .35. Thus, it appears the judgment calls of how to handle several studies changed the
        point estimates of the corrected correlation from .24 to .35.</p>
      
<p align="left">Sixth, we checked Berry et al.&#8217;s reliabilities versus our
        own. We changed the reliability coding for the unstructured interview in <xref ref-type="bibr" id="cr73-1" rid="c73">Villanova et al. (1994)</xref> to .69 (from .766). This changed the corrected validity
        to .36, though the change is not large.</p>
      
<sec id="s12" disp-level="subsect1">
        
<title>Moderator Analyses</title>
        
<p align="left">We also conducted moderator analyses to examine the influence
          of employment versus educational interviews (within the direct range restriction category of studies). We
          coded studies as employment related if the participants were being screened for work in an organization. We
          coded studies as education related if the participants were being screened for admission into a college or
          university. The educational studies are associated with a corrected mean <italic>r</italic> of .29
            (<italic>k</italic> = 6, <italic>N</italic> = 747) for all studies including <xref ref-type="bibr" id="cr37-1" rid="c37">Klehe and Latham (2005)</xref>. However, Klehe and Latham used an interview to
          predict teamwork in an MBA course, so some researchers might not consider this an educational study since it
          did not study admission into a university. Without this study, the corrected mean <italic>r</italic> was .30
            (<italic>k</italic> = 5, <italic>N</italic> = 668). Employment interview studies are associated with a
          corrected mean <italic>r</italic> of .41 (<italic>k</italic> = 5, <italic>N</italic> = 840). Thus, there again
          appears to be some evidence of moderation. Sample sizes are somewhat small, so we interpret such results with
          some caution. It is also interesting to note that the employment studies converge very nicely with the
          applicant employment studies, as both produce corrected interviews &#8211; ability correlations in the low
          .40 s.</p>
      
</sec>
    
</sec>
<sec id="s13">
      
<title>Overall Estimates of the Interview &#8211; Cognitive Ability Relationship</title>
      
<p align="left">We conclude our reanalysis by computing an overall estimate of
        the interviews &#8211; cognitive ability relationship in <xref ref-type="table" id="tbc3-1" rid="tbl3">Table
          3</xref> (see also our data in <xref ref-type="table" id="tbc4-1" rid="tbl4">Table 4</xref>). We combined the applicant
        condition and direct range restriction condition studies to find an overall estimate for employment interviews
        of .42 (<italic>k</italic> = 12, <italic>N</italic> = 3,824). This value is similar to (though slightly larger
        than) the mean of .38 from <xref ref-type="bibr" id="cr33-9" rid="c33">Huffcutt et al. (1996)</xref>
        for their analysis of studies that did not allow interviewers access to cognitive ability scores. It is also
        slightly larger than the overall results of .40 from Huffcutt et al. It is important to note that the 95%
        confidence interval for the estimate of .42 ranges from .36 to .48. Thus, none of the corrected estimates
        derived by <xref ref-type="bibr" id="cr5-23" rid="c5">Berry et al. (2007)</xref>, including the
        overall value of .27, the applicant pool value of .29, and the direct range restriction value of .24, fall
        within this range of scores. The values from Huffcutt et al. do fall with this range.<xref ref-type="table-anchor" rid="tbl3 tbl4"/></p>
      
<p align="left">We then estimated the interviews &#8211; ability correlation
        using the educational interviews from these two conditions. We combined the results of the single large study in
        the applicant pool condition (<xref ref-type="bibr" id="cr64-5" rid="c64">Shahani et al., 1991</xref>,
          <italic>r</italic> = .20, <italic>N</italic> = 2,583) with the educational studies from the direct range
        restriction condition (<italic>r</italic> = .30, <italic>N</italic> = 668). The resulting corrected mean
          <italic>r</italic> was .21 (<italic>k</italic> = 6, <italic>N</italic> = 3,251). As noted above, these
        analyses are dominated by the single study of <xref ref-type="bibr" id="cr64-6" rid="c64">Shahani et al.
          (1991)</xref>. On balance, it appears that the available data are consistent with the idea that
        educational versus employment contexts are a moderator of the interviews &#8211; ability relationship. Finally,
        to facilitate comparison with the overall results of <xref ref-type="bibr" id="cr5-24" rid="c5">Berry et al
          (2007)</xref>, we combined the educational interviews (<italic>r</italic> = .21,
          <italic>N</italic> = 3,251) and the employment interviews (<italic>r</italic> = .42, <italic>N</italic> =
        3,824). This resulted in a .32 correlation between interviews and cognitive ability. Thus, the correlation drops
        from .42 for employment interviews to .32 for all interviews. This .10 reduction suggests that one of the main
        differences between the results of previous meta-analyses (e.g., <xref ref-type="bibr" id="cr33-10" rid="c33">Huffcutt et al., 1996</xref>) and the results of <xref ref-type="bibr" id="cr5-25" rid="c5">Berry
          et al. (2007)</xref> may be largely the result of the inclusion of educational interviews in the
        latter, rather than more complex approaches to range restriction or the availability of test scores to
        interviewers.</p>
    
</sec>
<sec id="s14">
      
<title>Discussion</title>
      
<p align="left">We set out to clarify the relationship between interviews and
        cognitive ability tests given divergences among past studies. We did this by reanalyzing the data from the most
        up-to-date meta-analysis in the area (i.e., <xref ref-type="bibr" id="cr5-26" rid="c5">Berry et al.,
          2007</xref>). We discovered that when one clearly addresses the research question, carefully
        codes the underlying primary studies, and conducts employment versus educational interview moderator analyses on
        accurate data, the story changes considerably. <xref ref-type="bibr" id="cr5-27" rid="c5">Berry et al.
          (2007)</xref> found a corrected overall correlation of .27. Our point estimate for the employment
        interviews &#8211; cognitive ability relationship was .42. This is .15 higher (or 56% higher) than Berry et
        al.&#8217;s estimate of .27, and it is highly similar to the values of .40 for the overall analysis and .38 for
        the analysis of studies which did not provide access to cognitive ability tests by <xref ref-type="bibr" id="cr33-11" rid="c33">Huffcutt et al. (1996)</xref>. Further, the change in the magnitude of the
        mean correlation (i.e., .27&#8211;.42) is highly similar to the downward magnitude with which Berry et
        al.&#8217;s results appeared to change our understanding of this relationship in the interviewing literature
        (i.e., .38/.40&#8211;.27).</p>
      
<p align="left">Our results have both logical/theoretical and practical
        implications for personnel selection. Theoretically, the corrected correlation of .42 provides a point estimate
        suggesting employment interviews are often moderately capturing variance attributable to cognitive ability.
        Further, the employment interview credibility intervals lower bounds are generally in the mid to upper
        .20&#8217;s and the upper bounds often in the mid to upper .50&#8217;s. Thus, the balance of evidence suggests
        that many interviews in employment settings have moderate levels of relationships to cognitive ability. This is
        consistent with our logical position on the importance of cognitive ability in interviews. The value of .42 is
        also of interest because we are not aware of any other constructs (e.g., conscientiousness) that, on average,
        correlate this highly with interview ratings.</p>
      
<p align="left">Practically, an accurate correlation between interviews and
        cognitive ability is important for other reasons. One specific application of this approach is assessing levels
        of incremental validity (as per <xref ref-type="bibr" id="cr60-2" rid="c60">Schmidt &amp; Hunter,
          1998</xref>). <xref ref-type="bibr" id="cr5-28" rid="c5">Berry et al. (2007)</xref>
        questioned Schmidt and Hunter&#8217;s values for incremental validity of interviews due to their new
        intercorrelation of interviews and cognitive ability. Our analyses of the interviews &#8211; cognitive ability
        relationship facilitate more accurate estimates and address such questions.</p>
      
<p align="left">One can illustrate this issue by assembling a small
        meta-analytic matrix of interviews and cognitive ability, including their correlations with job performance. For
        example, <xref ref-type="bibr" id="cr49-1" rid="c49">Potosky et al. (2005)</xref> averaged the highly
        structured interview categories from <xref ref-type="bibr" id="cr30-3" rid="c30">Huffcutt and Arthur
          (1994)</xref> and the structured interviews from <xref ref-type="bibr" id="cr41-3" rid="c41">McDaniel, Whetzel, Schmidt, and Maurer (1994)</xref> to derive a corrected validity of .48.
          <xref ref-type="bibr" id="cr34-2" rid="c34">Hunter and Hunter (1984)</xref> reported a corrected
        validity of .51 for cognitive ability tests. An appropriate value for the intercorrelation between these
        predictors based on our research is .35.<xref ref-type="fn" id="fnc4-1" rid="fn4"><sup location="post">4</sup></xref> The
        corresponding criterion-related validity estimate for a unit weighted composite of cognitive test and interview
        scores would be .60. This is quite close to the estimated validity of .59 for an empirically-weighted composite
        reported by <xref ref-type="bibr" id="cr60-3" rid="c60">Schmidt and Hunter (1998)</xref> and the
        results reaffirm the guidance within that article.</p>
      
<p align="left">Our results could also help adverse impact researchers
        understand how and why interviews might be associated with differential hiring rates for various groups of
        applicants. Higher correlations with cognitive ability suggest higher levels of adverse impact potential.
        Finally, the analysis of meta-analytic matrices is increasingly common (e.g., <xref ref-type="bibr" id="cr7-3" rid="c7">Bobko et al., 1999</xref>; <xref ref-type="bibr" id="cr21-3" rid="c21">DeCorte et al.,
          2006</xref>, <xref ref-type="bibr" id="cr22-2" rid="c22">2007</xref>). The results from
        these matrices are only as good as the quality of the estimates that go into them (<xref ref-type="bibr" id="cr8-3" rid="c8">Bobko &amp; Stone-Romero, 1998</xref>; <xref ref-type="bibr" id="cr23-1" rid="c23">Doverspike, Winter, Healy, &amp; Barrett, 1996</xref>) and our estimates can be used in future
        efforts in this line of research.</p>
      
<p align="left">Our cumulative results for educational interviews are also
        noteworthy. Recall that most educational interviews were designed to minimize, as much as possible, the
        influence of cognitive ability. Our results are consistent with the idea that one can start with the goal of
        minimizing the variance in interview ratings associated with cognitive ability, and that ratings from such
        interviews can be less saturated with cognitive ability. However, our logical position is also affirmed in that
        it appears very difficult to eliminate the influence of cognitive ability given several ways in which it can
        influence interview ratings. Similarly, decisions to deemphasize cognitive-oriented job dimensions might have
        implications for the content validity of employment interviews.</p>
      
<p align="left">Our study also has important implications for meta-analysts in a
        variety of fields. First, meta-analysts should be careful to accurately code and extract information. For
        example, some studies in our reanalysis were incorrectly coded as not being influenced by range restriction
        (e.g., <xref ref-type="bibr" id="cr28-3" rid="c28">Hilliard, 2001</xref>; <xref ref-type="bibr" id="cr68-2" rid="c68">Tziner &amp; Dolan, 1982</xref>). Other studies were incorrectly classified
        as subject to direct range restriction when they were job incumbents (e.g., <xref ref-type="bibr" id="cr9-2" rid="c9">Bosshardt, 1993</xref>; <xref ref-type="bibr" id="cr72-2" rid="c72">Van Iddekinge et al.,
          2005</xref>). Second, meta-analysts should monitor influential cases (e.g., <xref ref-type="bibr" id="cr64-7" rid="c64">Shahani et al., 1991</xref>), as large sample studies with divergent
        results can change meta-analytic mean results (in this case by .06 within the applicant category).</p>
      
<p align="left">Finally, the careful consideration of moderator analyses is
        critical. In this case, many educational studies were designed to minimize the cognitive loading of the
        interview, and it is unclear whether KSAs measured in employment and educational studies are the same or
        different. As such, investigating the potential moderating influence of these studies was important.</p>
      
<sec id="s15" disp-level="subsect1">
        
<title>Limitations</title>
        
<p align="left">We note several potential limitations of the current study.
          First, there were a fairly small number of studies within some of the interviews &#8211; cognitive ability
          study categories. In spite of starting out with a sizeable number of studies, excluding studies in which
          interviewers had access to test scores and correctly categorizing the remaining studies took its toll on
          sample size.</p>
        
<p align="left">Second, meta-analyses are limited by the studies and data that
          go into them (<xref ref-type="bibr" id="cr8-4" rid="c8">Bobko &amp; Stone-Romero, 1998</xref>).
          There was often a lack of data reported on research artifacts and predictor intercorrelations in the primary
          studies. Further, there were relatively few studies of applicant pools and predictive validity studies that
          allow quality estimates of key parameters. Of course, this is more an indication of the studies in the field
          than an indictment of meta-analysis per se (<xref ref-type="bibr" id="cr58-1" rid="c58">Schmidt,
            2008</xref>).</p>
        
<p align="left">Third, corrections for interview unreliability used by
            <xref ref-type="bibr" id="cr5-29" rid="c5">Berry et al. (2007)</xref> and our reanalysis appear to
          be based primarily upon panel interviews. These estimates do not account for unreliability due to time or to
          different interview questions (i.e., they do not account for transient error or interview-specific factor
          error). Thus, our corrections may be conservative if one is concerned about across-interview indices of
          reliability (see also <xref ref-type="bibr" id="cr35-1" rid="c35">Hunter &amp; Schmidt,
          2004</xref>). Finally, we did not address the relationship between personality factors and
          interview ratings. More work could be done in this area, as there are comparatively few studies addressing
          these links.</p>
      
</sec>
      
<sec id="s16" disp-level="subsect1">
        
<title>Future Research</title>
        
<p align="left">More quality interviewing studies are needed. For instance,
          the field needs more high-quality predictive studies that allow corrections for artifacts, as they provide
          much better parameter estimates (e.g., <xref ref-type="bibr" id="cr35-2" rid="c35">Hunter &amp; Schmidt,
            2004</xref>; <xref ref-type="bibr" id="cr47-2" rid="c47">Ones et al., 1993</xref>).
          Unfortunately, we could find relatively few newer studies that might inform us of the relationship between
          interviews and cognitive ability. We did find one field study of employment interviews in which a measure of
          cognitive ability correlated .44 with structured interview ratings (<xref ref-type="bibr" id="cr20-2" rid="c20">Dayan et al., 2008</xref>), but this was only one study published in the intervening 5 years
          from the publication of Berry et al. to the present date (see also <xref ref-type="bibr" id="cr29-1" rid="c29">Honer, Wright, &amp; Sablynkski, 2007</xref>, for a study using students as participants,
            <italic>r</italic> = .45). We added the Dayan et al. study to our overall analyses and the overall
          interviews &#8211; cognitive ability relationship was .45 (<italic>k</italic> = 13, <italic>N</italic> =
          5,352, 80% credibility interval from .31. to .59). Thus, the field appears to be generating and publishing
          little new data to address the issue of the relationship between interviews and cognitive ability. Similarly,
          more applicant pool studies are needed for predictor intercorrelation research for many predictors such as
          situational judgment tests, work samples, and assessment centers. Perhaps of greatest importance, studies
          should be conducted in ways such that readers can tell what constructs were targeted for measurement and, if
          possible, how well such ratings correlated with existing measures of the constructs of interest.</p>
        
<p align="left">Finally, we suggest more attention to the issue of employment
          versus educational interviews. As we noted, many research efforts have focused on employment interviews. Yet,
          two meta-analyses have combined educational and employment interviews (<xref ref-type="bibr" id="cr5-30" rid="c5">Berry et al., 2007</xref>; <xref ref-type="bibr" id="cr57-2" rid="c57">Salgado &amp; Moscoso,
            2002</xref>). More discussion and moderator analyses are needed to clarify the potential
          importance of this issue.</p>
        
<p align="left">In conclusion, we suggest the interviews may be more saturated
          with cognitive ability variance than had recently been thought. While a recent meta-analysis appeared to
          revise our estimate of this relationship downward from approximately .40 to a value of .27, such a value
          appears to be an underestimate. In fact, careful coding of the data and consideration of moderators suggests
          that the correlation between interviews and cognitive ability is .42 for employment interviews (or .45 if one
          includes <xref ref-type="bibr" id="cr20-3" rid="c20">Dayan et al., 2008</xref>) and .21 for
          educational interviews. Thus, it appears time to &#8220;go back to the future&#8221; on our understanding of
          this important relationship and realize that better point estimates of the employment interviews &#8211;
          cognitive ability relationship are roughly .40 (or slightly higher) and that employment interviews are often
          moderately correlated with cognitive ability.</p>
      
</sec>
    
</sec>
</body>
  
<back>
<fn-group content-type="footnotes">
<fn id="fn1">
    
<label>1</label>
    
<p align="left"><xref ref-type="bibr" id="cr5-33" rid="c5">Berry et al.
        (2007)</xref> appear to have made substantial efforts to incorporate the data from both
        <xref ref-type="bibr" id="cr33-12" rid="c33">Huffcutt et al. (1996)</xref> and <xref ref-type="bibr" id="cr57-3" rid="c57">Salgado and Moscoso (2002)</xref>. Thus, we begin our analyses with Berry et
      al.&#8217;s comprehensive <xref ref-type="table" id="tbc1-3" rid="tbl1">Table 1</xref>.</p>
  </fn>
<fn id="fn2">
    
<label>2</label>
    
<p align="left">The values chosen by Berry et al. are for panel interviews such
      that they reflect the consistency of ratings from different panel members, who observed the same set of
      applicants. These interrater estimates do not account for transient error (e.g., changes in interviewee
      performance over time due to mood or anxiety) or interview-specific factor error (i.e., changes in interviewee
      performance when exposed to a different set of questions) (<xref ref-type="bibr" id="cr59-1" rid="c59">Schmidt &amp;
        Hunter, 1996</xref>). Thus, these values may be rather conservative corrections if one wishes to
      generalize results across different interviews. (Conway et al. also provided values for &#8220;separate
      interviews&#8221; in <xref ref-type="table" id="tbc4-2" rid="tbl4">Table 4</xref>, see also <xref ref-type="bibr" id="cr62-1" rid="c62">Schmidt &amp; Zimmerman, 2004</xref> on the reliability of interviews.)</p>
  </fn>
<fn id="fn3">
    
<label>3</label>
    
<p align="left">It was also somewhat difficult to code the reliability of
      Johnson&#8217;s structured interview as &#8220;no follow-up questions were allowed, but a student might be asked
      to expand upon a limited reply&#8221; (p. 75). We coded this as not allowing follow-up questions for the sake of
      reliability analysis.</p>
  </fn>
<fn id="fn4">
    
<label>4</label>
    
<p align="left">We use the value of .35 by &#8220;decorrecting&#8221; the
      correlation for cognitive test reliability of .90 and interview reliability of .75 because this calculation should
      use the correlation corrected only for range restriction (see <xref ref-type="bibr" id="cr60-4" rid="c60">Schmidt
        &amp; Hunter, 1998</xref>).</p>
  </fn>
</fn-group>
    
<ref-list use-in-PI="yes">
      <title>References</title>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c1" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Arvey</surname>, <given-names>R. D.</given-names></string-name>,
          &amp; <string-name><surname>Campion</surname>, <given-names>J. E.</given-names></string-name></person-group>
          (<year>1982</year>). <article-title>The employment interview: A summary and review of recent
          research</article-title>. <source>Personnel Psychology</source>, <volume>35</volume>,
          <fpage>281</fpage>&#8211;<lpage>322</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c2" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Arthur</surname>, <given-names>W.</given-names></string-name>,
          &amp; <string-name><surname>Villado</surname>, <given-names>A.</given-names></string-name></person-group>
        (<year>2008</year>). <article-title>The importance of distinguishing between constructs and methods when
          comparing predictors in personnel selection research and practice</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>93</volume>,
        <fpage>435</fpage>&#8211;<lpage>442</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c3" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Barrick</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Shaffer</surname>, <given-names>J. A.</given-names></string-name>, &amp;
              <string-name><surname>DeGrassi</surname>, <given-names>S. W.</given-names></string-name></person-group>
          (<year>2009</year>). <article-title>What you see may not be what you get: Relationships among self-presentation
          tactics and ratings of interview and job performance</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>94</volume>,
        <fpage>1394</fpage>&#8211;<lpage>1411</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="thesis" meta="no" id="c4" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bass</surname>
            <given-names>B. M.</given-names></string-name></person-group>
        <year>1949</year>
        <source>Comparison of the leaderless group discussion and the individual interview in the selection of sales and
          management trainees</source>
        <comment>Unpublished dissertation, Ohio State University</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c5" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>C. M.</given-names></string-name>,
              <string-name><surname>Sackett</surname>, <given-names>P. R.</given-names></string-name>, &amp;
              <string-name><surname>Landers</surname>, <given-names>R. N.</given-names></string-name></person-group>
          (<year>2007</year>). <article-title>Revisiting interview-cognitive ability relationships: Attending to specific
          range restriction mechanisms in meta-analysis</article-title>. <source>Personnel Psychology</source>,
          <volume>60</volume>, <fpage>837</fpage>&#8211;<lpage>874</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c6" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bobko</surname>, <given-names>P.</given-names></string-name>,
          &amp; <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name></person-group>
        (<year>2008</year>). <article-title>Psychometric accuracy and (the continuing need for) quality thinking in
          meta-analysis</article-title>. <source>Organizational Research Methods</source>, <volume>11</volume>,
          <fpage>114</fpage>&#8211;<lpage>126</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c7" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bobko</surname>, <given-names>P.</given-names></string-name>,
              <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>, &amp;
              <string-name><surname>Potosky</surname>, <given-names>D.</given-names></string-name></person-group> (<year>1999</year>).
          <article-title>Derivation and implications of a meta-analytic matrix incorporating cognitive ability,
          alternative predictors and job performance</article-title>. <source>Personnel Psychology</source>,
          <volume>52</volume>, <fpage>561</fpage>&#8211;<lpage>589</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c8" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bobko</surname>, <given-names>P.</given-names></string-name>,
          &amp; <string-name><surname>Stone-Romero</surname>, <given-names>G.</given-names></string-name></person-group>
          (<year>1998</year>). <article-title>Meta-analysis is another useful research tool but it is not a
          panacea</article-title>. In <person-group person-group-type="editor"><string-name><given-names>J.</given-names>
            <surname>Ferris</surname></string-name></person-group> (<role>Ed.</role>), <source>Research in personnel and human
          resources management</source>, <volume>16</volume>,
        <fpage>359</fpage>&#8211;<lpage>379</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="thesis" meta="no" id="c9" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bosshardt</surname>
            <given-names>M. J.</given-names></string-name></person-group> (<year>1993</year>). <source>Situational interviews
          versus behavior description interviews: A comparative validity study</source>. <comment>Unpublished
          dissertation, University of Minnesota</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c10" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bullock</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Svyantek</surname>, <given-names>D. J.</given-names></string-name></person-group> (<year>1985</year>). <article-title>Analyzing meta-analysis: Potential
          problems, an unsuccessful replication, and evaluation criteria</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>70</volume>,
        <fpage>108</fpage>&#8211;<lpage>115</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c11" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Burke</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Landis</surname>, <given-names>R. S.</given-names></string-name></person-group> (<year>2003</year>). <chapter-title>Methodological and conceptual
          challenges in conducting and interpreting meta-analyses</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K. R.</given-names>
            <surname>Murphy</surname></string-name></person-group> (<role>Ed.</role>), <source>Validity generalization: A
          critical review</source> (pp. <fpage>287</fpage>&#8211;<lpage>310</lpage>).
          <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Earlbaum</publisher-name>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c12" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Calkins</surname>, <given-names>E. V.</given-names></string-name>, <string-name><surname>Richards</surname>, <given-names>J. M.</given-names></string-name>,
              <string-name><surname>McCanse</surname>, <given-names>A.</given-names></string-name>,
              <string-name><surname>Burgess</surname>, <given-names>M. M.</given-names></string-name>, &amp;
              <string-name><surname>Willoughby</surname>, <given-names>T. L.</given-names></string-name></person-group>
          (<year>1974</year>). <article-title>Impact on admission to a school of medicine of an innovation in selection
          procedures</article-title>. <source>Psychological Reports</source>, <volume>35</volume>,
          <fpage>1135</fpage>&#8211;<lpage>1142</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c13" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Campion</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Palmer</surname>, <given-names>D. K.</given-names></string-name>, &amp;
              <string-name><surname>Campion</surname>, <given-names>J. E.</given-names></string-name></person-group>
          (<year>1997</year>). <article-title>A review of structure in the selection interview</article-title>.
          <source>Personnel Psychology</source>, <volume>50</volume>,
          <fpage>655</fpage>&#8211;<lpage>702</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c14" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Campion</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Palmer</surname>, <given-names>D. K.</given-names></string-name>, &amp;
              <string-name><surname>Campion</surname>, <given-names>J. E.</given-names></string-name></person-group>
          (<year>1998</year>). <article-title>Structuring employment interviews to improve reliability, validity, and
          users&#8217; reactions</article-title>. <source>Current Directions in Psychological Science</source>,
          <volume>7</volume>, <fpage>77</fpage>&#8211;<lpage>82</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c15" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Conway</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Jako</surname>, <given-names>R. A.</given-names></string-name>, &amp;
              <string-name><surname>Goodman</surname>, <given-names>D. F.</given-names></string-name></person-group>
          (<year>1995</year>). <article-title>A meta-analysis of interrater and internal consistency reliability of
          selection interviews</article-title>. <source>Journal of Applied Psychology</source>, <volume>80</volume>,
          <fpage>565</fpage>&#8211;<lpage>579</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c16" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Conway</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Peneno</surname>, <given-names>G. M.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Comparing structured interview
          question types: Construct validity and applicant reactions</article-title>. <source>Journal of Business and
          Psychology</source>, <volume>13</volume>,
        <fpage>485</fpage>&#8211;<lpage>506</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c17" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Cooper</surname>, <given-names>H. M.</given-names></string-name></person-group> (<year>1982</year>). <article-title>Scientific guidelines for
          conducting integrative research reviews</article-title>. <source>Review of Educational Research</source>,
          <volume>52</volume>, <fpage>291</fpage>&#8211;<lpage>302</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c18" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Cortina</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Goldstein</surname>, <given-names>N. B.</given-names></string-name>,
              <string-name><surname>Payne</surname>, <given-names>S. C.</given-names></string-name>,
              <string-name><surname>Davison</surname>, <given-names>H. K.</given-names></string-name>, &amp;
              <string-name><surname>Gilliland</surname>, <given-names>S. W.</given-names></string-name></person-group>
          (<year>2000</year>). <article-title>The incremental validity of interview scores over and above cognitive
          ability and conscientiousness scores</article-title>. <source>Personnel Psychology</source>,
          <volume>53</volume>, <fpage>325</fpage>&#8211;<lpage>351</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="conference" meta="no" id="c19" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Davey</surname>,
          <given-names>B.</given-names></string-name></person-group> (<year>1984</year>, <month>May</month>). <source>Are all
          oral panels created equal?</source>
        <comment>Paper presented at the Annual Conference of the International Personnel Management Association
          Assessment Council, Seattle, WA, USA</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c20" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Dayan</surname>, <given-names>K.</given-names></string-name>,
              <string-name><surname>Fox</surname>, <given-names>S.</given-names></string-name>, &amp;
              <string-name><surname>Kasten</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2008</year>).
          <article-title>The preliminary employment interview as a predictor of assessment center
        outcomes</article-title>. <source>International Journal of Selection and Assessment</source>,
        <volume>16</volume>, <fpage>102</fpage>&#8211;<lpage>111</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c21" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>DeCorte</surname>, <given-names>W.</given-names></string-name>,
              <string-name><surname>Lievens</surname>, <given-names>F.</given-names></string-name>, &amp;
              <string-name><surname>Sackett</surname>, <given-names>P. R.</given-names></string-name></person-group>
          (<year>2006</year>). <article-title>Predicting adverse impact and mean criterion performance in multi-stage
          selection</article-title>. <source>Journal of Applied Psychology</source>, <volume>91</volume>,
          <fpage>523</fpage>&#8211;<lpage>537</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c22" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>DeCorte</surname>, <given-names>W.</given-names></string-name>,
              <string-name><surname>Lievens</surname>, <given-names>F.</given-names></string-name>, &amp;
              <string-name><surname>Sackett</surname>, <given-names>P. R.</given-names></string-name></person-group>
          (<year>2007</year>). <article-title>Combining predictors to achieve optimal trade-offs between selection
          quality and adverse impact</article-title>. <source>Journal of Applied Psychology</source>,
        <volume>92</volume>, <fpage>1380</fpage>&#8211;<lpage>1393</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c23" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Doverspike</surname>,
            <given-names>D.</given-names></string-name>, <string-name><surname>Winter</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Healy</surname>, <given-names>M. C.</given-names></string-name>, &amp;
              <string-name><surname>Barrett</surname>, <given-names>G. V.</given-names></string-name></person-group>
          (<year>1996</year>). <article-title>Simulations as a method of illustrating the impact of differential weights
          on personnel selection outcomes</article-title>. <source>Human Performance</source>, <volume>9</volume>,
          <fpage>259</fpage>&#8211;<lpage>273</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c24" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hambrick</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>2007</year>). <article-title>The field of management&#8217;s
          devotion to theory: Too much of a good thing?</article-title>
        <source>Academy of Management Journal</source>, <volume>50</volume>,
          <fpage>1346</fpage>&#8211;<lpage>1352</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c25" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>M. M.</given-names></string-name></person-group> (<year>1989</year>). <article-title>Reconsidering the employment
          interview: A review of recent research literature and suggestions for future research</article-title>.
          <source>Personnel Psychology</source>, <volume>42</volume>,
          <fpage>691</fpage>&#8211;<lpage>726</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c26" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>M. M.</given-names></string-name></person-group> (<year>1999</year>). <chapter-title>What is are being
          measured?</chapter-title> In <person-group person-group-type="editor"><string-name><given-names>R. W.</given-names>
            <surname>Eder</surname></string-name>, &amp; <string-name><given-names>M. M.</given-names>
            <surname>Harris</surname></string-name></person-group> (<role>Eds.</role>), <source>The employment interview
          handbook</source> (pp. <fpage>143</fpage>&#8211;<lpage>157</lpage>). <publisher-loc>Thousand
          Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c27" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hausknecht</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Day</surname>, <given-names>D. V.</given-names></string-name>, &amp;
              <string-name><surname>Thomas</surname>, <given-names>S. C.</given-names></string-name></person-group>
        (<year>2004</year>). <article-title>Applicant reactions to selection procedures: An updated model and
          meta-analysis</article-title>. <source>Personnel Psychology</source>, <volume>57</volume>,
          <fpage>639</fpage>&#8211;<lpage>683</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c28" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hilliard</surname>, <given-names>P. A.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Comparison of the predictive
          validity of a written test, an integrity test, a conscientiousness questionnaire, a structured behavioral
          interview and a personality inventory in the assessment of job applicants&#8217; background investigations,
          and subsequent task and contextual job performance</article-title>. <source>Dissertation Abstracts
          International</source>, <volume>62</volume>, <fpage>2981B</fpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c29" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Honer</surname>, <given-names>J.</given-names></string-name>,
              <string-name><surname>Wright</surname>, <given-names>C. W.</given-names></string-name>, &amp;
              <string-name><surname>Sablynkski</surname>, <given-names>C. J.</given-names></string-name></person-group>
          (<year>2007</year>). <article-title>Puzzle interviews: What are they and what do they
          measure?</article-title>
        <source>Applied H.R.M Research</source>, <volume>11</volume>,
          <fpage>79</fpage>&#8211;<lpage>96</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c30" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Huffcutt</surname>, <given-names>A. I.</given-names></string-name>, &amp; <string-name><surname>Arthur</surname>,
          <given-names>W.</given-names></string-name></person-group> (<year>1994</year>). <article-title>Hunter and Hunter (1984)
          revisited: Interview validity for entry-level jobs</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>79</volume>,
        <fpage>184</fpage>&#8211;<lpage>190</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c31" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Huffcutt</surname>, <given-names>A. I.</given-names></string-name>, <string-name><surname>Conway</surname>, <given-names>J. M.</given-names></string-name>,
              <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>, &amp;
              <string-name><surname>Stone</surname>, <given-names>N. J.</given-names></string-name></person-group>
        (<year>2001</year>). <article-title>Identification and meta-analytic assessment of psychological constructs
          measured in employment interviews</article-title>. <source>Journal of Applied Psychology</source>,
          <volume>86</volume>, <fpage>897</fpage>&#8211;<lpage>913</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c32" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Huffcutt</surname>, <given-names>A. I.</given-names></string-name>, &amp; <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Racial group differences in interview
          evaluations</article-title>. <source>Journal of Applied Psychology</source>, <volume>83</volume>,
          <fpage>288</fpage>&#8211;<lpage>297</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c33" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Huffcutt</surname>, <given-names>A. I.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>, &amp;
              <string-name><surname>McDaniel</surname>, <given-names>M. A.</given-names></string-name></person-group>
          (<year>1996</year>). <article-title>A meta-analytic investigation of cognitive ability in employment interview
          evaluations: Moderating characteristics and implications for incremental validity</article-title>.
          <source>Journal of Applied Psychology</source>, <volume>81</volume>,
          <fpage>459</fpage>&#8211;<lpage>473</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c34" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hunter</surname>, <given-names>J. E.</given-names></string-name>, &amp; <string-name><surname>Hunter</surname>, <given-names>R. F.</given-names></string-name></person-group> (<year>1984</year>). <article-title>Validity and utility of alternative
          predictors of job performance</article-title>. <source>Psychological Bulletin</source>, <volume>96</volume>,
          <fpage>72</fpage>&#8211;<lpage>98</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="book" meta="no" id="c35" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hunter</surname>, <given-names>J. E.</given-names></string-name>, &amp; <string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name></person-group> (<year>2004</year>). <source>Methods of meta-analysis: Correcting for
          error and bias in research findings</source> (<edition>2nd Ed</edition>). <publisher-loc>Newbury Park,
          CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="thesis" meta="no" id="c36" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Johnson</surname>, <given-names>E. K.</given-names></string-name></person-group> (<year>1990</year>). <source>The structured interview: Manipulating
          structuring criteria and the effects on validity, reliability, and practicality</source>. <comment>Unpublished
          doctoral dissertation, Tulane University</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c37" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Klehe</surname>, <given-names>U. C.</given-names></string-name>, &amp; <string-name><surname>Latham</surname>, <given-names>G. P.</given-names></string-name></person-group> (<year>2005</year>). <article-title>The predictive and incremental
          validity of the situational and patterned behavior description interviews for teamplaying
          behavior</article-title>. <source>International Journal of Selection and Assessment</source>,
          <volume>13</volume>, <fpage>108</fpage>&#8211;<lpage>115</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c38" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Kuncel</surname>, <given-names>N. R.</given-names></string-name>, <string-name><surname>Hezlett</surname>, <given-names>S. A.</given-names></string-name>, &amp;
              <string-name><surname>Ones</surname>, <given-names>D. S.</given-names></string-name></person-group> (<year>2001</year>).
          <article-title>A comprehensive meta-analysis of the predictive validity of the graduate record examinations:
          Implications for graduate student selection and performance</article-title>. <source>Psychological
          Bulletin</source>, <volume>127</volume>, <fpage>162</fpage>&#8211;<lpage>181</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c39" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lance</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>LaPointe</surname>, <given-names>J. A.</given-names></string-name>, &amp;
              <string-name><surname>Fisicaro</surname>, <given-names>S. A.</given-names></string-name></person-group>
          (<year>1994</year>). <article-title>Tests of three causal models of halo rater error</article-title>.
          <source>Organizational Behavior and Human Decision Processes</source>, <volume>57</volume>,
          <fpage>83</fpage>&#8211;<lpage>96</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="book" meta="no" id="c40" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lipsey</surname>, <given-names>M. W.</given-names></string-name>, &amp; <string-name><surname>Wilson</surname>, <given-names>D. B.</given-names></string-name></person-group> (<year>2001</year>). <source>Practical meta-analysis</source>.
          <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage</publisher-name>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c41" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>McDaniel</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Whetzel</surname>, <given-names>D. L.</given-names></string-name>,
              <string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name>, &amp;
              <string-name><surname>Maurer</surname>, <given-names>S. D.</given-names></string-name></person-group>
        (<year>1994</year>). <article-title>The validity of employment interviews: A comprehensive review and
          meta-analysis</article-title>. <source>Journal of Applied Psychology</source>, <volume>79</volume>,
          <fpage>599</fpage>&#8211;<lpage>616</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="other" meta="no" id="c42" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Melchers</surname>, <given-names>K. G.</given-names></string-name>, <string-name><surname>Klehe</surname>, <given-names>U. C.</given-names></string-name>,
              <string-name><surname>Richter</surname>, <given-names>G. M.</given-names></string-name>,
              <string-name><surname>Kleinmann</surname>, <given-names>M.</given-names></string-name>, &amp;
              <string-name><surname>K&#246;nig</surname>, <given-names>C. J.</given-names></string-name></person-group>
        (<year>2005</year>). <source>The impact of interviewees&#8217; ability to identify criteria in structured
          interviews</source>. <comment>Unpublished manuscript</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c43" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Miner</surname>, <given-names>J. B.</given-names></string-name>, &amp; <string-name><surname>Raju</surname>, <given-names>N. S.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Risk propensity differences between
          managers and entrepreneurs and between low- and high-growth entrepreneurs: A reply in a more conservative
          vein</article-title>. <source>Journal of Applied Psychology</source>, <volume>89</volume>,
          <fpage>3</fpage>&#8211;<lpage>13</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c44" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Motowidlo</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Carter</surname>, <given-names>G. W.</given-names></string-name>,
              <string-name><surname>Dunnette</surname>, <given-names>M. D.</given-names></string-name>,
              <string-name><surname>Tippins</surname>, <given-names>N.</given-names></string-name>,
              <string-name><surname>Werner</surname>, <given-names>S.</given-names></string-name>,
              <string-name><surname>Burnett</surname>, <given-names>J. R.</given-names></string-name>, &amp;
              <string-name><surname>Vaughan</surname>, <given-names>M. J.</given-names></string-name></person-group>
          (<year>1992</year>). <article-title>Studies of the structured behavioral interview</article-title>.
          <source>Journal of Applied Psychology</source>, <volume>77</volume>,
          <fpage>571</fpage>&#8211;<lpage>587</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c45" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Mount</surname>, <given-names>M. K.</given-names></string-name>, &amp; <string-name><surname>Barrick</surname>,
          <given-names>M.</given-names></string-name></person-group> (<year>1995</year>). <article-title>The Big Five personality
          dimensions: For research and practice in human resources management</article-title>. <source>Research in
          Personnel and Human Resources Management</source>, <volume>13</volume>,
          <fpage>823</fpage>&#8211;<lpage>854</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c46" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>K. R.</given-names></string-name>, &amp; <string-name><surname>Newman</surname>, <given-names>D. A.</given-names></string-name></person-group> (<year>2003</year>). <chapter-title>The past, present, and future of
          validity generalization</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K. R.</given-names>
            <surname>Murphy</surname></string-name></person-group> (<role>Ed.</role>), <source>Validity generalization: A
          critical review</source> (pp. <fpage>403</fpage>&#8211;<lpage>424</lpage>).
          <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Earlbaum</publisher-name>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c47" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Ones</surname>, <given-names>D. S.</given-names></string-name>,
              <string-name><surname>Viswesvaran</surname>, <given-names>C.</given-names></string-name>, &amp;
              <string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name></person-group>
          (<year>1993</year>). <article-title>Comprehensive meta-analysis of integrity test validities: Findings and
          implications for personnel selection and theories of job performance</article-title>. <source>Journal of
          Applied Psychology</source>, <volume>78</volume>,
        <fpage>679</fpage>&#8211;<lpage>703</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c48" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Posthuma</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Morgeson</surname>, <given-names>F. P.</given-names></string-name>,
          &amp; <string-name><surname>Campion</surname>, <given-names>M. A.</given-names></string-name></person-group>
          (<year>2002</year>). <article-title>Beyond employment interview validity: A comprehensive narrative review of
          recent research and trends over time</article-title>. <source>Personnel Psychology</source>,
          <volume>55</volume>, <fpage>1</fpage>&#8211;<lpage>81</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c49" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Potosky</surname>, <given-names>D.</given-names></string-name>,
              <string-name><surname>Bobko</surname>, <given-names>P.</given-names></string-name>, &amp;
              <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name></person-group> (<year>2005</year>).
          <article-title>Forming composites of cognitive ability and alternative measures to predict job performance:
          Accurate estimation of standardized ethnic group differences and adverse impact</article-title>.
          <source>International Journal of Selection and Assessment</source>, <volume>13</volume>,
          <fpage>305</fpage>&#8211;<lpage>315</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c50" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Pritchard</surname>, <given-names>R. D.</given-names></string-name>, <string-name><surname>Maxwell</surname>, <given-names>S. E.</given-names></string-name>, &amp;
              <string-name><surname>Jordon</surname>, <given-names>W. C.</given-names></string-name></person-group>
        (<year>1984</year>). <article-title>Interpreting relationships between age and promotion in age-discrimination
          cases</article-title>. <source>Journal of Applied Psychology</source>, <volume>69</volume>,
          <fpage>199</fpage>&#8211;<lpage>206</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c51" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Reeb</surname>,
          <given-names>M.</given-names></string-name></person-group> (<year>1969</year>). <article-title>A structured interview
          for predicting military adjustment</article-title>. <source>Occupational Psychology</source>,
          <volume>43</volume>, <fpage>193</fpage>&#8211;<lpage>196</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c52" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Robie</surname>, <given-names>C.</given-names></string-name>,
              <string-name><surname>Komar</surname>, <given-names>S.</given-names></string-name>, &amp;
              <string-name><surname>Brown</surname>, <given-names>D. J.</given-names></string-name></person-group>
        (<year>2010</year>). <article-title>The effects of coaching and speeding on Big Five and Impression Management
          Scale scores</article-title>. <source>Human Performance</source>, <volume>23</volume>,
          <fpage>446</fpage>&#8211;<lpage>467</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c53" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>,
              <string-name><surname>Bobko</surname>, <given-names>P.</given-names></string-name>, &amp;
              <string-name><surname>McFarland</surname>, <given-names>L. A.</given-names></string-name></person-group>
          (<year>2005</year>). <article-title>A meta-analysis of work sample test validity: Updating some classic
          literature</article-title>. <source>Personnel Psychology</source>, <volume>58</volume>,
          <fpage>1009</fpage>&#8211;<lpage>1037</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c54" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>,
          &amp; <string-name><surname>Campion</surname>, <given-names>J. E.</given-names></string-name></person-group>
          (<year>1992</year>). <article-title>An analysis of the predictive power of the panel interview and
          preemployment tests</article-title>. <source>Journal of Occupational and Organizational Psychology</source>,
          <volume>65</volume>, <fpage>51</fpage>&#8211;<lpage>60</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c55" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Rothstein</surname>, <given-names>H. R.</given-names></string-name></person-group> (<year>2003</year>). <chapter-title>Progress is our most important
          product: Contributions of validity generalization and meta-analysis to the development and communication of
          knowledge in I/O Psychology</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K. R.</given-names>
            <surname>Murphy</surname></string-name></person-group> (<role>Ed.</role>), <source>Validity generalization: A
          critical review</source> (pp. <fpage>115</fpage>&#8211;<lpage>154</lpage>).
          <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Earlbaum</publisher-name>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c56" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Sackett</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>Lievens</surname>, <given-names>R.</given-names></string-name>,
              <string-name><surname>Berry</surname>, <given-names>C. M.</given-names></string-name>, &amp;
              <string-name><surname>Landers</surname>, <given-names>R. N.</given-names></string-name></person-group>
          (<year>2007</year>). <article-title>A cautionary note on the effects of range restriction on interpredictor
          correlations</article-title>. <source>Journal of Applied Psychology</source>, <volume>92</volume>,
          <fpage>538</fpage>&#8211;<lpage>544</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c57" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Salgado</surname>, <given-names>J. F.</given-names></string-name>, &amp; <string-name><surname>Moscoso</surname>,
          <given-names>S.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Comprehensive
          meta-analysis of the construct validity of the employment interview</article-title>. <source>European Journal
          of Work and Organizational Psychology</source>, <volume>11</volume>,
          <fpage>299</fpage>&#8211;<lpage>324</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c58" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Meta-analysis: A constantly
          evolving research integration tool</article-title>. <source>Organizational Research Methods</source>,
          <volume>11</volume>, <fpage>96</fpage>&#8211;<lpage>113</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c59" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name>, &amp; <string-name><surname>Hunter</surname>, <given-names>J. E.</given-names></string-name></person-group> (<year>1996</year>). <article-title>Measurement error in psychological
          research: Lessons from 26 research scenarios</article-title>. <source>Psychological Methods</source>,
          <volume>1</volume>, <fpage>199</fpage>&#8211;<lpage>223</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c60" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name>, &amp; <string-name><surname>Hunter</surname>, <given-names>J. E.</given-names></string-name></person-group> (<year>1998</year>). <article-title>The validity of selection methods in
          personnel psychology: Practical and theoretical implications of 85 years of research findings</article-title>.
          <source>Psychological Bulletin</source>, <volume>124</volume>,
          <fpage>262</fpage>&#8211;<lpage>274</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c61" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name>, <string-name><surname>Oh</surname>, <given-names>I. S.</given-names></string-name>, &amp;
              <string-name><surname>Le</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2006</year>).
          <article-title>Increasing the accuracy of corrections for range restriction: Implications for selection
          procedure validities and other research results</article-title>. <source>Personnel Psychology</source>,
          <volume>59</volume>, <fpage>281</fpage>&#8211;<lpage>305</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c62" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schmidt</surname>, <given-names>F. L.</given-names></string-name>, &amp; <string-name><surname>Zimmerman</surname>, <given-names>R. D.</given-names></string-name></person-group> (<year>2004</year>). <article-title>A counterintuitive hypothesis about
          employment interview validity and some supporting evidence</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>89</volume>,
        <fpage>553</fpage>&#8211;<lpage>561</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c63" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Schmitt</surname>, <given-names>N.</given-names></string-name>,
              <string-name><surname>Rogers</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Chan</surname>,
              <given-names>D.</given-names></string-name>, <string-name><surname>Sheppard</surname>,
            <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Jennings</surname>,
            <given-names>D.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Adverse impact and
          predictive efficiency of various predictor combinations</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>82</volume>,
        <fpage>719</fpage>&#8211;<lpage>730</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c64" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Shahani</surname>, <given-names>C.</given-names></string-name>,
              <string-name><surname>Dipboye</surname>, <given-names>R. L.</given-names></string-name>, &amp;
              <string-name><surname>Gehrlein</surname>, <given-names>T. M.</given-names></string-name></person-group>
          (<year>1991</year>). <article-title>The incremental contribution of an interview to college
          admissions</article-title>. <source>Educational and Psychological Measurement</source>, <volume>51</volume>,
          <fpage>1049</fpage>&#8211;<lpage>1061</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c65" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Stewart</surname>, <given-names>W. H.</given-names></string-name>, &amp; <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Risk taking propensity as a
          distinctive entrepreneurial characteristic: A meta-analysis</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>86</volume>,
        <fpage>145</fpage>&#8211;<lpage>153</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c66" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Stewart</surname>, <given-names>W. H.</given-names></string-name>, &amp; <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Data quality affects meta-analytic
          conclusions: A response to Miner and Raju concerning entrepreneurial risk propensity</article-title>.
          <source>Journal of Applied Psychology</source>, <volume>89</volume>,
          <fpage>14</fpage>&#8211;<lpage>21</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c67" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Tubiana</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>Ben-Shakhar</surname>,
          <given-names>G.</given-names></string-name></person-group> (<year>1982</year>). <article-title>An objective group
          questionnaire as a substitute for a personal interview in the prediction of success in military training in
          Israel</article-title>. <source>Personnel Psychology</source>, <volume>35</volume>,
          <fpage>349</fpage>&#8211;<lpage>357</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c68" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Tziner</surname>, <given-names>A.</given-names></string-name>,
          &amp; <string-name><surname>Dolan</surname>, <given-names>S.</given-names></string-name></person-group> (<year>1982</year>).
          <article-title>Validity of an assessment center for identifying future female officers in the
          military</article-title>. <source>Journal of Applied Psychology</source>, <volume>67</volume>,
          <fpage>728</fpage>&#8211;<lpage>736</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="other" meta="no" id="c69" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Van Iddekinge</surname>, <given-names>C. H.</given-names></string-name>, &amp; <string-name><surname>Eidson</surname> <suffix>Jr.</suffix>, <given-names>C. E.</given-names></string-name></person-group> (<year>2005</year>). <source>Using personality tests and structured
          interviews to select customer service managers</source>. <comment>Unpublished manuscript, Clemson University,
          Clemson, SC, USA</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="other" meta="no" id="c70" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Van Iddekinge</surname>, <given-names>C. H.</given-names></string-name>, &amp; <string-name><surname>Henry</surname>, <given-names>M. S.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Are facets of cognitive ability
          differentially predictive of interview performance?</article-title> In
              <person-group person-group-type="editor"><string-name><given-names>K.</given-names>
            <surname>Ferstl</surname></string-name>, &amp; <string-name><given-names>U.</given-names>
            <surname>Klehe</surname></string-name></person-group> (<role>Eds.</role>), <source>New insights into constructs
          underlying interview performance and validity</source>. <comment>Symposium conducted at the 21st Annual
          meetings of the Society for Industrial and Organizational Psychology, Dallas, TX</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c71" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Van Iddekinge</surname>, <given-names>C. H.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>,
              <string-name><surname>Raymark</surname>, <given-names>P.</given-names></string-name>, &amp;
              <string-name><surname>Odle-Dusseau</surname>, <given-names>H.</given-names></string-name></person-group>
          (<year>2012</year>). <article-title>The critical role of the research question, inclusion criteria, and
          transparency in meta-analyses of integrity test research: A reply to Harris et al. and Ones et
          al</article-title>. <source>Journal of Applied Psychology</source>, <volume>97</volume>,
          <fpage>543</fpage>&#8211;<lpage>549</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="conference" meta="no" id="c72" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Van Iddekinge</surname>, <given-names>C. H.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>P. L.</given-names></string-name>,
              <string-name><surname>Sager</surname>, <given-names>C. E.</given-names></string-name>, &amp;
              <string-name><surname>Heffner</surname>, <given-names>T. S.</given-names></string-name></person-group>
          (<year>2005</year>). <source>A construct oriented investigation of the structured employment
          interview</source>. <comment>Paper presented at the 20th Annual meetings of the Society for Industrial and
          Organizational Psychology, Los Angeles, CA</comment>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c73" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Villanova</surname>,
            <given-names>P.</given-names></string-name>, <string-name><surname>Bernardin</surname>, <given-names>H. J.</given-names></string-name>, <string-name><surname>Johson</surname>, <given-names>D. L.</given-names></string-name>, &amp;
              <string-name><surname>Dahmus</surname>, <given-names>S. A.</given-names></string-name></person-group>
        (<year>1994</year>). <article-title>The validity of a measure of job compatibility in the prediction of job
          performance and turnover of motion picture theatre personnel</article-title>. <source>Personnel
          Psychology</source>, <volume>47</volume>, <fpage>73</fpage>&#8211;<lpage>90</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c74" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Viswesvaran</surname>,
            <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Ones</surname>, <given-names>D. S.</given-names></string-name></person-group> (<year>1995</year>). <article-title>Theory testing: Combining
          psychometric meta-analysis and structural equations modeling</article-title>. <source>Personnel
          Psychology</source>, <volume>48</volume>,
        <fpage>865</fpage>&#8211;<lpage>886</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c75" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Walters</surname>, <given-names>L. C.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>M. R.</given-names></string-name>, &amp;
              <string-name><surname>Ree</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>1993</year>).
          <article-title>Structured interviews for pilot selection: No incremental validity</article-title>.
          <source>International Journal of Aviation Psychology</source>, <volume>3</volume>,
          <fpage>25</fpage>&#8211;<lpage>38</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c76" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Wanous</surname>, <given-names>J.</given-names></string-name>,
              <string-name><surname>Sullivan</surname>, <given-names>S.</given-names></string-name>, &amp;
              <string-name><surname>Malinak</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1989</year>).
          <article-title>The role of judgment calls in meta-analysis</article-title>. <source>Journal of Applied
          Psychology</source>, <volume>74</volume>,
        <fpage>259</fpage>&#8211;<lpage>264</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c77" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Whetzel</surname>, <given-names>D.</given-names></string-name>,
              <string-name><surname>McDaniel</surname>, <given-names>M.</given-names></string-name>, &amp;
              <string-name><surname>Nguyen</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2008</year>).
          <article-title>Subgroup differences in situational judgment test performance: A meta-analysis</article-title>.
          <source>Human Performance</source>, <volume>21</volume>,
          <fpage>291</fpage>&#8211;<lpage>308</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c78" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Wiesner</surname>, <given-names>W.</given-names></string-name>,
          &amp; <string-name><surname>Cronshaw</surname>, <given-names>S.</given-names></string-name></person-group>
          (<year>1988</year>). <article-title>A meta-analytic investigation of the impact of interview format and degree
          of structure on the validity of the employment interview</article-title>. <source>Journal of Occupational
          Psychology</source>, <volume>61</volume>,
        <fpage>275</fpage>&#8211;<lpage>290</lpage>.</mixed-citation>
</ref>
      
<ref><mixed-citation publication-type="journal" meta="no" id="c79" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Williamson</surname>, <given-names>L. G.</given-names></string-name>, <string-name><surname>Campion</surname>, <given-names>J. E.</given-names></string-name>,
              <string-name><surname>Malos</surname>, <given-names>S. B.</given-names></string-name>,
              <string-name><surname>Roehling</surname>, <given-names>M. V.</given-names></string-name>, &amp;
              <string-name><surname>Campion</surname>, <given-names>M. A.</given-names></string-name></person-group>
          (<year>1997</year>). <article-title>Employment interview on trial: Linking interview structure with litigation
          outcomes</article-title>. <source>Journal of Applied Psychology</source>, <volume>82</volume>,
          <fpage>900</fpage>&#8211;<lpage>912</lpage>.</mixed-citation>
</ref>
    
</ref-list>
  
</back>
  
  
  
  
  <floats-group>
<table-wrap id="tbl1" position="float" orientation="portrait" pagewide="no">
    
<label>1</label>
    
<caption><title>Reanalysis of <xref ref-type="bibr" id="cr5-31" rid="c5">Berry et al. (2007)</xref> entire
      applicant pool condition</title></caption>
    
<graphic copyright="inherit" id="tbl1a" xlink:href="prs_12_4_157_tbl1a.tif" xlink:type="simple"/>
    
<search-text>
      
        
          Analyses
          rmean
          SDr
          Corrected r
          N
          k
          80% Cred. Int.
        
      
      
        
          Note. Cred. Int. = credibility interval, SDr = standard
            deviation after removing sampling error.
        
      
      
        
          All studies
          .243
          .105
          .292
          6,891
          12
          .125&#8211;.460
        
        
          (Temporarily) Excluding Shahani study
          .292
          .107
          .350
          4,308
          11
          .175&#8211;.523
        
        
          Excluding Tziner and Dolan
          .290
          .110
          .347
          4,115
          10
          .167&#8211;.527
        
        
          Excluding Hilliard
          .297
          .106
          .356
          3,966
          9
          .180&#8211;.532
        
        
          Excluding Motowidlo studies
          .343
          .084
          .408
          2,984
          7
          .255&#8211;.561
        
        
          Change Van Iddekinge reliability
          .343
          .084
          .417
          2,984
          7
          .276&#8211;.558
        
      
    </search-text>
  </table-wrap>
  
<table-wrap id="tbl2" position="float" orientation="portrait" pagewide="no">
    
<label>2</label>
    
<caption><title>Reanalysis of <xref ref-type="bibr" id="cr5-32" rid="c5">Berry et al. (2007)</xref> direct range
      restriction condition</title></caption>
    
<graphic copyright="inherit" id="tbl2a" xlink:href="prs_12_4_157_tbl2a.tif" xlink:type="simple"/>
    
<search-text>
      
        
          Analyses
          rmean
          SDr
          Corrected r
          N
          k
          80% Cred. Int.
        
      
      
        
          Note. Cred. Int. = credibility interval; SDr = standard
            deviation after removing sampling error.
        
      
      
        
          All studies
          .145
          .093
          .243
          1,900
          12
          .054&#8211;.432
        
        
          Remove incumbents
          .166
          .107
          .281
          1,416
          10
          .068&#8211;.494
        
        
          Remove Conway
          .191
          .087
          .315
          1,271
          9
          .139&#8211;.490
        
        
          Add three studies into data
          .194
          .071
          .321
          1,810
          12
          .182&#8211;.459
        
        
          Results w/o Walters
          .214
          .056
          .354
          1,587
          11
          .253&#8211;.454
        
        
          Change Villanova reliability 
          .214
          .056
          .355
          1,587
          11
          .256&#8211;.455
        
        
          Moderator analyses
        
        
          Education samples with Klehe
          .181
          0
          .294
          747
          6
          .294&#8211;.294
        
        
          Education samples w/o Klehe
          .190
          0
          .301
          668
          5
          .301&#8211;.301
        
        
          Employment samples 
          .244
          .098
          .412
          840
          5
          .237&#8211;.587
        
      
    </search-text>
  </table-wrap>
  
<table-wrap id="tbl3" position="float" orientation="portrait" pagewide="no">
    
<label>3</label>
    
<caption><title>Summary of results of both meta-analyses</title></caption>
    
<graphic copyright="inherit" id="tbl3a" xlink:href="prs_12_4_157_tbl3a.tif" xlink:type="simple"/>
    
<search-text>
      
        
          Analyses
          rmean
          Corrected r
          N
          k
          80% credibility interval
        
      
      
        
          Applicant condition
        
        
          Berry et al.
          .24
          .29
          6,891
          12
          .13&#8211;.46
        
        
          Current study educational
          .16
          .20
          2,583
          1
          &#8211;
        
        
          Current study employment
          .34
          .42
          2,984
          7
          .28&#8211;.56
        
        
          Direct range restriction condition
        
        
          Berry et al.
          .14
          .24
          1,900
          12
          .05&#8211;.43
        
        
          Current education samples
          .19
          .30
          668
          5
          .30&#8211;.30
        
        
          Current employment samples
          .24
          .41
          840
          5
          .24&#8211;.59
        
        
          Overall analyses of the current study
        
        
          Education samples
          .17
          .21
          3,251
          6
          .21&#8211;.21
        
        
          Employment samples 
          .32
          .42
          3,824
          12
          .27&#8211;.56 
        
      
    </search-text>
  </table-wrap>
  
<table-wrap id="tbl4" position="float" orientation="portrait" pagewide="no">
    
<label>4</label>
    
<caption><title>Study coding of our analyses of employment and educational interviews</title></caption>
    
<graphic copyright="inherit" id="tbl4a" xlink:href="prs_12_4_157_tbl4a.tif" xlink:type="simple"/>
    
<search-text>
      
        
          Study
          r
          N
          Reliability
          Moderator
          Notes
        
      
      
        
          1Little changes if one recodes the Calkins study with a reliability of .75 as the corrected
            validity changes to .369 with an 80% credibility interval of .272&#8211;.466. 2Authors
            noted in correspondence that this interview did not allow probing in addition to questions and it was the
            highest level of structure in the interviewing literature.
        
      
      
        
          Applicant condition
        
        
          Bass (1949)
          .28
          32
          .766
          Employment
          
        
        
          
          .27
          30
          .766
          Employment
          
        
        
          Davey (1984)
          .30
          707
          .75
          Employment
          
        
        
          Melchers, Klehe, Richter, Kleinmann, and K&#246;nig
              (2005)
          .19
          94
          .92
          Employment
          
        
        
          Reeb (1969)
          .44
          1,250
          .72
          Employment
          
        
        
          Shahani et al. (1991)
          .16
          2,583
          .72
          Educational
          Not all applicants are interviewed, less structured interview.
        
        
          Tubiana and Ben-Shakhar (1982)
          .33
          459
          .72
          Employment
          
        
        
          Van Iddekinge and Eidson (2005)
          .18
          412
          .75
          Employment
          Authors indicated a behavioral interview and probing allowed.
        
        
          Direct range restriction
        
        
          Calkins et al. (1974)
          .19
          241
          .92
          Educational
          Berry codes reliability as .92. Could also justify .75 based on documentation.1
        
        
          
          .20
          335
          .92
          Educational
          
        
        
          Campion et al. (1998)
          .49
          140
          .92
          Employment
          
        
        
          Hilliard (2001)
          .10
          149
          .75
          Employment
          
        
        
          Johnson (1990)
          .13
          31
          .72
          Educational
          Semi-structured
        
        
          
          .24
          31
          .69
          Educational
          Unstructured
        
        
          
          .08
          30
          .92
          Educational
          Structured
        
        
          Klehe and Latham (2005)
          .11
          79
          .92
          Unclear
          MBA students interviewed for team work related skills. Criterion was peer assessment of skills in
            course.
        
        
          Van Iddekinge and Henry
            (2006)2
          .25
          203
          .92
          Employment
          
        
        
          
          .23
          187
          .92
          
          
        
        
          Villanova et al. (1994)
          .17
          161
          .69
          Employment
          Berry codes reliability as .92. Authors called the interview unstructured.
        
        
          Additional new study
        
        
          Dayan et al. (2008)
          .44
          1,528
          .75
          Employment
          Applicant level study
        
      
    </search-text>
  </table-wrap></floats-group>

</article>