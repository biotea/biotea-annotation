<?xml version='1.0' encoding='US-ASCII'?>
<!DOCTYPE article PUBLIC "-//APA//DTD APA Journal Archive DTD v1.0 20130715//EN" "http://xml.apa.org/serials/jats-dtds-1.0/APAjournal-archive.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" xml:lang="en" structure-type="article" dtd-version="1.0">
<front>
<journal-meta>
<journal-title-group>
<journal-title xml:lang="en">Aviation Psychology and Applied Human Factors</journal-title>
</journal-title-group>
<issn pub-type="print">2192-0923</issn>
<issn pub-type="online">2192-0931</issn>
<publisher>
<publisher-name>Hogrefe Publishing</publisher-name></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="apaID">apf_2_2_49</article-id>
<article-id pub-id-type="doi">10.1027/2192-0923/a000027</article-id>
<article-id pub-id-type="pi-uid">2013-00193-001</article-id>
<article-categories>
<subj-group subj-group-type="toc-heading">
<subject>Original Article</subject>
</subj-group>
</article-categories>
<title-group><article-title>Developing a Single-Pilot Line Operations Safety Audit: An Aviation Pilot Study</article-title>
</title-group>
<contrib-group content-type="primary-authors">
<contrib contrib-type="author" corresp="no" rid="aff1" xlink:type="simple"><string-name>
<given-names>Laurie</given-names>
<surname>Earl</surname></string-name>
</contrib>
<contrib contrib-type="author" corresp="no" rid="aff1" xlink:type="simple"><string-name>
<given-names>Paul R.</given-names>
<surname>Bates</surname></string-name>
</contrib>
<contrib contrib-type="author" corresp="no" rid="aff1" xlink:type="simple"><string-name>
<given-names>Patrick S.</given-names>
<surname>Murray</surname></string-name>
</contrib>
<contrib contrib-type="author" corresp="yes" rid="aff2 aff3 corr1" xlink:type="simple"><string-name>
<given-names>A.</given-names>
<surname>Ian Glendon</surname></string-name>
</contrib>
<contrib contrib-type="author" corresp="no" rid="aff3" xlink:type="simple"><string-name>
<given-names>Peter A.</given-names>
<surname>Creed</surname></string-name>
</contrib>
<aff id="aff1">Aerospace Strategic Study Centre, Griffith Aviation, Griffith
University, Queensland, Australia</aff>
<aff id="aff2">Work &amp; Organisational Wellbeing Research Centre, Griffith
University, Queensland, Australia</aff>
<aff id="aff3">Behavioural Basis of Health, Griffith University,
Queensland, Australia</aff>
<bio xlink:type="simple">
<p align="left">A. Ian Glendon
, BA (Hons), MBA, PhD, works in the School
of Applied Psychology, Griffith University. His research focuses on safety and
risk. He is an editorial board member for four international journals, and is
the immediate past-president of the International Association of Applied
Psychology&#8217;s Traffic and Transportation Psychology Division.</p></bio>
<bio xlink:type="simple">
<p align="left">Laurie Earl
, BSc, (Hons), MSc, has worked in the
airline industry as a human factors specialist and has taught human factors,
aviation medicine/flight physiology and culture at the tertiary level in
Australia and internationally. Her current research is in aviation safety for
single-pilot operators.</p></bio>
<bio xlink:type="simple">
<p align="left">Paul Bates
, BSc, PhD, is Head of Aviation at Griffith
University. He is the managing editor of an international journal and a member
of several international committees and advisory boards, chairing the Outreach
Committee of the International Civil Aviation Organisation Next Generation of
Aviation Professionals (ICAO NGAP) task force.</p></bio>
<bio xlink:type="simple">
<p align="left">Patrick Murray
, MAvMgmt, FRAeS, FAIM, is Director of the
Griffith University Aerospace Strategic Study Centre. He held senior positions
in the military, a major international airline, and the Australian Civil
Aviation Safety Authority. He is an editorial board member for two international
journals, and researches regional airline safety.</p></bio>
<bio xlink:type="simple">
<p align="left">Peter Creed
, BA (Hons), MPsych (Applied), PhD, works
in the School of Applied Psychology at Griffith University. His research
interests span the related fields of occupational and career psychology, and
include the specific areas of career development, occupational well-being, human
factors, and psychometrics.</p></bio></contrib-group><author-notes><corresp id="corr1"><addr-line>A. Ian Glendon</addr-line><addr-line>School of Applied Psychology</addr-line><addr-line>Gold Coast Campus</addr-line><addr-line>Griffith University</addr-line><addr-line>Queensland 4222</addr-line><addr-line>Australia</addr-line><phone>+61
7 5552-8964</phone><fax>+61 7 5552-8291</fax><ext-link specific-use="live" xlink:href="mailto:i.glendon@griffith.edu.au" ext-link-type="email" xlink:type="simple">i.glendon@griffith.edu.au</ext-link></corresp>
</author-notes>
<pub-date pub-type="print"><string-date><year>2012</year></string-date></pub-date><volume>2</volume>
<issue>2</issue>
<fpage>49</fpage>
<lpage>61</lpage>
<permissions copyright-status="active">
<copyright-year>2012</copyright-year>
<copyright-holder>Hogrefe Publishing</copyright-holder>
</permissions>
<abstract xml:lang="en">
<p align="left">A single-pilot form of the line operations safety audit was trialed with a
mid-sized emergency medical service air operator using two observers with a
sample of pilots flying 14 sectors. The conceptual basis for observing pilot
performance and analyzing data was the threat and error management model,
focusing on threats, errors, undesired aircraft states, and their management.
Forty-six threats and 42 crew errors were observed. Pilots generally used sound
strategies to prevent errors and to manage successfully those that occurred.
Threats resulting from operational pressures were well managed. The study
achieved its objective of determining whether a single-pilot line operations
safety audit could be successfully developed and used as a basis for systematic
data collection.</p>
</abstract>
<kwd-group xml:lang="en">
<kwd>aviation safety</kwd>
<kwd>in-flight observations</kwd>
<kwd>threat and error management model</kwd>
<kwd>countermeasures</kwd>
<kwd>undesired aircraft states</kwd>
</kwd-group>
</article-meta></front>
<body>
<sec id="s1">
<title>Introduction</title>
<p align="left">Among proactive approaches
increasingly supplementing traditional routes to improved aviation safety is the
line operations safety audit (LOSA; <xref ref-type="bibr" id="cr14-1" rid="c14">Klinect, Murray, &amp; Helmreich, 2003</xref>; <xref ref-type="bibr" id="cr23-1" rid="c23">Thomas, 2004</xref>). The LOSA is a safety
management tool developed for, and used in, aviation to collect data on and manage
threats and errors occurring during everyday operations. Endorsed by the
International Civil Aviation Organization (<xref ref-type="bibr" id="cr11-1" rid="c11">ICAO, 2002</xref>), LOSA methodology involves observing normal
multicrew operations with minimal observer effect to capture flight crew
performance. Aircraft operators are assisted in discovering how close they are to
safety limits without breaching them.</p>
<p align="left">Bringing single-pilot commercial
aircraft operations up to the safety and operating efficiency levels of multicrewed
operations presents significant challenges. For example, <xref ref-type="bibr" id="cr10-1" rid="c10">Horne (2008)</xref> estimated that 62% of the
US turboprop fleet are single-pilot operated, yet 74% of all turboprop crashes
involved single-pilot aircraft. In 2008 in Australia, single-pilot operations
accounted for 2,059 incidents and 204 crashes, involving 49 fatalities and 45
serious injuries (<xref ref-type="bibr" id="cr1-1" rid="c1">Australian Transport Safety
Bureau, 2009</xref>). Finding ways to reduce crash incident rates
in single-pilot operations is urgent. LOSA is well-established in multicrew
operations, where it draws on the communication among personnel for its rich data,
but whether it is transferrable to single-pilot operations has hitherto not been
researched.</p>
<p align="left">This paper reports a study to
determine the validity and practicality of a single-pilot LOSA concept. The key
question was whether, without cross talk between pilots, there would be sufficient
rich and valid data to draw conclusions that could usefully inform training, change
processes, and protocols. This is a new departure for LOSA.</p>
<sec id="s2" disp-level="subsect1">
<title>LOSA Origins</title>
<p align="left">LOSA was developed to assist crew
resource management (CRM) practices in reducing human error in complex flight
operations (<xref ref-type="bibr" id="cr8-1" rid="c8">Helmreich et al.,
2002</xref>). When it emerged that identification of threats
and threat management were critical in this process, these were added to the
concept. Recognizing the ubiquitous nature of threats and errors in normal
operations and, importantly, their management by flight crew, this framework
culminated in the threat and error management (TEM) model within LOSA
(<xref ref-type="bibr" id="cr9-1" rid="c9">Helmreich, Wilhelm, Klinect, &amp;
Merritt, 2001</xref>). The inaugural TEM LOSA Collaboration
between the University of Texas and Continental Airlines in 1996 provided proof
of concept for LOSA, transforming it from a research methodology to an industry
safety tool (<xref ref-type="bibr" id="cr13-1" rid="c13">Klinect,
2005</xref>).</p>
<p align="left">A LOSA aims to provide airlines
with an operational baseline of their strengths and weaknesses, giving them
insights into flight deck performance during normal flights. LOSA data have
demonstrated that 98% of flights experience one or more threats (average four
per flight), with errors observed on 82% of flights (<xref ref-type="bibr" id="cr13-2" rid="c13">Klinect, 2005</xref>), most of which are
well managed. By understanding what crews do successfully, as well as where
things go wrong, training and safety initiatives can be made more effective.
Flight crew and flight operations managers can readily follow TEM concepts,
particularly error reduction and mitigation, rather than aiming for the
impossibility of error elimination.</p>
<p align="left">Not everyone agrees that counting
threats and errors is a reliable way of measuring safety. <xref ref-type="bibr" id="cr4-1" rid="c4">Dekker (2003)</xref> stated that error
categorization is not equivalent to understanding error. <xref ref-type="bibr" id="cr5-1" rid="c5">Dougherty (1990)</xref> commented that
error classification schemes are often unable to distinguish cause from
consequence and identified safety as being more than the measurement and
management of negatives (errors), aspects of which can only be captured by a
less numerical approach. These authors variously identified the critical
importance of safety culture to safe practices. A strong possibility is that
companies that conduct a LOSA already have a positive safety culture. The
influence of these authors ensured that CRM (and LOSA) was accompanied by
proactive organizational support, while <xref ref-type="bibr" id="cr3-1" rid="c3">Cooper et al. (1980)</xref> saw secondary benefits of improved
morale and enhanced efficiency. <xref ref-type="bibr" id="cr20-1" rid="c20">Rochlin
(1986)</xref> argued that collective commitment to safety was
an institutionalized social construct, ensuring that organizations not only
performed well but also transmitted an operational culture of mutual
responsibility. By engaging in repeat LOSAs, an organization reaffirms its
commitment to safety through a dynamic, interactive, and interdependent
process.</p>
</sec>
<sec id="s3" disp-level="subsect1">
<title>International Acceptance</title>
<p align="left">The LOSA gained international
recognition in 2001 when it became a central focus of the Flight Safety and
Human Factors Program (<xref ref-type="bibr" id="cr14-2" rid="c14">Klinect et al.,
2003</xref>). The LOSA has since become a central focus for the
International Civil Aviation Organization (<xref ref-type="bibr" id="cr11-2" rid="c11">ICAO, 2002</xref>), which has recognized it as best
practice for airlines, dramatically increasing its use. Since the inception of
LOSAs in 1994 at the request of Delta Airlines (<xref ref-type="bibr" id="cr14-3" rid="c14">Klinect et al., 2003</xref>), observations have been
conducted on well over 10,000 flights with over 50 airlines worldwide. Airlines
with repeat LOSAs report a significant decrease in errors when improved training
or procedures have been adopted in response to LOSA findings. Regional airlines
have seen the potential benefits of a safety audit with plans by the LOSA
Collaborative to bring regional airlines within the LOSA domain
(<xref ref-type="bibr" id="cr21-1" rid="c21">Rosenkrans,
2007</xref>). Several regional airline LOSAs have been
completed, and differences in patterns of threat and error management between
small regional and large international airlines are apparent (<xref ref-type="bibr" id="cr16-1" rid="c16">Murray &amp; Bates, 2010</xref>).</p>
</sec>
</sec>
<sec id="s4">
<title>Theoretical and Methodological Framework</title>
<sec id="s5" disp-level="subsect1">
<title>Threat and Error Management Model</title>
<p align="left">TEM seeks to improve safety
margins in aviation operations through practical integration of human factors
knowledge (<xref ref-type="bibr" id="cr15-1" rid="c15">Maurino,
2005</xref>). The model (see <xref ref-type="fig" id="fgc1-1" rid="fig1">Figure 1</xref>)
conceptualizes operational activity in terms of threats and errors that flight
crews must manage to maintain adequate safety margins. The model captures
performance in its &#8220;natural&#8221; or normal operating context by
quantifying aspects of performance effectiveness. The TEM model is descriptive
and diagnostic of both human and system performance in normal operations. When
combined with an observational methodology such as LOSA, TEM is used to
understand systemic patterns within a large set of events, as with operational
audits. It helps to clarify human performance, needs, strengths, and
vulnerabilities.<xref ref-type="fig-anchor" rid="fig1"/></p>
<p align="left">From a flight crew perspective,
the three basic components of the TEM model are threats, errors, and undesired
aircraft states (UASs). Threats and errors are part of everyday aviation
operations that must be managed by flight crew, as otherwise they have the
potential to generate UASs, which can lead to unsafe outcomes. UAS management is
the last opportunity to avoid an unsafe outcome. Threats are events or errors
external to flight crew influence that can increase the operational complexity
of a flight, and which require immediate crew attention to maintain safety
margins. Environmental threats, which are outside the direct control of the
flight crew and the airline include adverse weather, hazardous airport
conditions, air traffic control shortcomings, bird strikes, and high terrain.
Airline threats, which are outside the direct control of the flight crew, but
within management&#8217;s purview, include aircraft malfunctions, cabin
interruptions, operational pressure, ground/ramp errors/events, cabin events and
interruptions (e.g., human factors), ground maintenance errors, and inadequacies
of manuals and charts. Increasing complexity in the operating environment,
including challenging and distracting events, increases the workload as flight
crews must divert their attention from normal flight duties to manage those
threats. A mismanaged threat is one that is linked to, or that induces, flight
crew error.</p>
<p align="left">Approximately 15% of aviation
errors are directly linked to a threat, with the remaining 85% related to human
performance (<xref ref-type="bibr" id="cr13-3" rid="c13">Klinect,
2005</xref>). Crew errors can vary from minor deviations, such
as entering the wrong assigned altitude into the autopilot and immediately
rectifying the mistake, to more severe errors, such as failing to set flaps
before takeoff. Regardless of cause or severity, error outcome depends on
whether the crew detects and manages the error before it leads to an unsafe
outcome. The foundation of TEM lies in understanding error management rather
than solely focusing on error commission.</p>
<p align="left">The TEM model recognizes three
basic categories of flight crew error, defined as flight crew action or inaction
that leads to a deviation from organizational expectations or crew intentions:
aircraft handling errors, procedural errors, and communication errors. The four
types of aircraft handling errors are manual handling / flight control,
automation, system/instrument/radio, and ground navigation. The seven types of
procedural errors are briefing, callout, checklist, standard operating procedure
(SOP) cross-verification, documentation, pilot flying / pilot not flying duty,
and &#8220;other&#8221;. The two types of communication errors are
crew-external and pilot-to-pilot. A mismanaged error is one that is linked to,
or that induces, additional error or a UAS. A further classification is
associated with whether the deviation was unintentional or deliberate (e.g., SOP
noncompliance).</p>
<p align="left">A UAS is an aircraft configuration
that generates a safety-compromised situation resulting from ineffective threat
and error management due to flight crew error. The pilot usually detects the UAS
without recognizing the original error, which may not need to be corrected. For
example, the solution to a &#8220;floated landing&#8221; on a short runway may
be a go-around. The potential for a serious outcome means that UAS management is
vital.</p>
</sec>
<sec id="s6" disp-level="subsect1">
<title>Threat and Error Countermeasures</title>
<p align="left">The TEM model provided a broader
base for understanding CRM performance skills, also described as threat and
error countermeasures, which are used to anticipate threats, avoid errors, and
detect and mitigate events/errors that occur. Research led to the development of
12 crew countermeasures in four higher level activities: team climate, planning,
execution, and review/modification (<xref ref-type="bibr" id="cr7-1" rid="c7">Helmreich, 2001</xref>). <xref ref-type="table" id="tbc1-1" rid="tbl1">Table 1</xref>
outlines the threat and error countermeasures.<xref ref-type="table-anchor" rid="tbl1"/></p>
</sec>
<sec id="s7" disp-level="subsect1">
<title>Aims of the Current Study</title>
<p align="left">The first aim was to determine
whether a single-pilot line operations safety audit (LOSA-SP) could be
successfully developed and used as a basis for systematic data collection in a
single-pilot operational environment. A single-pilot version of the LOSA was
devised and trialed with two observers monitoring a sample of pilots flying
various sectors. The second aim was to determine whether the TEM model could be
used as the conceptual basis for data collection and analysis. The specific aim
here was to determine whether pilot performance could be rated using four
standard threat and error countermeasure categories.</p>
</sec>
</sec>
<sec id="s8">
<title>Method</title>
<sec id="s9" disp-level="subsect1">
<title>LOSA-SP Methodology</title>
<p align="left">To facilitate the differences
applicable to single-pilot operations, adaptations were made to the LOSA
methodology, including revising some error categories. LOSA indicators based on
the TEM framework were retained but adjusted to suit single-pilot operations.
The University of Texas proposed 10 operating characteristics
(<xref ref-type="bibr" id="cr7-2" rid="c7">Helmreich, 2001</xref>)
critical to successful implementation of a LOSA, which have been adopted and
endorsed by the <xref ref-type="bibr" id="cr11-3" rid="c11">ICAO
(2002)</xref>. These were replicated for single-pilot
operations. The LOSA-SP collected data on pilot demographics, threat occurrence
and threat management, error occurrence and error management, and CRM
effectiveness, through TEM-based behavioral markers.</p>
</sec>
<sec id="s10" disp-level="subsect1">
<title>Integrity of Methodology</title>
<p align="left">Salient issues when conducting
LOSA observations include data reliability (<xref ref-type="bibr" id="cr19-1" rid="c19">Reid, 1982</xref>), establishing trust with those
being observed (<xref ref-type="bibr" id="cr12-1" rid="c12">Johnson,
1975</xref>), coding system accuracy (<xref ref-type="bibr" id="cr2-1" rid="c2">Bakeman, 2000</xref>), and observational
reactivity, which occurs when individuals alter their normal behaviors because
of an observer&#8217;s presence (<xref ref-type="bibr" id="cr14-4" rid="c14">Klinect et al., 2003</xref>). In single-pilot operations, the
LOSA observer uses the copilot&#8217;s seat. Management commitment to the
audit, together with promulgating a &#8220;just culture,&#8221; is paramount
to success. It is important to recruit pilots who are both willing to act as
observers and representative of the group. To counter any possible bias of
individuals affecting observations within a small company, the training included
a full explanation of the LOSA methodology.</p>
</sec>
<sec id="s11" disp-level="subsect1">
<title>Operating Characteristics</title>
<p align="left">The LOSA-SP was developed by
closely matching the 10 characteristics with those specified by the
International Civil Aviation Organization (<xref ref-type="bibr" id="cr11-4" rid="c11">ICAO, 2002</xref>).<list list-type="arabic">
<list-item><label>1</label>
<p align="left"><italic>Observations
during normal flight operations:</italic> Occupying the copilot
seat, observers did not converse with the pilot, nor help in
high-load situations. Observations were made discretely using note
taking. Narratives were recorded as soon after the flight as
possible. Laptop computers or personal digital assistants were not
allowed, as these could distract the pilot.</p></list-item>
<list-item><label>2</label>
<p align="left"><italic>Joint
management/pilot sponsorship:</italic> The steering committee,
involved at all stages of the project, included management and
pilots.</p></list-item>
<list-item><label>3</label>
<p align="left"><italic>Voluntary crew
participation:</italic> Observations were conducted only when
pilots agreed to the observer being on board. Information was given
to the pilots prior to flights commencing, and their consent was
obtained. None refused to participate.</p></list-item>
<list-item><label>4</label>
<p align="left"><italic>De-identified,
confidential, and safety-minded data collection:</italic>
Observations were based on International Civil Aviation Organization
guidelines (<xref ref-type="bibr" id="cr11-5" rid="c11">ICAO,
2002</xref>), ensuring that no identifying
information was recorded.</p></list-item>
<list-item><label>5</label>
<p align="left"><italic>Targeted
observation instrument:</italic> Observers used specially
designed schedules based on TEM and adapted from LOSAs for multicrew
operations. The schedules targeted threats, errors, and UASs, and
how each was identified and managed. Codes were developed by the
company, pilots, and the research team.</p></list-item>
<list-item><label>6</label>
<p align="left"><italic>Trusted,
trained, and calibrated observers:</italic> Observers were
volunteer pilots trained by the researchers. Following initial
training, the observers carried out a trial run on two flight
sectors, returning for data calibration to ensure coding consistency
and reliability.</p></list-item>
<list-item><label>7</label>
<p align="left"><italic>Trusted data
collection site:</italic> All observation worksheets were
retained by the researchers for data entry, storage, cleaning, and
analysis. No one in the company could access the observation data,
and no pilot could be identified from the worksheets.</p></list-item>
<list-item><label>8</label>
<p align="left"><italic>Data
verification roundtables:</italic> Sessions were conducted
primarily by the researchers for coding reliability and checked with
subject matter experts (managers) from the company.</p></list-item>
<list-item><label>9</label>
<p align="left"><italic>Data-derived
targets for enhancement:</italic> In multicrew LOSAs, trends are
analyzed and prioritized for attention after data analysis. In this
study, where data were sufficiently robust, recommendations were
provided to the company.</p></list-item>
<list-item><label>10</label>
<p align="left"><italic>Feedback of
results to line pilots:</italic> Management reported back to the
pilots on the major issues.</p></list-item></list></p>
</sec>
<sec id="s12" disp-level="subsect1">
<title>Procedure</title>
<p align="left">After initial meetings with crew
and management at a mid-sized emergency medical system (EMS) company operating
single-pilot, twin turboprop, fixed-wing aircraft, a draft research proposal was
developed. Following agreement by the company and pilot representatives to
participate, an introductory newsletter was circulated, observer expressions of
interest were invited, and a LOSA presentation was made to pilots and managers.
A 5-day observer training course for two volunteer pilots was conducted by the
third author (P.S.M.).</p>
</sec>
<sec id="s13" disp-level="subsect1">
<title>Observer Training</title>
<p align="left">LOSA observer training occurred in
two parts: (1) education in procedural protocol and (2) teaching TEM concepts
and classifications (<xref ref-type="bibr" id="cr14-5" rid="c14">Klinect et al.,
2003</xref>). Training emphasized the confidentiality and
anonymity of observations, how to brief crews, and introduced &#8220;LOSA
etiquette,&#8221; including when to speak up regarding a safety-critical event
not detected by a pilot. It teaches observers how to recognize, record, and code
TEM performance. Observers were trained to focus on capturing data first, and
classifying and coding them later (<xref ref-type="app" id="apcA-1" rid="A">Appendix A</xref> shows the error management worksheet and
<xref ref-type="app" id="apcB-1" rid="B">Appendix B</xref> the
threat management worksheet). Training included demonstrations and examples, as
well as test exercises and a trial run with subsequent recalibration.</p>
<p align="left">Pilots were trained to observe
passively, not forming part of the constituted crew and making no operational
input. The observers then flew 14 sectors of the company&#8217;s route network
and crew, including day and night flights. Observations were conducted on a
strict &#8220;no jeopardy&#8221; basis, so that no names, flight numbers, or
dates were recorded. Management agreed that, regardless of event, crew members
would not be tracked through LOSA observations. After a flight, the pilot was
asked standard questions about aspects of the operational environment, including
their perceptions of the operation, such as what they considered to be the
greatest safety issue.</p>
<p align="left">Observers were instructed to rate
a countermeasure if they observed it or if its absence was significant (e.g., a
pilot failed to evaluate their plan in light of new information). A once-only
rating was given for overall crew effectiveness, leadership, and communication.
Planning countermeasures, which are integral to threat management, and execution
countermeasures, considered crucial for error detection and error management,
were rated during predeparture/taxi-out, cruise, and descent/approach/landing.
Observers rated pilots&#8217; performance using a 4-point scale: 1 = poor
&#8211; had safety implications; 2 = marginal &#8211; adequate but needs
improvement; 3 = good &#8211; effective; and 4 = outstanding &#8211; truly
noteworthy (see <xref ref-type="table" id="tbc1-2" rid="tbl1">Table
1</xref>).</p>
</sec>
</sec>
<sec id="s14">
<title>Results</title>
<sec id="s15" disp-level="subsect1">
<title>Sample Description</title>
<p align="left">Crew experience ranged from 5 to
47 years (3,500&#8211;22,500 hr), with experience on the specific aircraft type
ranging from 100 to 15,000 hr (mean 2,773 hr). All observed pilots were male,
and their work experience with the company ranged from 1 to 25 years (mean 8.25
years). Of the 14 observed flights (10 day, 4 night), 13 were on familiar
routes, with 12 being normal flights and two involving short-notice changes of
route or destination prior to departure.</p>
</sec>
<sec id="s16" disp-level="subsect1">
<title>Observed Threats</title>
<p align="left">Forty-six threats were observed
during the 14 flights (mean 3.3 threats/flight). <xref ref-type="table" id="tbc2-1" rid="tbl2">Table 2</xref>
shows the numbers of threats observed by major category, with further
descriptions of the categories below.<xref ref-type="table-anchor" rid="tbl2"/></p>
<sec id="s17" disp-level="subsect2">
<title>Air Traffic Control</title>
<p align="left">Air traffic control (ATC)
threats were most frequent, with challenging or late clearances being the
major concern. Other threats were making frequent heading or altitude
changes, incorrect notices to airmen (NOTAMs), and poor quality ATC
transmissions. While a small number of threats was recorded due to ATC
errors, the major difficulties were caused by clearances that challenged the
crew to perform ATC requirements. Most of these threats occurred during the
descent and approach phases when ATC managed traffic under congested
conditions.</p>
</sec>
<sec id="s18" disp-level="subsect2">
<title>Airport Conditions</title>
<p align="left">Airport threats were the
second most frequent category. Some were due to runway maintenance or
contamination, one being exacerbated by an unresponsive airport safety
officer. Other threats reflected the company&#8217;s operating environment,
which involved pilots encountering unfamiliar airstrips, short airstrips
with low apron maneuvering capacity, and airports operating in nontowered
Class G airspace.</p>
</sec>
<sec id="s19" disp-level="subsect2">
<title>Weather Conditions</title>
<p align="left">The third most frequent threat
was posed by weather conditions. Marginal visual flight rules, mainly due to
low cloud, added to threat frequency. Other threats included smaller
airstrips with no terminal aerodrome forecast (TAF).</p>
</sec>
<sec id="s20" disp-level="subsect2">
<title>Operational Pressures</title>
<p align="left">The fourth most frequent
threat category, operational pressures, was almost exclusively associated
with company operational requirements, such as changes in task or route,
which is normal for this company&#8217;s operations.</p>
</sec>
<sec id="s21" disp-level="subsect2">
<title>Environmental Operational Pressure</title>
<p align="left">Fifth was environmental
operational pressure, partly due to the complications of the airspace in
which the company operated. Threats included high ground, high lowest safe
altitude (LSALT), and high traffic volumes in uncontrolled airspace.</p>
</sec>
<sec id="s22" disp-level="subsect2">
<title>Other Threat Types</title>
<p align="left">A small number of
&#8220;other&#8221; threats were recorded that could potentially cause
problems. Aircraft automation posed a threat on two occasions.</p>
</sec>
<sec id="s23" disp-level="subsect2">
<title>Phase of Flight</title>
<p align="left">The five flight phases in
which a threat could occur were predeparture/taxi-out, take-off/climb,
cruise, descent/approach/landing, and taxi-in (see Figure 2). The highest
frequency of threats originated in the predeparture/taxi-out phase. These
included tasks and associated workload or with changes to it, and threats
associated with ATC at the departure airfield. The descent/approach/landing
phase had the next highest number of threats, with none in the taxi-in
phase, despite pilots commenting that some airports had
&#8220;tight&#8221; maneuvering areas, perhaps indicating some level of
&#8220;normalization&#8221; of these threats.</p>
</sec>
</sec>
<sec id="s24" disp-level="subsect1">
<title>Errors</title>
<p align="left">Forty-two crew errors were
observed during the 14 flights (mean 3.0/flight). Crew errors were classified
under four categories: intentional noncompliance, aircraft handling, procedural,
and communication errors (see <xref ref-type="table" id="tbc3-1" rid="tbl3">Table
3</xref>). Intentional
noncompliance and procedures errors were significant.<xref ref-type="table-anchor" rid="tbl3"/></p>
<p align="left">While LOSA methodology captures
errors committed, it is equally important to assess management and mismanagement
rates. Most errors occurred in the predeparture/taxi-out phase (<xref ref-type="fig" id="fgc2-1" rid="fig2">Figure 2</xref>), which could be associated with a large number of threats and
high workload, particularly with a change in task or destination. This phase
also required the use of checklists, which were sometimes either omitted or
performed from memory. Several errors were associated with the pilot being
&#8220;head-down&#8221; (e.g., updating systems) while taxiing.<xref ref-type="fig-anchor" rid="fig2"/></p>
</sec>
<sec id="s25" disp-level="subsect1">
<title>Error Management</title>
<p align="left">In multicrew operations, there is
invariably a requirement for pilots to verbalize their actions, briefings, and
intentions. Checklists are conducted as &#8220;challenge and response.&#8221;
Generally there is no such requirement in single-pilot operations, with views
being divided on the value of this process. While this company did not stipulate
that pilots should verbalize, it was informally reported to the research team
that there was a fairly even split between pilots who did and did not verbalize.
On six of the 14 observed flights, pilots verbalized their actions and
intentions and used checklists out loud in a &#8220;challenge and
response&#8221; fashion. On these flights, seven procedural errors were
observed (1.1 errors/flight), of which five were managed well. Of eight flights
where the pilot did not verbalize, 11 procedural errors were observed (1.4
errors/flight), of which four were well managed (see <xref ref-type="fig" id="fgc3-1" rid="fig3">Figure 3</xref>).<xref ref-type="fig-anchor" rid="fig3"/></p>
</sec>
<sec id="s26" disp-level="subsect1">
<title>Threat Management</title>
<p align="left">While all threats can potentially
affect safety adversely, some categories were better managed than others.
&#8220;Mismanaged&#8221; threats (those not detected, or which led to errors)
are of particular concern, especially those with high rates of occurrence and
high rates of mismanagement (i.e., having increased risk potential). For
example, a pilot is required to conduct many essential procedures from memory,
and a checklist is then used to ensure that the actions required have been
correctly completed. While a missed checklist might not be a major event in
itself unless coupled with an earlier procedural error by the pilot, risk
increases significantly when checklists are missed on several occasions.
<xref ref-type="table" id="tbc2-2" rid="tbl2">Table 2</xref> shows that
although ATC created the greatest number of threats, those threats were well
managed on all but one occasion. Conversely, while weather accounted for six
threats (12.5%), these were mismanaged on 50% of occasions.</p>
</sec>
<sec id="s27" disp-level="subsect1">
<title>Undesired Aircraft States</title>
<p align="left">Six UASs were observed (mean
0.43/flight), all with inconsequential outcomes. <xref ref-type="table" id="tbc4-1" rid="tbl4">Table 4</xref>
shows the most common UASs and their management.<xref ref-type="table-anchor" rid="tbl4"/></p>
<sec id="s28" disp-level="subsect2">
<title>Countermeasures</title>
<p align="left">If performance on any item was
rated as anything other than &#8220;good,&#8221; then observers were
required to explain their rating in their accompanying narratives. To
illustrate the observers&#8217; range of marks for each countermeasure,
<xref ref-type="table" id="tbc5-1" rid="tbl5">Table 5</xref> shows the four highest and the four lowest
ratings. Of the lowest scoring markers, monitor/cross-check showed the
greatest variation in scores, with as many pilots scoring &#8220;4 &#8211;
outstanding&#8221; as scored &#8220;1 &#8211; poor&#8221; or &#8220;2
&#8211; marginal.&#8221;<xref ref-type="table-anchor" rid="tbl5"/></p>
</sec>
<sec id="s29" disp-level="subsect2">
<title>Standardization</title>
<p align="left">Standardization addresses the
issue of whether pilots complied with the company&#8217;s SOPs, and whether
these effectively reduced risk. The observations identified useful
variations in performance in these areas.</p>
</sec>
<sec id="s30" disp-level="subsect2">
<title>Checklists</title>
<p align="left">Checklists were the biggest
category of observed errors, which included pilots omitting prestart, after
start, after landing, and shutdown checklists. Some incorrect checklists
were used, and items were sometimes missed from checklists. Checklists were
sometimes completed late or from memory. While most checklist errors were
undetected by the pilots, and the outcomes were mostly inconsequential, on
at least one occasion a missed checklist item led to a UAS.</p>
</sec>
<sec id="s31" disp-level="subsect2">
<title>Cross-Verification</title>
<p align="left">Required cross-verification
was not carried out on several occasions. These included no verification of
flight management system (FMS) flight plans to paper copies, LSALT not
checked on chart, and cabin security not confirmed. These errors went
undetected, on two occasions leading to further errors.</p>
</sec>
<sec id="s32" disp-level="subsect2">
<title>External Communication</title>
<p align="left">On some occasions, no
broadcast calls were made to local traffic, or incorrect departure calls
were made.</p>
</sec>
<sec id="s33" disp-level="subsect2">
<title>Crew Communication</title>
<p align="left">Sterile cockpit procedures are
specified so that the pilot is not involved in potentially distracting
nonoperational conversations during critical phases of flight. On two
occasions, these were not maintained at low altitudes, as a result of not
isolating the cockpit from the cabin interphone system, as required by the
SOP.</p>
</sec>
<sec id="s34" disp-level="subsect2">
<title>Briefings</title>
<p align="left">Briefings not carried out
sometimes led to further errors. In one instance, a pilot did not advise of
an instrument approach as he expected to become visual early in the descent.
The weather was worse than anticipated, leading to a hasty and unbriefed
instrument approach, and subsequently a missed approach and a diversion. On
another occasion, there was no check of a TAF at an alternative airfield,
leading to a hurried briefing when it was found that this was required, also
resulting in a missed approach.</p>
</sec>
</sec>
<sec id="s35" disp-level="subsect1">
<title>Safety Interviews: Key Findings</title>
<p align="left">The following paragraphs introduce
a more subjective element of the strengths and weaknesses of pilots&#8217;
technical performance, coupled with opinions from crew interviews.</p>
<sec id="s36" disp-level="subsect2">
<title>Taxiing</title>
<p align="left">Taxiing was rated lowest in
terms of performance marks, being either poor or marginal. A number of
head-down high pilot workload incidents were observed. On most occasions,
the pilot averted an adverse event by intermittently looking up to maintain
correct position. However, an aircraft once veered significantly on the
taxiway, resulting in a UAS.</p>
</sec>
<sec id="s37" disp-level="subsect2">
<title>Automation Management</title>
<p align="left">Pilots&#8217; automation
skills varied from outstanding to poor. Pilots with previous experience of
the aircraft type were best equipped to manage the FMS. Pilots with little
experience on the aircraft type made more errors, indicating that more
targeted training could benefit pilots new to type.</p>
</sec>
<sec id="s38" disp-level="subsect2">
<title>Safety Concerns</title>
<p align="left">Of pilots who commented, short
notice changes and night operations were of greatest concern, particularly
night operations flying into &#8220;black-hole&#8221; airports without
appropriate navigation aids or with unfamiliar airstrips. Comments included
aircraft parking and taxiing areas being too small, requiring tight
maneuvering with little margin for error. Also mentioned were workload and
the amount of information to be consulted prior to a flight, particularly
for a late task change.</p>
</sec>
<sec id="s39" disp-level="subsect2">
<title>Suggested Safety Improvements</title>
<p align="left">A general comment was that
SOPs should be more specific. Concerns were also expressed about the
centralized tasking center and its &#8220;complacency&#8221; toward night
operations.</p>
</sec>
<sec id="s40" disp-level="subsect2">
<title>Automation</title>
<p align="left">Pilots commented on the poorly
located database unit, which resulted in too much head-down time in the
event of changes to approach or departure. Some saw failures of the attitude
heading reference system (AHRS). One comment concerned a well-documented
failure &#8211; the FMS memory battery failing, resulting in the autopilot
disengaging.</p>
</sec>
<sec id="s41" disp-level="subsect2">
<title>Company Operational Efficiency</title>
<p align="left">Pilots were confident that the
company was sound. Their concern was with external agencies that needed to
be made more aware of the company&#8217;s needs so as to enhance its
efficiency.</p>
</sec>
</sec>
</sec>
<sec id="s42">
<title>Discussion</title>
<sec id="s43" disp-level="subsect1">
<title>Threat and Error Management</title>
<p align="left">While based on a relatively small
sample of operations, the LOSA-SP methodology produced useful and strongly
indicative safety data. Larger samples are required for more definitive
conclusions and recommendations. In light of well-publicized crash rates in
single-pilot fixed-wing and rotary-wing operations, this type of research is
vital in identifying safety improvements in all single-pilot operations.</p>
<p align="left">The mismanagement rate of
intentional noncompliance errors is high because if pilots decide to ignore a
rule or procedure, this is in the expectation of no negative consequences. This
may be because the procedure is unrealistic and is widely ignored, or because a
pilot has &#8220;normalized&#8221; the deviance of procedures as consistent
with the organization&#8217;s safety culture (<xref ref-type="bibr" id="cr25-1" rid="c25">Vaughan, 1999</xref>, <xref ref-type="bibr" id="cr26-1" rid="c26">2005</xref>). While errors in this category generally
lead to inconsequential outcomes, repeated intentional noncompliance errors can
substantially increase overall risk. Given that several shortcomings were
observed in checklists use, and that checklists may be the last line of
procedural defense against human error, these should be the most important
operational area for review.</p>
<p align="left">Communication with an external
party (e.g., ATC) could be critical to safe operations, and although these did
not constitute a large number of errors, consequences of this error type are
potentially severe. In larger single-pilot operations studies, it will be
necessary to observe a greater number and variety of errors during interactions
between pilots and other parties, including cabin crew, ATC, and ground
operations.</p>
<p align="left">While aircraft handling errors are
more easily detected than other errors, their consequences are often more
serious, leading immediately to a UAS. Where monitoring and cross-checking
procedures are well executed, aircraft handling errors should be identified and
corrected before a more serious error or UAS occurs. Although these data were
insufficient to draw definitive conclusions, a high level of mismanagement of
aircraft-handling errors in multicrew LOSAs could indicate weaknesses in
monitoring and cross-checking.</p>
<p align="left">Monitoring and cross-checking also
affect procedural error mismanagement rates. These are best explained as simple
mistakes, such as the wrong altitude being set on the flight control unit (FCU)
panel. The observed 50% mismanagement rate emphasizes the need to review and
reinforce monitoring and cross-checking procedures. However, communication
errors in single-pilot operations may be hard to detect as it is difficult for
an observer to confirm monitoring and cross-checking occurrences. Where a pilot
does not verbalize his/her intentions (which is optional), even an experienced
observer could miss a procedure. However, evidence from this study suggested
that, compared with those who did not do so, pilots who verbalized their
intentions were more assiduous in cross-checking and made fewer mismanaged
procedural errors.</p>
<p align="left">Threats from operational pressures
were all observed to be well managed. Nevertheless, they add to overall flight
complexity, and their reduction should be a management target. Aircraft threats
also fall within the operator&#8217;s domain, and training could reduce the
frequency of threats from this source. Threats due to the cabin environment
might indicate advantages of a multicrew CRM training environment
(<xref ref-type="bibr" id="cr17-1" rid="c17">O&#8217;Connor et al.,
2008</xref>) to include nonpilot EMS crew members. Facing a
variety of standard threats, as well as those unique to the company&#8217;s
operation, the observed pilots generally used sound strategies to prevent errors
and to manage successfully those that occurred.</p>
</sec>
<sec id="s44" disp-level="subsect1">
<title>Undesired Aircraft States</title>
<p align="left">While the data revealed that all
observed UAS outcomes were inconsequential, they are insufficient to draw firm
conclusions. Thus, broadly based strategies to detect and manage UASs are
important in improving safety. A subjective view of the UAS distribution
suggested that incorrect aircraft configuration states and approach/landing
states, vital to safety management, were of particular concern. This UAS
category is highly important, and it was recommended to the company that
individual reports be analyzed to see what lessons might be learned, and to
determine strategies for reducing them. For example, in simulator training,
approach and landing UASs can be introduced with good effect (e.g., poor ATC
vectors onto final approach, leaving an aircraft in a high/fast situation
requiring significant pilot management to avoid an unstable approach).</p>
</sec>
<sec id="s45" disp-level="subsect1">
<title>Other Issues and Further Recommendations</title>
<p align="left">The observers and research team
were impressed with the dedication of the pilots and EMS crew. This was obvious
from the high morale among company crews and the in-flight energy displayed
while performing routine procedures that form the foundation for safe flying.
Evidence from audit and interview data indicated that the company had
established a strong framework to support its flight operations. Well-motivated
and hard working, the pilots enjoyed their work and each other&#8217;s company.
They were very adept at managing changing workloads and adapting quickly to new
instructions. They were seldom observed to be flustered and scored highly on
evaluation of plans. All seemed comfortable with questioning changes and
ensuring flight safety.</p>
<p align="left">There were examples of links
between organizational culture, crew performance, and flight safety. The
positive organizational culture reported at Southwest Airlines has been hailed
as the driving force behind its excellent safety record and financial success
(<xref ref-type="bibr" id="cr6-1" rid="c6">Freiberg &amp; Freiberg,
1996</xref>). Conversely, negative organizational cultural
factors have been cited as contributing to the Challenger disaster, and the 1996
ValueJet 592 crash (<xref ref-type="bibr" id="cr24-1" rid="c24">Vaughan,
1996</xref>). In the current study, questioning revealed belief
in a robust safety culture, which could have contributed to the trust in the
audit and reactions to the findings. Merely setting up a LOSA study has been
found to increase safety awareness, also evident in the current study.</p>
<p align="left">Most observed flights were on
familiar routes, albeit with a few short notice changes. Of interest would be
comparing observation data from flights originating from short notice callouts.
The sample size in this study was selected to determine whether the LOSA
methodology could be adapted to single-pilot operations. This objective was
achieved, as the LOSA methodology was largely transferrable so that all TEM
model categories were observable. However, while the methodology was
transferrable with some adaptations for single-pilot operations (e.g.,
crew&#8211;crew communication), much of the adaptation was operator specific.
This suggests that while the methodology could be used in a single-pilot
concept, further refinement is required, in particular threat type definitions
for other single-pilot operators (e.g., rotary-wing EMS operations).</p>
<p align="left">Experience has shown that in a
typical airline operation, a sample size of around 60 flights is needed to
capture enough errors, threats, and UASs to undertake valid quantitative data
analysis (<xref ref-type="bibr" id="cr13-4" rid="c13">Klinect,
2005</xref>). Larger samples would facilitate cross-tabulating
threat source and flight phase, as in a full LOSA evaluation. Such an analysis
would normally show that a large proportion of threats and errors are
encountered in the preflight and approach/landing flight phases.</p>
<p align="left"><xref ref-type="bibr" id="cr22-1" rid="c22">Sexton and Klinect (2001)</xref> stated that an
airline&#8217;s safety culture combines individual members&#8217; practices,
attitudes, and competencies against a backdrop of organizational policies and
procedures. The current study demonstrated practices and competencies under
normal flying circumstances for both pilots and the system, highlighting the
effectiveness of safety culture in contributing to improvements.
<xref ref-type="bibr" id="cr18-1" rid="c18">Rayner (1992)</xref>
distinguished safety from safeness. Defining an organization as safe because it
has a low rate of errors or incidents has limitations comparable with defining
health in terms of not being sick. A LOSA has been likened to a health check
&#8211; by identifying potential problems (e.g., high cholesterol), a patient
can engage measures to prevent an adverse health event (e.g., heart attack;
<xref ref-type="bibr" id="cr13-5" rid="c13">Klinect, 2005</xref>).
Safeness is the story that a group or organization tells about itself and its
relation to the risk environment. A LOSA aims to capture data that can point to
problems in the system and, together with a positive safety culture, make
changes to improve safety within an organization&#8217;s operations.</p>
</sec>
</sec>
</body>
<back>
<ref-list use-in-PI="yes"><title>References</title>
<ref><mixed-citation publication-type="book" meta="no" id="c1" xlink:type="simple"><person-group person-group-type="author"><collab xlink:type="simple">Australian Transport Safety
Bureau</collab></person-group>. (<year>2009</year>). <source>Aviation
occurrence statistics: 1 January 1999 to 30 June 2009</source>. ((<comment>ATSB
Transport Safety Report; Aviation Research and Analysis AR-2009-016(2)
Final</comment>)). <publisher-loc>Canberra, ACT</publisher-loc>
<publisher-name>Author</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c2" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Bakeman</surname>,
<given-names>R.</given-names></string-name></person-group> (<year>2000</year>).
<chapter-title>Behavioural observation and coding</chapter-title>. In
<person-group person-group-type="editor"><string-name><given-names>H. T.</given-names>
<surname>Reis</surname></string-name> &amp; <string-name><given-names>C. M.</given-names>
<surname>Judd</surname></string-name></person-group> (<role>Eds.</role>),
<source>Handbook of research methods in social and personality
psychology</source> (pp.
<fpage>138</fpage>&#8211;<lpage>159</lpage>).
<publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Cambridge
University Press</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="other" meta="no" id="c3" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Cooper</surname>,
<given-names>G. E.</given-names></string-name>,
<string-name><surname>White</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Lauber</surname>,
<given-names>J. K.</given-names></string-name></person-group>
(<year>1980</year>). <article-title>Resource management on the flightdeck. NASA
Conference Publication 2120. NTIS N80-22083</article-title>
(<fpage>31</fpage>&#8211;<lpage>58</lpage>). <source>Proceedings
of a NASA/Industry Workshop</source>, <comment>Moffett Field, CA, June
26&#8211;28, 1979</comment>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c4" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Dekker</surname>,
<given-names>S.</given-names></string-name></person-group> (<year>2003</year>).
<article-title>Illusions of explanation: A critical essay on error
classification</article-title>. <source>International Journal of Aviation
Psychology</source>, <volume>13</volume>,
<fpage>95</fpage>&#8211;<lpage>106</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c5" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Dougherty</surname>,
<given-names>E. M.</given-names>
<suffix>Jr.</suffix></string-name></person-group> (<year>1990</year>).
<article-title>Human reliability analysis: Where shouldst thou
turn?</article-title>
<source>Reliability Engineering and System Safety</source>, <volume>29</volume>,
<fpage>283</fpage>&#8211;<lpage>299</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c6" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Freiberg</surname>,
<given-names>K. L.</given-names></string-name>, &amp;
<string-name><surname>Freiberg</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>1996</year>).
<source>NUTS!</source>. <publisher-loc>Austin,
TX</publisher-loc>: <publisher-name>Bard</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="other" meta="no" id="c7" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Helmreich</surname>,
<given-names>R.</given-names></string-name></person-group> (<year>2001</year>).
<source>The line operations safety audit (LOSA) and safety culture</source>.
<comment>The University of Texas Human Factors Research Project. LOSA Summit,
Cathay City, Hong Kong, March 12&#8211;14, 2001</comment>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c8" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Helmreich</surname>,
<given-names>R. L.</given-names></string-name>,
<string-name><surname>Klinect</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Wilhelm</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Tesmer</surname>,
<given-names>B.</given-names></string-name>,
<string-name><surname>Gunther</surname>, <given-names>D.</given-names></string-name>,
<string-name><surname>Thomas</surname>, <given-names>R.</given-names></string-name>,
<etal>&#8230;</etal> <string-name><surname>Maurino</surname>,
<given-names>D.</given-names></string-name></person-group> (<year>2002</year>).
<source>Line operations safety audit (LOSA)</source>. (<comment>Doc
9803-AN/761</comment>). <publisher-loc>Montreal</publisher-loc>:
<publisher-name>International Civil Aviation
Organization</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c9" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Helmreich</surname>,
<given-names>R. L.</given-names></string-name>,
<string-name><surname>Wilhelm</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Klinect</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Merritt</surname>,
<given-names>A. C.</given-names></string-name></person-group>
(<year>2001</year>). <source>Culture, error, and crew resource management</source>.
(<comment>Human Factors Research Project Publication 254</comment>).
<publisher-loc>Austin, TX</publisher-loc>: <publisher-name>University of
Texas</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="web-page" meta="no" id="c10" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Horne</surname>,
<given-names>T. A.</given-names></string-name></person-group>
(<year>2008</year>). <article-title>The risks of riding solo</article-title>.
<source>Aircraft Owners and Pilots Association Pilot Magazine</source>.
<issue> October Issue, 1&#8211;3</issue>. <comment>Retrieved from</comment>
<ext-link ext-link-type="uri" xlink:href="http://www.aopa.org/pilot/turbine/safety0810.html" specific-use="live" xlink:type="simple">http://www.aopa.org/pilot/turbine/safety0810.html</ext-link></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c11" xlink:type="simple"><person-group person-group-type="author"><collab xlink:type="simple">International Civil Aviation
Organization (ICAO)</collab></person-group>. (<year>2002</year>). <source>Line
operations safety audit (LOSA)</source>. (<comment>ICAO Document 9803,
AN/761</comment>). <publisher-loc>Montreal</publisher-loc>:
<publisher-name>Author</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c12" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Johnson</surname>,
<given-names>J. M.</given-names></string-name></person-group>
(<year>1975</year>). <source>Doing field research</source>. <publisher-loc>New
York</publisher-loc>: <publisher-name>Free Press</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c13" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Klinect</surname>,
<given-names>J. R.</given-names></string-name></person-group>
(<year>2005</year>). <source>Line operations safety audit (LOSA): A cockpit
methodology for monitoring commercial airline safety performance</source>
(<comment>Dissertation</comment>). <publisher-loc>Austin,
TX</publisher-loc>: <publisher-name>University of
Texas</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c14" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Klinect</surname>,
<given-names>J. R.</given-names></string-name>,
<string-name><surname>Murray</surname>, <given-names>P. S.</given-names></string-name>, &amp; <string-name><surname>Helmreich</surname>,
<given-names>R.</given-names></string-name></person-group> (<year>2003</year>).
<chapter-title>Line operations safety audit (LOSA): Definition and operating
characteristics</chapter-title>. In <source>Proceedings of the 12<sup location="post">th</sup>
International Symposium on Aviation Psychology</source> (pp.
<fpage>663</fpage>&#8211;<lpage>668</lpage>).
<publisher-loc>Dayton, OH</publisher-loc>: <publisher-name>Ohio State
University</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="conference" meta="no" id="c15" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Maurino</surname>,
<given-names>D.</given-names></string-name></person-group> (<month>April</month>,
<year>2005</year>). <source>Threat and error management (TEM)</source>.
<comment>Paper presented at Canadian Aviation Safety seminar, Vancouver, Canada.
Available from</comment>
<ext-link ext-link-type="uri" xlink:href="http://flightsafety.org/archives-and-resources/threat-and-error-management-tem" specific-use="live" xlink:type="simple">http://flightsafety.org/archives-and-resources/threat-and-error-management-tem</ext-link></mixed-citation>
</ref>
<ref><mixed-citation publication-type="other" meta="no" id="c16" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Murray</surname>,
<given-names>P. S.</given-names></string-name>, &amp;
<string-name><surname>Bates</surname>, <given-names>P. R.</given-names></string-name></person-group> (<year>2010</year>).
<article-title>Patterns of threat and error management in regional
airlines</article-title>. <source>Proceedings from the 9<sup location="post">th</sup>
International Australian Aviation Psychology Association Conference</source>.
<comment>Sydney, Australia</comment>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c17" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>O&#8217;Connor</surname>,
<given-names>P.</given-names></string-name>,
<string-name><surname>Campbell</surname>,
<given-names>J.</given-names></string-name>, <string-name><surname>Newton</surname>,
<given-names>J.</given-names></string-name>, <string-name><surname>Melton</surname>,
<given-names>J.</given-names></string-name>, <string-name><surname>Salas</surname>,
<given-names>E.</given-names></string-name>, &amp;
<string-name><surname>Wilson</surname>,
<given-names>K.</given-names></string-name></person-group> (<year>2008</year>).
<article-title>Crew resource management training effectiveness: A meta-analysis
and some critical needs</article-title>. <source>International Journal of
Aviation Psychology</source>, <volume>18</volume>,
<fpage>353</fpage>&#8211;<lpage>368</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c18" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Rayner</surname>,
<given-names>S.</given-names></string-name></person-group> (<year>1992</year>).
<chapter-title>Cultural theory and risk analysis</chapter-title>. In
<person-group person-group-type="editor"><string-name><given-names>S.</given-names>
<surname>Krimsky</surname></string-name> &amp;
<string-name><given-names>D.</given-names>
<surname>Golding</surname></string-name></person-group> (<role>Eds.</role>),
<source>Social theories of risk</source> (pp.
<fpage>83</fpage>&#8211;<lpage>115</lpage>).
<publisher-loc>Westport, CT</publisher-loc>:
<publisher-name>Praeger</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c19" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Reid</surname>, <given-names>J. B.</given-names></string-name></person-group> (<year>1982</year>).
<chapter-title>Observer training in naturalistic research</chapter-title>. In
<person-group person-group-type="editor"><string-name><given-names>D. P.</given-names>
<surname>Hartman</surname></string-name></person-group> (<role>Ed.</role>),
<source>Using observers to study behaviour</source> (pp.
<fpage>37</fpage>&#8211;<lpage>50</lpage>). <publisher-loc>San
Francisco, CA</publisher-loc>:
<publisher-name>Jossey-Bass</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="other" meta="no" id="c20" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Rochlin</surname>,
<given-names>G. I.</given-names></string-name></person-group>
(<month>September</month>, <year>1986</year>). <article-title>High reliability
organisations and technical change: Some ethical problems and
dilemmas</article-title>. <source>IEEE Technology and Society</source>.
<fpage>3</fpage>&#8211;<lpage>9</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="other" meta="no" id="c21" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Rosenkrans</surname>,
<given-names>W.</given-names></string-name></person-group> (<month>March</month>,
<year>2007</year>). <article-title>Threat and error detectives. Flight Safety
Foundation </article-title>. <source>AerosafetyWorld</source>.
<fpage>37</fpage>&#8211;<lpage>39</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c22" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Sexton</surname>,
<given-names>J. B.</given-names></string-name>, &amp;
<string-name><surname>Klinect</surname>, <given-names>J. R.</given-names></string-name></person-group> (<year>2001</year>). <source>The link
between safety attitudes and observed performance in flight operations. Human
Factors Research Project</source>. <publisher-loc>Austin,
TX</publisher-loc>: <publisher-name>Department of Psychology, University of
Texas at Austin</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c23" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Thomas</surname>,
<given-names>M. J. W.</given-names></string-name></person-group>
(<year>2004</year>). <article-title>Predictors of threat and error management:
Identification of core nontechnical skills and implications for training systems
design</article-title>. <source>International Journal of Aviation
Psychology</source>, <volume>14</volume>,
<fpage>207</fpage>&#8211;<lpage>231</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c24" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Vaughan</surname>,
<given-names>D.</given-names></string-name></person-group> (<year>1996</year>).
<source>The Challenger launch decision: Risky technology, culture, and deviance
at NASA</source>. <publisher-loc>Chicago, IL</publisher-loc>:
<publisher-name>University of Chicago Press</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c25" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Vaughan</surname>,
<given-names>D.</given-names></string-name></person-group> (<year>1999</year>).
<article-title>The dark side of organizations: Mistake, misconduct, and
disaster</article-title>. <source>Annual Review of Sociology</source>,
<volume>25</volume>,
<fpage>271</fpage>&#8211;<lpage>305</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c26" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Vaughan</surname>,
<given-names>D.</given-names></string-name></person-group> (<year>2005</year>).
<chapter-title>System effects: On slippery slopes, repeating negative patterns,
and learning from mistakes?</chapter-title> In
<person-group person-group-type="editor"><string-name><given-names>W.</given-names>
<surname>Starbuck</surname></string-name> &amp;
<string-name><given-names>F.</given-names>
<surname>Moshe</surname></string-name></person-group> (<role>Eds.</role>),
<source>Organizations at the limit: Lessons from the Columbia disaster</source>
(pp. <fpage>41</fpage>&#8211;<lpage>59</lpage>).
<publisher-loc>Oxford, UK</publisher-loc>:
<publisher-name>Blackwell</publisher-name>.</mixed-citation>
</ref>
</ref-list>
<app-group>
<app id="A" copyright="inherit"><title>Error Management Worksheet</title>
<sec id="s46">
<p align="left"><xref ref-type="table-anchor" rid="tbl6"/></p>
</sec></app>
<app id="B" copyright="inherit"><title>Threat Management Worksheet</title>
<sec id="s47">
<p align="left"><xref ref-type="table-anchor" rid="tbl7"/></p>
</sec></app></app-group>
</back><floats-group>
<table-wrap id="tbl1" position="float" orientation="portrait" pagewide="no">
<label>1</label>
<caption><title>Threat and Error Countermeasures</title></caption>
<graphic copyright="inherit" id="tbl1a" xlink:href="apf_2_2_49_tbl1a.tif" xlink:type="simple"/>
<search-text>
Observed performance ratings
1. Poor: Had safety implications
2. Marginal: Adequate but needs improvement
3. Good: Effective
4. Outstanding: Truly noteworthy
Note. SOP = standard operating procedure. Reprinted with
permission from Line operations safety audit (LOSA): A cockpit
methodology for monitoring commercial airline safety
performance (Dissertation), by J. R. Klinect. Austin, TX:
University of Texas. Copyright 2005 by The LOSA Collaborative.
Planning performance markers
SOP briefing
Required briefings interactive and operationally thorough
Concise, not rushed, clear boundaries established
Plans stated
Operational plans and decisions communicated and
acknowledged
Shared understanding about plans
Contingency management
Pilot anticipated, developed, and communicated strategies to
manage safety risks
Used all available resources to manage threats, errors, and
undesired aircraft states
Execution performance markers
Monitor/cross-check
Pilot actively monitored and cross-checked: position, systems,
and other crew members
Aircraft position, settings, and crew actions verified; pilot
maintained situation awareness
Workload management
Operational tasks prioritized and properly managed to handle
primary flight duties
Avoided task fixation and did not allow work overload
Automation management
Automation properly managed to balance
situational/workload requirements
Automation setup briefed to other members
Taxiway/runway management
Pilot used caution and kept watch outside when navigating
taxiways and runways
Clearances verbalized and charts used
Review/modify performance markers
Evaluation of plans
Existing plans reviewed and modified when necessary
Crew decisions and actions openly analyzed
Inquiry
Crew members not afraid to ask questions to
investigate/clarify current plans of action when necessary
Crew members spoke up without hesitation
Team climate performance markers (overall performance
only)
Communication environment
Environment for open communication established and
maintained
Good cross talk &#8211; flow of information fluid, clear,
direct
Leadership
Captain showed leadership and verbally coordinated flight deck
activities
In command, decisive, encouraged crew participation
Overall crew performance
Overall crew performance as risk managers
</search-text></table-wrap>
<table-wrap id="tbl2" position="float" orientation="portrait" pagewide="no">
<label>2</label>
<caption><title>Number of threats observed by category and whether these were managed</title></caption>
<graphic copyright="inherit" id="tbl2a" xlink:href="apf_2_2_49_tbl2a.tif" xlink:type="simple"/>
<search-text>
Threat
Managed
Mismanaged
N
Air traffic control
16
1
17
Airport conditions
8
0
8
Weather
3
3
6
Airline operational pressures
5
0
5
Environmental operational pressures
4
0
4
Aircraft automation features
0
2
2
Cabin
0
1
1
Others
3
0
3
Total
39
7
46
</search-text></table-wrap>
<table-wrap id="tbl3" position="float" orientation="portrait" pagewide="no">
<label>3</label>
<caption><title>Error types: Numbers managed and mismanaged</title></caption>
<graphic copyright="inherit" id="tbl3a" xlink:href="apf_2_2_49_tbl3a.tif" xlink:type="simple"/>
<search-text>
Error type
Managed
Mismanaged
N
Intentional noncompliance
3
19
22
Aircraft handling
0
1
1
Procedural
9
9
18
Communication
0
1
1
Total
12
30
42
</search-text></table-wrap>
<table-wrap id="tbl4" position="float" orientation="portrait" pagewide="no">
<label>4</label>
<caption><title>Number of managed and mismanaged Undesired Aircraft States (UASs)</title></caption>
<graphic copyright="inherit" id="tbl4a" xlink:href="apf_2_2_49_tbl4a.tif" xlink:type="simple"/>
<search-text>
UAS description
Managed
Mismanaged
N
Configuration states
2
1
3
Ground states
1
0
1
Aircraft handling states
1
0
1
Approach/landing states
0
1
1
Total
4
2
6
</search-text></table-wrap>
<table-wrap id="tbl5" position="float" orientation="portrait" pagewide="no">
<label>5</label>
<caption><title>Countermeasures: Lowest and highest scoring markers</title></caption>
<graphic copyright="inherit" id="tbl5a" xlink:href="apf_2_2_49_tbl5a.tif" xlink:type="simple"/>
<search-text>
Average rating
Average rating excluding two &#8220;perfect&#8221; flights*
Note. SOPs = standard operating procedures.
*The observer gave ratings of &#8220;4 &#8211; outstanding&#8221;
for much of the pilot&#8217;s performance during two flights, which were
judged as almost &#8220;perfect.&#8221; The small number of flights
observed (14) meant that these ratings affected the data for some markings,
so the final column shows the figures excluding the ratings for these two
flights.
Highest scoring markers
&#8195;Workload
4.0
4.0
&#8195;Evaluation of plans
3.6
3.5
&#8195;SOPs
3.6
3.5
&#8195;Communication
3.5
3.5
Lowest scoring markers
&#8195;Taxi
3.8
1.6
&#8195;Monitor/cross-check
3.3
2.7
&#8195;Contingency planning
3.3
2.9
&#8195;Automation
3.5
3.0
</search-text></table-wrap>
<table-wrap id="tbl6" position="anchor" orientation="portrait" pagewide="no">
<graphic copyright="inherit" id="tbl6a" xlink:href="apf_2_2_49_tbl6a.tif" xlink:type="simple"/>
<search-text>
Error description
Error response/Outcome
Note. ATC = air traffic control; UAS = undesired aircraft
state. With acknowledgment to the LOSA Collaborative.
Error ID
Describe the error and any associated undesired aircraft states
Phase of Flight
Pre-depart/Taxi
Takeoff/Climb
Cruise
Descend/Approach/Landing
Taxi-in
Was the error proficiency based?(Yes or No)
Error Type
Intentional
Noncompliance
Aircraft
Handling
Procedural
Communication
Error Code &amp; altitude error occurred
Who committed the error?
Who detected the error?
Error Response
Detected &amp;
action
Detected and
ignored
Undetected
Error Outcome
Inconsequential
Undesired
state
Additional
error
E1
&#8211;&#8211;&#8211;&#8211;
Error management
Undesired aircraft states
Error ID
Associated with a threat?(If Yes, enter threat ID &#8211;
e.g., T2)
How did the pilot manage or mismanage the
error? (Describe the response to the error and the
outcome) Also describe the response to any associated UAS and the
outcome
Was there an undesired aircraft state (Y/N)
UAS code and altitude UAS occurred
Who detected the UAS?
UAS response
Detected &amp;
action
Detected &amp;
ignored
Undetected
UAS outcome
Inconsequential
Additional
error
E1
&#8211;&#8211;&#8211;&#8211;
Who Committed/Detected Codes
Flight crew
Other people
Aircraft
1 Pilot
5 Nobody
8 ATC
10 Ground crew
20 Aircraft systems
3 Other crew member
6 Observer (only complete if observer had to intervene for safety)
9 Dispatch
11 Maintenance
Other
4 All crew members
99 Detected by any other means
</search-text></table-wrap>
<table-wrap id="tbl7" position="anchor" orientation="portrait" pagewide="no">
<graphic copyright="inherit" id="tbl7a" xlink:href="apf_2_2_49_tbl7a.tif" xlink:type="simple"/>
<search-text>
Threats &#8211; Events or errors that originate outside
the influence of the pilot but require active management to maintain
safety
Threat ID
Threat description
Threat management
Describe the threat
Threat code &amp; altitude that threat occurred
Phase of flight
Pre-depart/Taxi
Takeoff/Climb
Cruise
Descend/Approach/Landing
Taxi-in
Effectively managed?(Yes / No)
How did the pilot manage or mismanage the
threat?(Describe the response to the threat and the
outcome)
T1
T2
T3
T4
T5
T6
</search-text></table-wrap>
<fig id="fig1">
<label>1</label>
<caption>
<p align="left">The threat and error management model (TEM). Adapted from &#8220;Line operations
safety audit (LOSA): Definition and operating characteristics,&#8221; by J. R. Klinect,
P. S. Murray, &amp; R. Helmreich, 2003, In <italic>Proceedings of the
12</italic><sup location="post"><italic>th</italic></sup>
<italic>International Symposium on Aviation Psychology</italic> (pp. 663&#8211;668).
Dayton, OH: Ohio State University. Reproduced courtesy of the LOSA Collaborative.
Copyright 2003 LOSA Collaborative.</p>
</caption>
<graphic copyright="inherit" id="fig1a" xlink:href="apf_2_2_49_fig1a.tif" xlink:type="simple"/>
</fig>
<fig id="fig2">
<label>2</label>
<caption>
<p align="left">Threats and errors by phase of flight. App = approach; Des = descent; Pre-dep =
predeparture.</p>
</caption>
<graphic copyright="inherit" id="fig2a" xlink:href="apf_2_2_49_fig2a.tif" xlink:type="simple"/>
</fig>
<fig id="fig3">
<label>3</label>
<caption>
<p align="left">Procedural errors of verbalizing and nonverbalizing pilots.</p>
</caption>
<graphic copyright="inherit" id="fig3a" xlink:href="apf_2_2_49_fig3a.tif" xlink:type="simple"/>
</fig></floats-group>
</article>