<?xml version='1.0' encoding='US-ASCII'?>
<!DOCTYPE article PUBLIC "-//APA//DTD APA Journal Archive DTD v1.0 20130715//EN" "http://xml.apa.org/serials/jats-dtds-1.0/APAjournal-archive.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" xml:lang="en" structure-type="article" dtd-version="1.0">
<front>
<journal-meta>
<journal-title-group>
<journal-title xml:lang="en">Psychology of Aesthetics, Creativity, and the Arts</journal-title></journal-title-group>
<issn pub-type="print">1931-3896</issn>
<issn pub-type="online">1931-390X</issn>
<publisher>
<publisher-name>American Psychological Association</publisher-name></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="apaID">aca_7_4_341</article-id>
<article-id pub-id-type="doi">10.1037/a0033644</article-id>
<article-id pub-id-type="pi-uid">2013-34485-001</article-id>
<article-categories>
<subj-group subj-group-type="toc-heading">
<subject>Articles</subject>
</subj-group>
</article-categories>
<title-group><article-title>Assessment of Divergent Thinking by Means of the Subjective Top-Scoring Method: Effects of the Number of Top-Ideas and Time-on-Task on Reliability and Validity</article-title>
</title-group><contrib-group content-type="journal-editors"><contrib contrib-type="editor" corresp="no" xlink:type="simple"><string-name><given-names>Roni</given-names> <surname>Reiter-Palmon</surname></string-name> <role>Co-Editor</role></contrib><contrib contrib-type="editor" corresp="no" xlink:type="simple"><string-name><given-names>Pablo</given-names> <surname>Tinio</surname></string-name> <role>Co-Editor</role></contrib></contrib-group>
<contrib-group content-type="primary-authors">
<contrib rid="aff1 corr1" contrib-type="author" corresp="yes" xlink:type="simple">
<string-name>
<given-names>Mathias</given-names> <surname>Benedek</surname></string-name>
</contrib>
<contrib rid="aff1" contrib-type="author" corresp="no" xlink:type="simple">
<string-name>
<given-names>Caterina</given-names> <surname>M&#252;hlmann</surname></string-name>
</contrib>
<contrib rid="aff1" contrib-type="author" corresp="no" xlink:type="simple">
<string-name>
<given-names>Emanuel</given-names> <surname>Jauk</surname></string-name>
</contrib>
<contrib rid="aff1" contrib-type="author" corresp="no" xlink:type="simple">
<string-name>
<given-names>Aljoscha C.</given-names> <surname>Neubauer</surname></string-name>
</contrib>
<aff id="aff1">Department of Psychology, University of Graz, Graz, Austria</aff>
</contrib-group>
<author-notes>
<p align="left">This research was supported by a grant from the Austrian Science Fund (FWF): P23914.</p>
<corresp id="corr1">
<addr-line>Mathias Benedek, Department of Psychology, University of Graz, Maiffredygasse 12b, 8010 Graz, Austria</addr-line> <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" specific-use="live" xlink:href="mailto:mathias.benedek@uni-graz.at" ext-link-type="email" xlink:type="simple">mathias.benedek@uni-graz.at</ext-link></corresp>
</author-notes>
<pub-date pub-type="online"><string-date><month number="9">September</month> <day>30</day>, <year>2013</year></string-date></pub-date>
<pub-date pub-type="print"><string-date><month number="11">November</month> <year>2013</year></string-date></pub-date>
<volume>7</volume>
<issue>4</issue>
<fpage>341</fpage>
<lpage>349</lpage>
<history>
<string-date content-type="received"><month number="10">October</month> <day>22</day>, <year>2012</year></string-date>
<string-date content-type="revised"><month number="1">January</month> <day>28</day>, <year>2013</year></string-date>
<string-date content-type="accepted"><month number="3">March</month> <day>4</day>, <year>2013</year></string-date>
</history>
<permissions copyright-status="active">
<copyright-statement>&#169; 2013 American Psychological Association</copyright-statement>
<copyright-year>2013</copyright-year>
<copyright-holder>American Psychological Association</copyright-holder>
</permissions>
<abstract xml:lang="en">
<p align="left">Divergent thinking tasks are commonly used as indicators of creative potential, but traditional scoring methods of ideational originality face persistent problems such as low reliability and lack of convergent and discriminant validity. <xref ref-type="bibr" id="cr34-1" rid="c34">Silvia et al. (2008)</xref> have proposed a subjective top-2 scoring method, where participants are asked to select their two most creative ideas, which then are evaluated for creativity. This method was found to avoid problems with discriminant validity, and to outperform other scoring methods in terms of convergent validity. These findings motivate a more general, systematic analysis of the subjective top-scoring method. Therefore, this study examined how reliability and validity of the originality and fluency scores depend on the number of top-ideas and on time-on-task. The findings confirm that subjective top-scoring avoids the confounding of originality with fluency. The originality score showed good internal consistency, and evidence of reliability was found to increase as a function of the number of top-ideas and of time-on-task. Convergent validity evidence, however, was highest for a time-on-task of about 2 to 3 minutes and when using a medium number of about three top-ideas. Reasons for these findings are discussed together with possible limitations of this study and future directions. The article also presents some general recommendations for the assessment of divergent thinking with the subjective top-scoring method.</p>
</abstract>
<kwd-group xml:lang="en">
<kwd>originality</kwd>
<kwd>fluency</kwd>
<kwd>time-on-task</kwd>
<kwd>reliability</kwd>
<kwd>validity</kwd>
</kwd-group>
</article-meta></front>
<body>
<sec id="s1">
<p align="left">Divergent thinking tests have had long-standing popularity in creativity research but also have faced persistent debates about their limitations. A common issue is that divergent thinking ability may be considered a useful indicator of creative potential, but it may not generalize to a more general conceptualization of creativity which for example, also includes real-life creative achievement (<xref ref-type="bibr" id="cr26-1" rid="c26">Runco &amp; Acar, 2012</xref>). A second common issue is related to the unsatisfactory psychometric properties (i.e., objectivity, reliability, and validity) of divergent thinking scores. These psychometric issues need to be resolved to establish confidence in the use of divergent thinking tasks for the assessment of creative potential and for the study of the cognitive and neurocognitive mechanisms underlying creative ideation (e.g., <xref ref-type="bibr" id="cr5-1" rid="c5">Benedek, K&#246;nen &amp; Neubauer, 2012</xref>; <xref ref-type="bibr" id="cr9-1" rid="c9">Fink &amp; Benedek, in press</xref>; <xref ref-type="bibr" id="cr39-1" rid="c39">Gilhooly et al., 2007</xref>; <xref ref-type="bibr" id="cr20-1" rid="c20">Nusbaum &amp; Silvia, 2011</xref>). In the past few years, strong efforts have been made to further examine divergent thinking tests in the light of different methodological considerations and to propose new solutions to common issues (e.g., <xref ref-type="bibr" id="cr22-1" rid="c22">Plucker, Qian &amp; Wang, 2011</xref>; <xref ref-type="bibr" id="cr29-1" rid="c29">Runco, Okuda &amp; Thurston, 1987</xref>; <xref ref-type="bibr" id="cr33-1" rid="c33">Silvia, Martin &amp; Nusbaum, 2009</xref>; <xref ref-type="bibr" id="cr34-2" rid="c34">Silvia et al., 2008</xref>). This study aims to extend these developments by a systematic examination of the psychometric properties of subjective scoring methods.</p>
<p align="left">Divergent thinking tasks require participants to generate creative solutions to given open problems. A large number of different divergent thinking tasks have been devised (e.g., the alternate uses tasks ask to find creative uses for a commodity item such as a brick; cf., <xref ref-type="bibr" id="cr3-1" rid="c3">Benedek, Fink &amp; Neubauer, 2006</xref>), and a variety of different measures have been proposed for scoring responses generated in these tasks (e.g., <xref ref-type="bibr" id="cr37-1" rid="c37">Torrance, 2008</xref>). These measures commonly involve a scoring of the fluency and originality (or creativity) of ideas, which can be considered to reflect the quantity and quality of ideation performance. The scoring of ideational fluency is straightforward as it essentially requires counting the number of relevant responses. In contrast, the scoring of originality is more complex and can be achieved by different methods. In the uniqueness scoring, the originality of responses is defined by their statistical infrequency. For example, infrequent responses (<italic>p</italic> &lt; 5&#8211;10%) are usually defined as unusual or unique, whereas more frequent responses are considered to be common (e.g., <xref ref-type="bibr" id="cr25-1" rid="c25">Runco, 2008</xref>; <xref ref-type="bibr" id="cr36-1" rid="c36">Torrance, 1974</xref>). The originality score then is obtained by counting the number of unique responses. Although this method appears to allow for an objective scoring, a number of serious objections have been raised including the issue that statistical infrequency may not be a valid indicator of creativity because it does not account for the appropriateness of responses (<xref ref-type="bibr" id="cr34-3" rid="c34">Silvia et al., 2008</xref>). As an alternative, in the subjective scoring method, external judges are used to evaluate all responses for creativity (i.e., unusualness and appropriateness; cf., <xref ref-type="bibr" id="cr1-1" rid="c1">Amabile, 1982</xref>) and ratings are finally summed. Good interrater reliability of this method can be seen as an argument for a certain objectivity of this method, but the evaluation of large amounts of responses by different judges is still very laborious.</p>
<p align="left">The uniqueness scoring and the subjective scoring method, however, also face a more general methodological issue. Ideational fluency has been realized to act as a contaminating factor for all other scores (<xref ref-type="bibr" id="cr11-1" rid="c11">Hocevar, 1979a</xref>, <xref ref-type="bibr" id="cr12-1" rid="c12">1979b</xref>; <xref ref-type="bibr" id="cr14-1" rid="c14">Kaufman, Plucker &amp; Baer, 2008</xref>; <xref ref-type="bibr" id="cr18-1" rid="c18">Michael &amp; Wright, 1989</xref>; <xref ref-type="bibr" id="cr29-2" rid="c29">Runco et al., 1987</xref>). According to the scoring techniques outlined above, the scoring of originality is directly related to the number of responses (i.e., fluency score). A person who gives more responses thus is more likely to get points for originality. This explains for the extremely high correlations of fluency with originality scores, which often range from <italic>r</italic> = .80 to .90 (e.g., <xref ref-type="bibr" id="cr19-1" rid="c19">Mouchiroud &amp; Lubart, 2001</xref>; <xref ref-type="bibr" id="cr37-2" rid="c37">Torrance, 2008</xref>). It has been argued that these marked correlations do not support discriminant validity (<xref ref-type="bibr" id="cr22-2" rid="c22">Plucker et al., 2011</xref>; <xref ref-type="bibr" id="cr34-4" rid="c34">Silvia et al., 2008</xref>). Moreover, after the effect of fluency is partialed out, the reliability evidence of the originality score is usually very low (<xref ref-type="bibr" id="cr11-2" rid="c11">Hocevar, 1979a</xref>, <xref ref-type="bibr" id="cr12-2" rid="c12">1979b</xref>; <xref ref-type="bibr" id="cr29-3" rid="c29">Runco et al., 1987</xref>); one study found that reliability is still adequate for gifted children performing figural tasks (<xref ref-type="bibr" id="cr27-1" rid="c27">Runco &amp; Albert, 1985</xref>). The reliability and validity of originality scores hence appear to be substantially affected by the correlation with ideational fluency.</p>
<p align="left">Because ideational originality is conceived as an essential qualitative factor of divergent thinking ability, a number of suggestions were made on how to control for the confounding influence of ideational fluency. One suggestion is that the evaluations should be based on the entire set of ideas rather than single ideas (i.e., scoring of ideational pools, or snapshot scoring; <xref ref-type="bibr" id="cr28-1" rid="c28">Runco &amp; Mraz, 1992</xref>; <xref ref-type="bibr" id="cr33-2" rid="c33">Silvia et al., 2009</xref>). This method allows for a very quick overall assessment but was found to yield only moderate evidence of reliability. It was also proposed to divide total originality by the number of ideas (i.e., average scoring, or ratio scoring). This method has some merits (e.g., <xref ref-type="bibr" id="cr22-3" rid="c22">Plucker et al., 2011</xref>; <xref ref-type="bibr" id="cr34-5" rid="c34">Silvia et al., 2008</xref>), but again it sometimes was found to show very low reliability evidence (<xref ref-type="bibr" id="cr29-4" rid="c29">Runco, Okudo &amp; Thurston, 1987</xref>), and it should be noted that average originality might not be valid for the ability to come up with the most creative ideas. Another possibility is to focus on a constant number of responses (<xref ref-type="bibr" id="cr8-1" rid="c8">Clark &amp; Mirels, 1970</xref>). The examinees can, for example, be instructed to produce a predefined number of responses (e.g., generate three creative responses; <xref ref-type="bibr" id="cr12-3" rid="c12">Hocevar, 1979b</xref>). This method controls for fluency, but no longer allows for the implicit assessment of fluency. As an alternative, the scoring can be restricted to a predefined number of responses from the entire response set (<xref ref-type="bibr" id="cr18-2" rid="c18">Michael &amp; Wright, 1989</xref>). This method can be called <italic>subjective top-scoring</italic>. Recently, <xref ref-type="bibr" id="cr34-6" rid="c34">Silvia et al. (2008)</xref> have adopted this approach by proposing the top-2 scoring method. This method asks the examinees to indicate their two most creative responses per task, and only these two responses then are evaluated. The top-2 scoring of originality was shown to avoid excessive correlations with fluency and to perform better than the snapshot scoring or average scoring (<xref ref-type="bibr" id="cr32-1" rid="c32">Silvia, 2011</xref>; <xref ref-type="bibr" id="cr34-7" rid="c34">Silvia et al., 2008</xref>, <xref ref-type="bibr" id="cr33-3" rid="c33">2009</xref>). Similarly, <xref ref-type="bibr" id="cr23-1" rid="c23">Reiter-Palmon, Illies, Cross, Buboltz and Nimps (2009)</xref>, using more complex, real-life divergent thinking tasks, found that using the single most creative response (i.e., top-1 scoring) is suitable to overcome a confounding with fluency.</p>
<p align="left">Evaluating people by their best responses reflects a maximum performance condition (<xref ref-type="bibr" id="cr24-1" rid="c24">Runco, 1986</xref>) and acknowledges that the ability to select one&#8217;s best ideas is important for creativity (<xref ref-type="bibr" id="cr35-1" rid="c35">Smith, Ward &amp; Finke, 1995</xref>). This may involve that generative and evaluative processes become confounded (<xref ref-type="bibr" id="cr25-2" rid="c25">Runco, 2008</xref>), but examinees were found to be quite discerning in selecting their most creative ideas which supports the validity of this procedure (<xref ref-type="bibr" id="cr31-1" rid="c31">Silvia, 2008</xref>). Finally, from a practical point of view, this method also enhances the efficiency of the rating procedure. <xref ref-type="bibr" id="cr34-8" rid="c34">Silvia et al. (2008)</xref> reported that by using top-2 scoring only about 28% of the total number of ideas had to be evaluated.</p>
<p align="left">Recently, <xref ref-type="bibr" id="cr22-4" rid="c22">Plucker et al. (2011)</xref> have compared different methods of originality scoring with respect to reliability and validity. The methods included uniqueness scoring, average uniqueness (i.e., dividing uniqueness by fluency), uniqueness of the first or last 10 ideas, and subjective, rater-based scorings of the entire response set (summative score) or the first or last 10 ideas. Using only two items of the instances task, reliabilities ranged between .37 and .62. The average uniqueness score was found to show somewhat higher correlations with self-report creativity measures and negative correlations with fluency. It was concluded that this method could be favored over subjective rater-based methods. However, because in this study participants were not asked to select their most creative ideas, the authors suggested that examining the reliability and validity of top-ideas &#8220;is also promising and should be the subject of additional study&#8221; (p. 15).</p>
</sec>
<sec id="s2">
<title>Main Research Questions</title>
<p align="left">The main idea underlying subjective top-scoring of originality is to focus on a constant number of top-ideas to avoid a confounding with fluency which questions its discriminant validity. The top-2 scoring method, which focuses on the two most creative ideas, was found to perform well in terms of reliability and validity as compared to other scoring methods such as uniqueness scoring (<xref ref-type="bibr" id="cr34-9" rid="c34">Silvia et al., 2008</xref>). In recent investigations, we have also used a subjective scoring of divergent thinking tasks and found that correlations with intelligence crucially depended on the scoring method (i.e., top-2 vs. average originality; <xref ref-type="bibr" id="cr13-1" rid="c13">Jauk, Benedek &amp; Neubauer, 2013</xref>). Moreover, we observed that top-3 scoring resulted in a somewhat higher reliability evidence of the originality score as compared to top-1 or top-2 scoring (<xref ref-type="bibr" id="cr4-1" rid="c4">Benedek, Franz, Heene &amp; Neubauer, 2012</xref>). This raises the question to what extent the number of top-ideas actually affects reliability and maybe also the validity of the originality score. Moreover, because the number and originality of ideas depend on time-on-task (e.g., <xref ref-type="bibr" id="cr2-1" rid="c2">Beaty &amp; Silvia, 2012</xref>; <xref ref-type="bibr" id="cr17-1" rid="c17">Mednick, 1962</xref>), the most adequate number of top-ideas might also depend on the duration of divergent thinking tasks. Therefore, this study aims to have a close look on different realizations of the subjective top-scoring method and their effects on the psychometric properties of originality scores. Specifically, we want to examine systematically to what extent (a) the actual number of top-ideas and (b) the time-on-task affect (1) the correlation of originality scores with fluency, (2) the reliability of originality scores, and (3) the convergent validity of originality scores. Additionally, we also examine the effect of task duration on the reliability and validity of fluency scores. We thereby hope to reveal further information about the adequate assessment of ideational originality, ensuring high psychometric quality but also efficient scoring procedures.</p>
</sec>
<sec id="s3">
<title>Method</title>
<sec id="s4" disp-level="subsect1">
<title>Participants</title>
<p align="left">A sample of 105 participants (51 females) took part in this study. The age ranged from 18 to 51 years (<italic>M</italic> = 23.80, <italic>SD</italic> = 3.97). Forty-nine percent of participants were students of Psychology at the University of Graz, 38% were majoring in different fields, and the remaining 13% were nonstudents. Participants were invited to take part in a study on creativity and personality and were offered credits for participation in empirical investigations (if applicable) and an individual feedback on personality structure in exchange for participation. The only requirement for participation was basic computer literacy. All participants gave written informed consent. The study was approved by the local ethics committee.</p>
</sec>
<sec id="s5" disp-level="subsect1">
<title>Tasks and Material</title>
<p align="left">We used six divergent thinking tasks timed for five minutes each. The tasks included three alternate uses tasks (&#8220;car tire,&#8221; &#8220;glass bottle,&#8221; and &#8220;knife&#8221;) and three instances tasks (&#8220;what could be round?&#8221;, &#8220;what could make a loud noise?&#8221;, &#8220;what could be used for faster locomotion?&#8221;). Tasks were administered by a self-devised computer program written in Matlab (The Mathworks; Natick, MA), which allows for acquisition of time-stamped responses. There is evidence that computer-based assessment of divergent thinking is highly comparable to a paper-pencil assessment (<xref ref-type="bibr" id="cr16-1" rid="c16">Lau &amp; Cheung, 2010</xref>).</p>
<p align="left">In an initial general instruction participants were told that they will be presented some questions for which they should try to &#8220;generate as many different unusual and creative responses as possible.&#8221; They were asked to express their ideas as succinctly as possible, and to write each idea into the input box and then press the enter-key to add it to their idea list. Participants were told that there was &#8220;some minutes&#8221; time for each task and that the program would proceed automatically as soon as time is over. By giving participants no exact information about the total or remaining task duration, we hoped that they would keep on entering every idea as soon as it comes to mind, but not to develop specific task strategies related to a five minutes task time. After a task was started, participants were presented the specific task instructions on top of the screen (e.g., &#8220;What could make a loud noise? Name all the unusual and creative responses that you can think of.&#8221;). Below, there was an editable input box where ideas could be entered. Every idea was added to a list placed below the input box. Two time events were recorded for each idea: (1) the time when the participant started entering the idea, and (2) the time when writing was complete and the idea was added to the list. We only considered the former time event, because this can be considered as the time when the idea actually came to mind, whereas the latter time event depends on the length of the idea and the typing speed.</p>
<p align="left">After all tasks were completed, ideas were ranked for creativity by the participants. To this end, participants were presented with lists showing all their ideas within a single task with the ideas being arranged in randomized order. They were asked to rearrange the position of the ideas until the sequence of ideas in the list reflected the creativity of ideas as subjectively appraised by the participants. Ideas were rearranged by selecting them and moving them up or down by means of specific buttons. At the end, the topmost idea in the final list should be the most creative one, the second idea in the list should be the second-most creative one, and the last idea in the list should be the least creative one. This was done for all six tasks, separately.</p>
<p align="left">We also measured self-reported ideational behavior by means of a German version of the Runco Ideational Behavior Scale (RIBS; Runco, Plucker &amp; Lim, 2000). Personality structure was assessed by means of the five-factor inventory NEO-FFI (<xref ref-type="bibr" id="cr7-1" rid="c7">Borkenau &amp; Ostendorf, 1993</xref>).</p>
</sec>
<sec id="s6" disp-level="subsect1">
<title>Scoring of Divergent Thinking Tasks</title>
<p align="left">The ideas generated in the divergent thinking tasks were scored for fluency and originality. Fluency scores simply reflect the number of ideas generated after a given time. Originality scores were computed according to the subjective top-scoring method using the creativity evaluations obtained by external judges.</p>
<sec id="s7" disp-level="subsect2">
<title>External originality ratings</title>
<p align="left">Participants generated a total of 10,921 ideas in the six divergent thinking tasks. All ideas were pooled and identical ideas were removed, resulting in a final set of nonredundant 6229 ideas. Eight external raters were asked to evaluate the creativity of the ideas on a scale ranging from 0 (<italic>not creative</italic>) to 3 (<italic>very creative</italic>). All raters received an initial training, which made them familiar with the scale (e.g., they were informed that ideas can be considered &#8220;highly creative&#8221; when they are perceived as original and useful, and probably only few people will come up with them). The judges evaluated a small subset of ideas and after that discussed their ratings. Because of the large amount of ideas, each judge then evaluated the ideas of only half of the tasks so that finally there were four independent ratings for each idea. The interrater reliability between the four judges was ICC = .68, .80, .65, .60, .51, and .68 for the tasks &#8220;car tire,&#8221; &#8216;glass bottle,&#8221; &#8216;knife,&#8221; &#8220;round,&#8221; &#8220;loud noise,&#8221; and &#8220;faster locomotion,&#8221; respectively. The creativity of a single idea was defined as the average creativity rating given by the four external judges.</p>
</sec>
<sec id="s8" disp-level="subsect2">
<title>Subjective top-scoring</title>
<p align="left">The main idea of the top-scoring method is that the originality score is based on the creativity evaluations of a predefined number of top-ideas. The top-ideas are identified by the participants themselves according to their subjective appraisal of the creativity of their ideas. For example, <xref ref-type="bibr" id="cr34-10" rid="c34">Silvia et al. (2008)</xref> used a top-2 scoring, where participants marked their two most creative ideas which then were considered for scoring. Generally, all kinds of top-scores can be computed. For example, for a top-1 score only the single most creative idea within a task would be considered, whereas for a top-3 score the three most creative ideas would be included.</p>
<p align="left">A first specific aim of this study was to examine the effect of the number of <italic>top-ideas</italic>. This was made possible by having participants sort all their ideas for creativity, as that allows for a post hoc classification of any number of top-ideas. Second, we aimed to also consider the effect of <italic>time-on-task</italic>. In this study, time-on-task can theoretically vary from zero to five minutes (i.e., the total time for each task). For a specific time-on-task lower than five minutes, for example, 3 minutes, the scores were computed based on the data available after 3 minutes. To illustrate this method, let us consider the following example: Assume that a participant generated four ideas at 30, 60, 120 and 240 seconds, and afterward ranked them 2., 4., 3., 1. (i.e., the first idea being second-most creative, the second idea being least creative, and so on). Then, for computing the <italic>top-2</italic> originality score for a <italic>time-on-task</italic> of 3 minutes, only the two most creative ideas within the first 3 minutes are considered, hence, the first and the third idea. The originality score was finally computed by averaging the creativity evaluations of the considered top-ideas. If a participant generated fewer ideas than the number of top-ideas then the creativity evaluations of the available ideas were averaged.</p>
</sec>
</sec>
<sec id="s9" disp-level="subsect1">
<title>Procedure</title>
<p align="left">Participants were tested in small groups of up to five people in a computer room. They first performed the six divergent thinking tasks, which were presented in a randomized order. The divergent thinking tasks were preceded by a short exercise (enter words starting with the letter &#8220;F&#8221;) to become familiar with the general procedure of a computer-based idea generation task. After completion of the six tasks, the participants ranked their ideas for creativity. Finally, the participants completed the personality inventory, and the ideational behavior scale. The whole session took about one hour.</p>
</sec>
<sec id="s10" disp-level="subsect1">
<title>Analysis Plan</title>
<p align="left">The main analyses include correlation analysis of fluency and originality scores, reliability analyses (i.e., internal consistency of scores), and validity analyses (i.e., correlations with external criteria). In all of these analyses two experimental factors are varied systematically: First, the factor <italic>top-ideas</italic> is varied from 1 to 10 ideas (see section on top-scoring method for further details). Additionally, this factor also includes the value &#8220;all ideas,&#8221; where all ideas given by a participant were considered; this hence corresponds to an average originality score (cf., <xref ref-type="bibr" id="cr34-11" rid="c34">Silvia et al., 2008</xref>). This factor only applies for the originality score but not for the fluency score. Second, the factor <italic>time-on-task</italic> is varied from 1 to 5 minutes (i.e., scores are computed for time-on-task of 1, 2, 3, 4, and 5 minutes). In total, the scoring hence was computed for 55 different conditions (11 top-idea conditions by 5 time-on-task conditions). The results of these analyses are visualized by means of contour plots (see <xref ref-type="fig" id="fgc1-1" rid="fig1">Figures 1</xref>, <xref ref-type="fig" id="fgc2-1" rid="fig2">2</xref>, and <xref ref-type="fig" id="fgc3-1" rid="fig3">3</xref>).<xref ref-type="fig-anchor" rid="fig1"/><xref ref-type="fig-anchor" rid="fig2"/><xref ref-type="fig-anchor" rid="fig3"/></p>
</sec>
</sec>
<sec id="s11">
<title>Results</title>
<sec id="s12" disp-level="subsect1">
<title>Descriptive Statistics and Preliminary Analyses</title>
<p align="left">Participants generated on average 17 ideas (<italic>SD</italic> = 6.36) within the task time of 5 minutes. The fluency of ideas was significantly higher in the three instances tasks (<italic>M</italic> = 21.95, <italic>SD</italic> = 8.61) than in the three alternate uses tasks (<italic>M</italic> = 12.72, <italic>SD</italic> = 4.96), <italic>t</italic>(104) = 15.83, <italic>p</italic> &lt; .01. As can be seen in <xref ref-type="table" id="tbc1-1" rid="tbl1">Table 1</xref>, the total number of ideas steadily increases over time, however the fluency of ideas also steadily declines over time starting from the first minute. Considering the alternate uses tasks, half of participants had created four ideas or more within the first minute of the task but the increase flattened down to one additional idea in the last minute of the task (difference between median values after 4 and 5 minutes; see <xref ref-type="table" id="tbc1-2" rid="tbl1">Table 1</xref>). It can also be seen that there are large individual differences in fluency scores. Whereas the least fluent 10% of participants generated only nine ideas or less after working on the instances task for five minutes, the most productive 10% of the sample generated more than three times as many ideas (i.e., 32.7).<xref ref-type="table-anchor" rid="tbl1"/></p>
<p align="left">A principal factor analysis with Varimax rotation and Kaiser normalization was performed for the six fluency scores and the six average originality scores derived from the alternate uses as well as the instances tasks. The analysis extracted two factors (according to the Kaiser criterion and according to the Scree test; K-M-O = .83), explaining 67% of total variance. Further evidence for a two-factorial solution comes from the minimum average partial test (MAP test: <xref ref-type="bibr" id="cr38-1" rid="c38">Velicer, Eaton, &amp; Fava, 2000</xref>), which returned two components as the number of factors to extract from the 12 measures. This two-factor solution clearly revealed a fluency factor and an originality factor with all six fluency and originality scores loading on corresponding factors (unspecific loadings were below .25). In other words, we obtained evidence for score-specific factors rather than task-specific factors, which supports the feasibility of aggregating fluency and originality scores across tasks.</p>
</sec>
<sec id="s13" disp-level="subsect1">
<title>How Do Scoring Conditions Affect the Correlation of Fluency and Originality?</title>
<p align="left">We computed correlations between originality and fluency scores for different numbers of top-responses at varying time-on-task. It was assumed that the subjective top-scoring method can avoid excessively high correlations between originality and fluency because it focuses on a constant number of ideas. In line with these expectations, correlations were found to be close to zero ranging between &#8211;.30 and .06 (see <xref ref-type="fig" id="fgc1-2" rid="fig1">Figure 1</xref>). Ideational fluency and originality even showed significant negative correlations when using the average score and considering task times of 3 minutes or less.</p>
<p align="left">For reasons of comparison with previous studies, we also computed summative originality scores by summing up the creativity evaluations of all ideas produced by participants within a task. As expected, these summative creativity scores showed extremely high correlations with the fluency scores of <italic>r</italic> = .83, .87, .90, .90, .91 for time-on-task of 1, 2, 3, 4, and 5 minutes, respectively.</p>
</sec>
<sec id="s14" disp-level="subsect1">
<title>How Do Scoring Conditions Affect Reliability?</title>
<p align="left">To examine how the scoring conditions affect reliability of fluency and originality scores, we computed their internal consistency (Cronbach&#8217;s alpha). The fluency score shows high reliability (&#945; = .83) even for a short time-on-task of 1 minute. The reliability evidence increases with time-on-task up to &#945; = .89 for a time-on-task of 5 minutes (see <xref ref-type="fig" id="fgc2-2" rid="fig2">Figure 2A</xref>).</p>
<p align="left">The reliability evidence of the originality score also was found to generally increase with an increasing number of top-ideas and with increasing time-on-task (see <xref ref-type="fig" id="fgc2-3" rid="fig2">Figure 2B</xref>). Reliability was lowest when only a single top-idea was considered (i.e., top-1 score) staying below an alpha of .60, but it increased substantially by including some additional top-ideas. For example, at a time-on-task of 2 minutes using top-2, top-3, or top-4 scoring increased reliability to .70, .75, or .77, respectively.</p>
<p align="left">Time-on-task also generally increased reliability evidence, but this is especially true when a larger number of top-ideas is considered. For the top-1 scoring, the increase of time-on-task from 1 minute to 5 minutes only causes an increase in reliability from .56 to .59, whereas it increases from .71 to .83 for the top-5 scoring. A decent alpha coefficient of at least .75 could be obtained only by using a time-on-task of 2 minutes (or higher) and when using at least the top-3 ideas. An alpha of .80 was obtained when using top-4 scoring with a time-on-task of 4 minutes or top-5 scoring with time-on task of 3 minutes. Reliability of the originality score peaked at an alpha of .87 when using the average score (i.e., using all ideas) at a time-on-task of 5 minutes.</p>
</sec>
<sec id="s15" disp-level="subsect1">
<title>How Do Scoring Conditions Affect Validity?</title>
<p align="left">The effect of the scoring method on the convergent validity evidence of ideational fluency and originality was tested by means of correlations with the external criteria of self-reported ideational behavior and the personality factor openness. The fluency score showed significant positive correlations with both external criteria ranging from .26 to .33 for the ideational behavior scale and from .25 to .30 for openness, respectively (see <xref ref-type="fig" id="fgc3-2" rid="fig3">Figure 3A and 3C</xref>). At this, there is a small trend for correlations to increase with time-on-task.</p>
<p align="left">The originality score showed no significant correlations with the ideational behavior scale, but just a weak trend toward positive correlations (see <xref ref-type="fig" id="fgc3-3" rid="fig3">Figure 3B</xref>). With respect to openness, the originality scores generally showed significant positive correlations (see <xref ref-type="fig" id="fgc3-4" rid="fig3">Figure 3D</xref>). These correlations were highest (<italic>r</italic> = .35 to .38) for a time-on-task of 2 minutes when using scoring of top-2 to top-8. The correlations were substantially lower but still significant (<italic>r</italic> = .21 to .26) for the average scoring method which considers all ideas.</p>
</sec>
</sec>
<sec id="s16">
<title>Discussion</title>
<sec id="s17" disp-level="subsect1">
<title>Can Subjective Top-Scoring Avoid the Confounding of Originality and Fluency?</title>
<p align="left">One major aim of the subjective top-scoring method is to avoid the usually high dependency of qualitative measures of divergent thinking (e.g., ideational originality) from the number of ideas generated by participants (i.e., ideational fluency). We were able to replicate the common finding that a summative scoring of originality (i.e., computing a sum of the creativity evaluations of all ideas generated by a participant) results in extremely high correlation with the fluency scoring ranging between .80 and .90 (cf., <xref ref-type="bibr" id="cr19-2" rid="c19">Mouchiroud &amp; Lubart, 2001</xref>; <xref ref-type="bibr" id="cr37-3" rid="c37">Torrance, 2008</xref>). In contrast, when originality scores were computed by means of the top-scoring method, correlations with fluency were largely close to zero. This is in line with the finding of <xref ref-type="bibr" id="cr34-12" rid="c34">Silvia et al. (2008)</xref>, who also obtained no significant correlation with fluency when using top-2 scoring. The results hence confirm that the subjective top-scoring method avoids the confounding of originality scores with fluency.</p>
<p align="left">The average score is a special case because it uses all ideas but by averaging ratings rather than summing them, a high positive correlation with fluency of ideas can be avoided. For the average score (and to a smaller extent also for the top-9 or top-10 score) we even observed small negative correlations at least when time-on-task was short. This result may probably be attributed to the existence of people who focus on fluency rather than creativity of ideas and thus were able to generate large amounts of responses. This strategy probably involves the generation of a large number of highly common responses which then results in a low average originality score as compared to those who rather focus on creativity of ideas (<xref ref-type="bibr" id="cr23-2" rid="c23">Reiter-Palmon et al., 2009</xref>).</p>
</sec>
<sec id="s18" disp-level="subsect1">
<title>Psychometric Properties of the Fluency Score</title>
<p align="left">We obtained high internal consistency for the ideational fluency scores of the six divergent thinking tasks. Alpha coefficients slightly increased with time-on-task but already settled above .85 for times-on-task of 2 minutes or more. This suggests that ideational fluency can be reliably assessed even with short divergent thinking tasks. We further obtained significant positive correlations of fluency with self-reported ideational behavior and openness supporting the general validity of this score. These correlations also showed a slight increase with time-on-task which can probably be attributed to the corresponding increases in reliability.</p>
</sec>
<sec id="s19" disp-level="subsect1">
<title>Psychometric Properties of the Originality Score</title>
<p align="left">The top-scoring method was found to result in dependable originality scores. Although interrater reliability was moderate for some tasks, the internal consistency between the six different divergent thinking tasks reached Cronbach&#8217;s alpha levels well beyond .80 for some scoring conditions. This level of reliability bears comparison with other well-established constructs of cognitive ability. Together with the findings derived from factor analysis, this indicates that originality scores coming from different divergent thinking tasks share a substantial amount of common variance. Although divergent thinking tasks may not be fully interchangeable with respect to their cognitive demands (<xref ref-type="bibr" id="cr10-1" rid="c10">Guilford, 1967</xref>; <xref ref-type="bibr" id="cr15-1" rid="c15">Kuhn &amp; Holling, 2009</xref>; <xref ref-type="bibr" id="cr32-2" rid="c32">Silvia, 2011</xref>), our results support the feasibility of computing aggregate scores across different divergent thinking task to obtain a reliable total originality score. The reliability, however, was found to be sensitive to scoring conditions (i.e., <italic>top-ideas</italic> and <italic>time-on-task</italic>). Reliability was lowest when only a single top-idea was considered, but it could be increased substantially by including some additional top-ideas (<xref ref-type="bibr" id="cr4-2" rid="c4">Benedek, Franz et al., 2012</xref>), and was highest for the average score which makes use of all ideas (<xref ref-type="bibr" id="cr34-13" rid="c34">Silvia et al., 2008</xref>). A straightforward explanation for this is that the aggregated evaluations of a larger number of ideas allows for a more reliable assessment, just as any test increases reliability by extending the number of relevant items. Also, considering more ideas could compensate for any discrepancies between the participants and the raters about what are considered to be the most creative ideas.</p>
<p align="left">A higher time-on-task was found to increase reliability at least for scores using four or more top-ideas. This suggests that scoring a high number of ideas makes more sense when there is enough time for participants to generate large numbers of ideas. A task time of 2 or 3 minutes apparently already worked quite well for most scores; further increases in task time only added small increases in reliability.</p>
<p align="left">We also examined correlations with other common indicators of creativity to estimate effects of task properties on the validity of the originality score. A priori, one could assume that the correlation pattern would generally match that of reliability as any lack of reliability necessarily impairs validity coefficients. Interestingly, this was not the case. Whereas the reliability evidence of originality scores was highest for average scoring at 5 minutes time-on-task, the correlation with openness for this score was lowest. The highest validity coefficients were obtained for a task time of 2 minutes using a medium number of about 3 to 6 top-ideas. This raises the question why correlations did not increase with increasing number of top-ideas just as reliability did. It has to be remembered that people were instructed to generate as many unusual and creative ideas as possible. High creative people presumably were able to generate many unusual ideas, of which, however, only some are very creative and thus truly indicative of their potential for creative thought. Hence, when all ideas are considered, such as in the average scoring, the evaluations of more and less creative ideas become mixed up. This would result in a moderate total creativity score for a high creative person which could equally be attained by a less creative person who just generated a few moderately creative ideas. It hence can be concluded that subjective top-scoring may provide more valid scores than average scoring, even though the latter method may be somewhat more reliable in terms of internal consistency.</p>
<p align="left">The question remains why the validity did not increase steadily with time-on-task like reliability did. This might be explained by the fact that originality generally increases over time (e.g., <xref ref-type="bibr" id="cr2-2" rid="c2">Beaty &amp; Silvia, 2012</xref>; <xref ref-type="bibr" id="cr17-2" rid="c17">Mednick, 1962</xref>; <xref ref-type="bibr" id="cr21-1" rid="c21">Piers &amp; Kirchner, 1971</xref>) but creative people overcome common ideas more quickly than less creative people (<xref ref-type="bibr" id="cr6-1" rid="c6">Benedek &amp; Neubauer, in press</xref>). As a consequence, after a short time-on-task, creative people may already have come up with highly original ideas whereas less creative people have not. As the time-on-task proceeds less creative people eventually also come up with more creative ideas, whereas high creative people can hardly further improve their performance to the same extent. Hence, the discernment between high and low creative people (i.e., validity) may be higher for shorter task times than for excessively long ones.</p>
<p align="left">Originality showed significant correlations only with openness but not with self-reported ideational behavior. The absent significant correlations with ideational behavior suggest that the ideational behavior questionnaire is more indicative of ideational fluency (two sample items read &#8220;I come up with a lot of ideas or solutions to problems&#8221; or &#8221;I have always been an active thinker&#8212;I have lots of ideas&#8221;; <xref ref-type="bibr" id="cr30-1" rid="c30">Runco et al., 2001</xref>).</p>
</sec>
<sec id="s20" disp-level="subsect1">
<title>Recommendations/Implications for Scoring of Divergent Thinking Tasks</title>
<p align="left">Some straightforward recommendations concerning the adequate assessment of ideational fluency and originality can be derived from the results of this study. For ideational fluency, it appears to be quite simple to obtain a reliable and valid score. This can be achieved by using divergent thinking tasks with short task time of about two minutes. The originality score, however, appears to be more sensitive to task and scoring properties. First, originality scores were found to be more valid when using tasks with durations of about 2 to 3 minutes. This substantiates the common practice of using similar tasks durations. Using shorter or much longer tasks, however, might negatively affect the validity of scores. Second, the top-scoring method should consider a medium number of about three to six ideas. Using much fewer or much more ideas (e.g., <xref ref-type="bibr" id="cr22-5" rid="c22">Plucker et al., 2011</xref>) may result in less valid scores. Considering that using a higher number of top-ideas also implies that a higher total number of ideas has to be subjected to ratings, it could be a good compromise to use three top-ideas. For a time-on-task of 2 minutes participants generated on average 10 ideas. Using only the three most creative ideas would help to reduce the rating effort by about 70% as compared to having to evaluate all ideas. Similar rates were reported by <xref ref-type="bibr" id="cr34-14" rid="c34">Silvia et al. (2008)</xref> for top-2 scoring. Moreover, more than 90% of participants generated three or more ideas within two minutes.</p>
</sec>
<sec id="s21" disp-level="subsect1">
<title>Some Limitations of This Study and Future Directions</title>
<p align="left">Some limitations of this study need to be addressed. Time-on-task was varied as an experimental variable by analyzing the performance data available at different times within the task. This was done to estimate scores that could be obtained for tasks of different length. Although this method is efficient, results obtained for, for example, a time-on-task of 2 minutes might not fully generalize to studies which explicitly use 2 minute tasks. Differences might for example relate to higher effects of fatigue, because performing six divergent thinking tasks with five minutes probably involves more cognitive effort than six tasks with only two minutes. Moreover, people might apply different idea generation strategies when they know that tasks are shorter. We tried, however, to minimize these effects by not telling participants about the exact task time and by not giving them any information about the remaining task time.</p>
<p align="left">A similar argument applies to the experimental variation of the number of top-ideas. The post hoc selection of a specific number of top-ideas may not fully generalize to the corresponding instruction to select a specific number of top-ideas. Some people who had generated large amounts of ideas reported that they found it difficult to arrange them all properly for creativity. This issue might be less prominent for shorter tasks and when people are just asked to identify their three or five most creative ideas. Taken together, it could be assumed that shorter task durations and the selection of a low number of most creative ideas may cause lower fatigue and more accurate judgments, which might eventually have additional positive effects on the psychometric properties of the originality score. Further limitations include the sample size, and the specific tasks which were selected for this study. For example, for more complex divergent thinking tasks (e.g., <xref ref-type="bibr" id="cr23-3" rid="c23">Reiter-Palmon et al., 2009</xref>), which often show lower fluency, the most adequate number of top-ideas might differ. The present findings hence await replication with larger samples, using other divergent thinking tasks, and employing further criteria for examining the validity of scores.</p>
<p align="left">There are also some additional methodological issues that could be addressed in future research. First of all, one might consider using separate tasks for assessing fluency and originality. We derived both scores from the same tasks (e.g., <xref ref-type="bibr" id="cr37-4" rid="c37">Torrance, 2008</xref>) and instructed participants to generate as many unusual and creative ideas as possible. This could be considered as kind of a double task which permits participants to use different strategies either focusing on fluency or creativity of ideas. Future work might therefore attempt to assess fluency and originality with separate tasks using specific task instructions to focus either only on fluency or only on originality of ideas. Although this procedure may require a larger total number of tasks, it might help to further increase the validity of scores. Finally, it should be noted that using a specific number of top-ideas also implies the possibility that there are some participants who actually do not generate as much ideas within the given time. There are different ways to handle this. In this study, we then used all available ideas of the participant. Another possibility would be to assign missing ideas with the lowest possible creativity rating (i.e., a creativity rating of zero). This would implicitly penalize very low fluency. Some side analyses indicated that such originality scores can again be highly correlated with fluency, at least for high numbers of top-ideas. This scoring approach could, however, be useful in studies that decide not to use separate fluency scorings but still allow for a moderate influence of fluency on the originality score.</p>
</sec>
</sec>
<sec id="s22">
<title>Conclusions</title>
<p align="left">This study provides further evidence of the usefulness of the subjective top-scoring method for the assessment of ideational originality (cf., <xref ref-type="bibr" id="cr34-15" rid="c34">Silvia et al., 2008</xref>). Using subjective top-scoring ensures that ideational originality scores overcome the issues often associated with this score, such as a lack of discriminant validity with respect to fluency. Moreover, adequate scoring methods help to obtain a highly reliable and valid originality score. As an example, a top-3 originality score for 2 minutes time-on-task showed a higher correlation with openness than fluency did. Adequate scoring of ideational originality hence may provide researchers with a powerful indicator of creative potential, besides and beyond fluency.</p>
</sec>
</body>
<back>
<ref-list use-in-PI="yes"><title>References</title>
<ref><mixed-citation publication-type="journal" meta="no" id="c1" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Amabile</surname>, <given-names>T.</given-names></string-name></person-group> (<year>1982</year>). <article-title>Social psychology of creativity: A consensual assessment technique</article-title>. <source>Journal of Personality and Social Psychology</source>, <volume>43</volume>, <fpage>997</fpage>&#8211;<lpage>1013</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0022-3514.43.5.997</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c2" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Beaty</surname>, <given-names>R. E.</given-names></string-name>, &amp; <string-name><surname>Silvia</surname>, <given-names>P. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Why do ideas get more creative across time? An executive interpretation of the serial order effect in divergent thinking tasks</article-title>. <source>Psychology of Aesthetics, Creativity, and the Arts</source>. <comment>Advance online publication</comment>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/a0029171</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c3" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Fink</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Neubauer</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Enhancement of ideational fluency by means of computer-based training</article-title>. <source>Creativity Research Journal</source>, <volume>18</volume>, <fpage>317</fpage>&#8211;<lpage>328</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1207/s15326934crj1803_7</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c4" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Franz</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Heene</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Neubauer</surname>, <given-names>A. C.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Differential effects of cognitive inhibition and intelligence on creativity</article-title>. <source>Personality and Individual Differences</source>, <volume>53</volume>, <fpage>480</fpage>&#8211;<lpage>485</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.paid.2012.04.014</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c5" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>K&#246;nen</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Neubauer</surname>, <given-names>A. C.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Associative abilities underlying creativity</article-title>. <source>Psychology of Aesthetics, Creativity, and the Arts</source>, <volume>6</volume>, <fpage>273</fpage>&#8211;<lpage>281</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/a0027059</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c6" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Neubauer</surname>, <given-names>A. C.</given-names></string-name></person-group> (<comment>in press</comment>). <article-title>Revisiting Mednick&#8217;s model on creativity-related differences in associative hierarchies. Evidence for a common path to uncommon thought</article-title>. <source>Journal of Creative Behavior</source>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1002/jocb.35</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c7" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Borkenau</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Ostendorf</surname>, <given-names>F.</given-names></string-name></person-group> (<year>1993</year>). <source>NEO-F&#252;nf-Faktoren Inventar (NEO-FFI) nach Costa und McCrae</source> [<trans-source>NEO-Five factor inventory after Costa and McCrae</trans-source>]. <publisher-loc>G&#246;ttingen, Germany</publisher-loc>: <publisher-name>Hogrefe</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c8" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Clark</surname>, <given-names>P. M.</given-names></string-name>, &amp; <string-name><surname>Mirels</surname>, <given-names>H. L.</given-names></string-name></person-group> (<year>1970</year>). <article-title>Fluency as a pervasive element in the measurement of creativity</article-title>. <source>Journal of Educational Measurement</source>, <volume>7</volume>, <fpage>83</fpage>&#8211;<lpage>86</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1111/j.1745-3984.1970.tb00699.x</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c9" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Fink</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name></person-group> (<comment>in press</comment>). <article-title>EEG Alpha power and creative ideation</article-title>. <source>Neuroscience and Biobehavioral Reviews</source>. <comment>Advance online publication</comment>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.neubiorev.2012.12.002</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c39" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Gilhooly</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Fioratou</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Anthony</surname>, <given-names>S. H.</given-names></string-name>, &amp; <string-name><surname>Wynn</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Divergent thinking: Strategies and executive involvement in generating novel uses for familiar objects</article-title>. <source>British Journal of Psychology</source>, <volume>98</volume>, <fpage>611</fpage>&#8211;<lpage>625</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c10" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Guilford</surname>, <given-names>J. P.</given-names></string-name></person-group> (<year>1967</year>). <source>The nature of human intelligence</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c11" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hocevar</surname>, <given-names>D.</given-names></string-name></person-group> (<year>1979a</year>). <article-title>A comparison of statistical infrequency and subjective judgment as criteria in the measurement of originality</article-title>. <source>Journal of Personality Assessment</source>, <volume>43</volume>, <fpage>297</fpage>&#8211;<lpage>299</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1207/s15327752jpa4303_13</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c12" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Hocevar</surname>, <given-names>D.</given-names></string-name></person-group> (<year>1979b</year>). <article-title>Ideational fluency as a confounding factor in the measurement of originality</article-title>. <source>Journal of Educational Psychology</source>, <volume>71</volume>, <fpage>191</fpage>&#8211;<lpage>196</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/0022-0663.71.2.191</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c13" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Jauk</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dunst</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Neubauer</surname>, <given-names>A. C.</given-names></string-name></person-group> (<year>2013</year>). <article-title>The relationship between intelligence and creativity: New support for the threshold hypothesis by means of empirical breakpoint detection</article-title>. <source>Intelligence</source>, <volume>41</volume>, <fpage>212</fpage>&#8211;<lpage>221</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.intell.2013.03.003</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c14" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Kaufman</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Plucker</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Baer</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2008</year>). <source>Essentials of creativity assessment</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c15" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Kuhn</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Holling</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Measurement invariance of divergent thinking across gender, age, and school forms</article-title>. <source>European Journal of Psychological Assessment</source>, <volume>25</volume>, <fpage>1</fpage>&#8211;<lpage>7</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1027/1015-5759.25.1.1</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c16" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Lau</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Cheung</surname>, <given-names>P. C.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Creativity assessment: Comparability of the electronic and paper-and-pencil versions of the Wallach&#8211;Kogan Creativity Tests</article-title>. <source>Thinking Skills and Creativity</source>, <volume>5</volume>, <fpage>101</fpage>&#8211;<lpage>107</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.tsc.2010.09.004</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c17" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Mednick</surname>, <given-names>S. A.</given-names></string-name></person-group> (<year>1962</year>). <article-title>The associative basis of the creative process</article-title>. <source>Psychological Review</source>, <volume>69</volume>, <fpage>220</fpage>&#8211;<lpage>232</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/h0048850</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c18" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Michael</surname>, <given-names>W. B.</given-names></string-name>, &amp; <string-name><surname>Wright</surname>, <given-names>C. R.</given-names></string-name></person-group> (<year>1989</year>). <chapter-title>Psychometric issues in the assessment of creativity</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>J. A.</given-names> <surname>Glover</surname></string-name>, <string-name><given-names>R. R.</given-names> <surname>Ronning</surname></string-name> &amp; <string-name><given-names>C. R.</given-names> <surname>Reynolds</surname></string-name></person-group> (<role>Eds.</role>), <source>Handbook of creativity</source> (pp. <fpage>33</fpage>&#8211;<lpage>52</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Plenum Press</publisher-name>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1007/978-1-4757-5356-1_2</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c19" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Mouchiroud</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Lubart</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Children&#8217;s original thinking: An empirical examination of alternative measures derived from divergent thinking tasks</article-title>. <source>The Journal of Genetic Psychology: Research and Theory on Human Development</source>, <volume>162</volume>, <fpage>382</fpage>&#8211;<lpage>401</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/00221320109597491</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c20" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Nusbaum</surname>, <given-names>E. C.</given-names></string-name>, &amp; <string-name><surname>Silvia</surname>, <given-names>P. J.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Are intelligence and creativity really so different? Fluid intelligence, executive processes, and strategy use in divergent thinking</article-title>. <source>Intelligence</source>, <volume>39</volume>, <fpage>36</fpage>&#8211;<lpage>45</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.intell.2010.11.002</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c21" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Piers</surname>, <given-names>E. V.</given-names></string-name>, &amp; <string-name><surname>Kirchner</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>1971</year>). <article-title>Productivity and uniqueness in continued word association as a function of subject creativity and stimulus properties</article-title>. <source>Journal of Personality</source>, <volume>39</volume>(<issue>2</issue>), <fpage>264</fpage>&#8211;<lpage>276</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1111/j.1467-6494.1971.tb00041.x</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c22" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Plucker</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Qian</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Is originality in the eye of the beholder? Comparison of scoring techniques in the assessment of divergent thinking</article-title>. <source>The Journal of Creative Behavior</source>, <volume>45</volume>, <fpage>1</fpage>&#8211;<lpage>22</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1002/j.2162-6057.2011.tb01081.x</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c23" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Reiter-Palmon</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Illies</surname>, <given-names>M. Y.</given-names></string-name>, <string-name><surname>Cross</surname>, <given-names>L. K.</given-names></string-name>, <string-name><surname>Buboltz</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Nimps</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Creativity and domain specificity: The effect of task type on multiple indexes of creative problem-solving</article-title>. <source>Psychology of Aesthetics, Creativity, and the Arts</source>, <volume>3</volume>, <fpage>73</fpage>&#8211;<lpage>80</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/a0013410</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c24" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Maximal performance on divergent thinking tests by gifted, talented, and nongifted children</article-title>. <source>Psychology in the Schools</source>, <volume>23</volume>, <fpage>308</fpage>&#8211;<lpage>315</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1002/1520-6807(198607)23:3&lt;308::AID-PITS2310230313&gt;3.0.CO;2-V</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c25" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Commentary: Divergent thinking is not synonymous with creativity</article-title>. <source>Psychology of Aesthetics, Creativity, and the Arts</source>, <volume>2</volume>, <fpage>93</fpage>&#8211;<lpage>96</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/1931-3896.2.2.93</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c26" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Acar</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Divergent thinking as an indicator of creative potential</article-title>. <source>Creativity Research Journal</source>, <volume>24</volume>, <fpage>66</fpage>&#8211;<lpage>75</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1080/10400419.2012.652929</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c27" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Albert</surname>, <given-names>R. S.</given-names></string-name></person-group> (<year>1985</year>). <article-title>The reliability and validity of ideational originality in the divergent thinking of academically gifted and nongifted children</article-title>. <source>Educational and Psychological Measurement</source>, <volume>45</volume>, <fpage>483</fpage>&#8211;<lpage>501</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c28" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Mraz</surname>, <given-names>W.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Scoring divergent thinking tests using total ideational output and a creativity index</article-title>. <source>Educational and Psychological Measurement</source>, <volume>52</volume>, <fpage>213</fpage>&#8211;<lpage>221</lpage>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c29" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Okuda</surname>, <given-names>S. M.</given-names></string-name>, &amp; <string-name><surname>Thurston</surname>, <given-names>B. J.</given-names></string-name></person-group> (<year>1987</year>). <article-title>The psychometric properties of four systems for scoring divergent thinking tests</article-title>. <source>Journal of Psychoeducational Assessment</source>, <volume>5</volume>, <fpage>149</fpage>&#8211;<lpage>156</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1177/073428298700500206</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c30" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Runco</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Plucker</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Lim</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Development and psychometric integrity of a measure of ideational behavior</article-title>. <source>Creativity Research Journal</source>, <volume>13</volume>, <fpage>393</fpage>&#8211;<lpage>400</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1207/S15326934CRJ1334_16</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c31" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Silvia</surname>, <given-names>P. J.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Discernment and creativity: How well can people identify their most creative ideas?</article-title> <source>Psychology of Aesthetics, Creativity, and the Arts</source>, <volume>2</volume>, <fpage>139</fpage>&#8211;<lpage>146</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/1931-3896.2.3.139</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c32" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Silvia</surname>, <given-names>P. J.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Subjective scoring of divergent thinking: Examining the reliability of unusual uses, instances, and consequences tasks</article-title>. <source>Thinking Skills and Creativity</source>, <volume>6</volume>, <fpage>24</fpage>&#8211;<lpage>30</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.tsc.2010.06.001</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c33" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Silvia</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Nusbaum</surname>, <given-names>E. C.</given-names></string-name></person-group> (<year>2009</year>). <article-title>A snapshot of creativity: Evaluating a quick and simple method for assessing divergent thinking</article-title>. <source>Thinking Skills and Creativity</source>, <volume>4</volume>, <fpage>79</fpage>&#8211;<lpage>85</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1016/j.tsc.2009.06.005</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="journal" meta="no" id="c34" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Silvia</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Winterstein</surname>, <given-names>B. P.</given-names></string-name>, <string-name><surname>Willse</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Barona</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Cram</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Hess</surname>, <given-names>K. I.</given-names></string-name>, <etal>. . .</etal> <string-name><surname>Richard</surname>, <given-names>C. A.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Assessing creativity with divergent thinking tasks: Exploring the reliability and validity of new subjective scoring methods</article-title>. <source>Psychology of Aesthetics, Creativity, and the Arts</source>, <volume>2</volume>, <fpage>68</fpage>&#8211;<lpage>85</lpage>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1037/1931-3896.2.2.68</pub-id></mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c35" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Ward</surname>, <given-names>T. B.</given-names></string-name>, &amp; <string-name><surname>Finke</surname>, <given-names>R. A.</given-names></string-name></person-group> (<year>1995</year>). <source>The creative cognition approach</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c36" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Torrance</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>1974</year>). <source>Torrance Tests of Creative Thinking: Norms-technical manual, verbal forms A and B</source>. <publisher-loc>Bensenville, IL</publisher-loc>: <publisher-name>Scholastic Testing Service</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book" meta="no" id="c37" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Torrance</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2008</year>). <source>Torrance Tests of Creative Thinking: Norms-technical manual, verbal forms A and B</source>. <publisher-loc>Bensenville, IL</publisher-loc>: <publisher-name>Scholastic Testing Service</publisher-name>.</mixed-citation>
</ref>
<ref><mixed-citation publication-type="book-chapter" meta="no" id="c38" xlink:type="simple"><person-group person-group-type="author"><string-name><surname>Velicer</surname>, <given-names>W. F.</given-names></string-name>, <string-name><surname>Eaton</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Fava</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2000</year>). <chapter-title>Construct explication through factor or component analysis: A review and evaluation of alternative procedures for determining the number of factors or components</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>R. D.</given-names> <surname>Goffin</surname></string-name> &amp; <string-name><given-names>E.</given-names> <surname>Helmes</surname></string-name></person-group> (<role>Eds.</role>), <source>Problems and solutions in human assessment</source> (pp. <fpage>41</fpage>&#8211;<lpage>71</lpage>). <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Kluwer</publisher-name>. doi:<pub-id pub-id-source="author-published" pub-id-type="doi">10.1007/978-1-4615-4397-8_3</pub-id></mixed-citation></ref>
</ref-list>
</back>
<floats-group>
<table-wrap id="tbl1" position="float" orientation="portrait" pagewide="no">
<label>1</label>
<caption><title>Number of Ideas Generated After a Time-on-Task of 1 to 5 Minutes in the Alternate Uses Tasks and the Instances Tasks</title></caption>
<graphic copyright="inherit" id="tbl1a" xlink:href="aca_7_4_341_tbl1a.tif" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" span="1"/>
<col align="char" char="." span="1"/>
<col align="char" char="." span="1"/>
<col align="char" char="." span="1"/>
<col align="char" char="." span="1"/>
<col align="char" char="." span="1"/>
</colgroup>
<thead>
<tr valign="bottom">
<th align="center" rowspan="1" colspan="1"/>
<th align="center" rowspan="1" colspan="1">1 min</th>
<th align="center" rowspan="1" colspan="1">2 min</th>
<th align="center" rowspan="1" colspan="1">3 min</th>
<th align="center" rowspan="1" colspan="1">4 min</th>
<th align="center" rowspan="1" colspan="1">5 min</th>
</tr>
</thead>
<tfoot valign="top">
<tr>
<td align="left" colspan="6" rowspan="1"><italic>Note</italic>.&#8195;The three values in each cell denote 10, 50, and 90 percentile values.</td>
</tr></tfoot>
<tbody>
<tr valign="top">
<td rowspan="1" colspan="1">Alternate uses</td>
<td rowspan="1" colspan="1">2.0/4.3/6.7</td>
<td rowspan="1" colspan="1">3.5/7.0/10.3</td>
<td rowspan="1" colspan="1">4.8/9.0/13.7</td>
<td rowspan="1" colspan="1">5.3/11.0/17.0</td>
<td rowspan="1" colspan="1">6.3/12.0/19.0</td>
</tr>
<tr valign="top">
<td rowspan="1" colspan="1">Instances</td>
<td rowspan="1" colspan="1">2.5/7.7/11.3</td>
<td rowspan="1" colspan="1">4.8/12.0/17.7</td>
<td rowspan="1" colspan="1">6.5/15.3/23.7</td>
<td rowspan="1" colspan="1">8.4/18.7/28.3</td>
<td rowspan="1" colspan="1">9.0/21.7/32.7</td></tr></tbody></table></table-wrap>
<fig id="fig1">
<label>1</label>
<caption><p align="left">Correlation of fluency and originality scores depending on the number of <italic>top-ideas</italic> and <italic>time-on-task</italic>. Correlation coefficients exceeding <italic>r</italic> = .19 are considered statistically significant given the sample size of <italic>n</italic> = 105.</p></caption>
<graphic copyright="inherit" id="fig1a" xlink:href="aca_7_4_341_fig1a.tif" xlink:type="simple"/></fig>
<fig id="fig2">
<label>2</label>
<caption><p align="left">Reliability (Cronbach&#8217;s alpha) of (A) the fluency score and (B) the originality score depending on the number of <italic>top-ideas</italic> and <italic>time-on-task.</italic></p></caption>
<graphic copyright="inherit" id="fig2a" xlink:href="aca_7_4_341_fig2a.tif" xlink:type="simple"/></fig>
<fig id="fig3">
<label>3</label>
<caption><p align="left">Correlation of fluency (A, C) and originality (B, D) with self-reported ideational behavior and openness depending on the number of <italic>top-ideas</italic> and <italic>time-on-task</italic>. Correlation coefficients exceeding <italic>r</italic> = .19 are considered statistically significant given the sample size of <italic>n</italic> = 105.</p></caption>
<graphic copyright="inherit" id="fig3a" xlink:href="aca_7_4_341_fig3a.tif" xlink:type="simple"/></fig></floats-group></article>